{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a203430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\r\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d054912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import s3fs\n",
    "from pyarrow.parquet import ParquetDataset\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os, errno\n",
    "import sys\n",
    "from tqdm import trange\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a83f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights.npy', 'rb') as f:\n",
    "    weights = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54c86759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('sequences', 'rb') as fp:  \n",
    "    sequences = pickle.load(fp)\n",
    "    \n",
    "with open('timestamps', 'rb') as fp:  \n",
    "    timestamps = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3da518a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2vembedding(sequences, weights):\n",
    "    for seqIndex, sequence in enumerate(sequences):\n",
    "        for opIndex, operation in enumerate(sequence):\n",
    "            sequences[seqIndex][opIndex] = weights[operation - 1]\n",
    "    return sequences\n",
    "\n",
    "num_sequences = sequences\n",
    "sequences = w2vembedding(sequences, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a9964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(sequences, window_size = 20): \n",
    "    windowed_sequences = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) >= window_size:\n",
    "            for i in range(len(sequence) - window_size):\n",
    "                windowed_sequences.append(sequence[i:window_size+i])\n",
    "    return windowed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15029bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_sequences = window(sequences)\n",
    "torched_windowed_sequences = torch.from_numpy(np.array(windowed_sequences))\n",
    "torched_windowed_sequences = torched_windowed_sequences.type(torch.FloatTensor)\n",
    "\n",
    "windowed_timestamps = window(timestamps)\n",
    "torched_windowed_timestamps = torch.from_numpy(np.array(windowed_timestamps))\n",
    "torched_windowed_timestamps  = torched_windowed_timestamps.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd24f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torched_windowed_sequences = torched_windowed_sequences.permute(1,0,2)\n",
    "torched_windowed_timestamps = torched_windowed_timestamps.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e57667ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 158859, 128])\n",
      "torch.Size([20, 158859])\n"
     ]
    }
   ],
   "source": [
    "print(torched_windowed_sequences.shape)\n",
    "print(torched_windowed_timestamps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54aa09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.jit as jit\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c89f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64965d50",
   "metadata": {},
   "source": [
    "### LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29ead207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.i2h = nn.Linear(input_size, 4 * hidden_size, bias=bias) # previously 4, added another gate\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "\n",
    "        self.t2h = nn.Linear(1, hidden_size, bias=bias)\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, \n",
    "                t, # time modification here\n",
    "                hidden):\n",
    "        h, c = hidden\n",
    "\n",
    "        preact = self.i2h(x) + self.h2h(h) \n",
    "\n",
    "        gates = preact[:, :, :3 * self.hidden_size].sigmoid()\n",
    "        \n",
    "        g_t = preact[:, :, 3 * self.hidden_size:].tanh()\n",
    "        \n",
    "        i_t = gates[:, :, :self.hidden_size]\n",
    "        \n",
    "        f_t = gates[:, :, self.hidden_size:2 * self.hidden_size]\n",
    "        o_t = gates[:, :, -self.hidden_size:]\n",
    "        \n",
    "        c_t = torch.mul(c, f_t) + torch.mul(i_t, g_t)\n",
    "        \n",
    "        h_t = torch.mul(o_t, c_t.tanh())\n",
    "        \n",
    "        return h_t, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4aa357ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.lstm_cell = LSTMCell(input_size, hidden_size) \n",
    "\n",
    "    def forward(self, input_, time, hidden):\n",
    "        for i, x in enumerate(torch.unbind(input_, dim=0)): \n",
    "            h_t, hidden = self.lstm_cell(x.unsqueeze(0), \n",
    "                                             time[i].unsqueeze(0), \n",
    "                                             hidden) \n",
    "        return h_t, hidden\n",
    "    \n",
    "class lstm_encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = LSTM(input_size = input_size, hidden_size = hidden_size,)\n",
    "    def forward(self, x_input, time_input):\n",
    "        batch_size = x_input.shape[1]\n",
    "        lstm_out, self.hidden = self.lstm(x_input,\n",
    "                                          #.view(x_input.shape[0], x_input.shape[1], self.input_size)\n",
    "                                          time_input, \n",
    "                                          (torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(self.num_layers, batch_size, self.hidden_size)))\n",
    "        #print(\"self.hidden is\" + str(self.hidden[0].shape))\n",
    "        return lstm_out, self.hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "    def test(self, x_input, time_input, embedding, batch_size=1):\n",
    "        mid = len(embedding)//2\n",
    "        hid1 = torch.from_numpy(embedding[:mid])\n",
    "        hid2 = torch.from_numpy(embedding[mid:])\n",
    "        hidden = (hid1, hid2)\n",
    "        lstm_out, self.hidden = self.lstm(x_input,\n",
    "                                          time_input, \n",
    "                                          hidden)\n",
    "        return self.hidden\n",
    "\n",
    "class lstm_decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = LSTM(input_size = input_size, hidden_size = hidden_size,\n",
    "                            #num_layers = num_layers\n",
    "                               )\n",
    "        self.linear = nn.Linear(hidden_size, input_size)           \n",
    "\n",
    "    def forward(self, x_input, time_input, encoder_hidden_states):\n",
    "        '''\n",
    "        print(\"We are now in the lstm decoder\")\n",
    "        print(\"x_input shape is\")\n",
    "        print(x_input.shape)\n",
    "        print(x_input)\n",
    "        '''\n",
    "        x_input = x_input.unsqueeze(0)\n",
    "        #print(encoder_hidden_states[0].shape) # torch.Size([1, 5, 15])\n",
    "        \n",
    "        #print(x_input.shape)\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(x_input, \n",
    "                                          time_input,\n",
    "                                          encoder_hidden_states)\n",
    "        #print('lstm_out')\n",
    "        #print(lstm_out.shape)\n",
    "        output = self.linear(lstm_out.squeeze(0))  \n",
    "        \n",
    "        #print('output')\n",
    "        #print(output.shape)\n",
    "        return output, self.hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87436e09",
   "metadata": {},
   "source": [
    "### Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "117dbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(lstm_autoencoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = lstm_encoder(input_size = input_size, hidden_size = hidden_size)\n",
    "        self.decoder = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
    "        \n",
    "        self.predictor = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
    "\n",
    "\n",
    "    def train_autoencoder(self, input_tensor, \n",
    "                          time_tensor,\n",
    "                          #target_tensor, \n",
    "                          n_epochs, \n",
    "                          #target_len, \n",
    "                          batch_size, \n",
    "                          training_prediction = 'recursive', teacher_forcing_ratio = 0.5, learning_rate = 0.01, dynamic_tf = False):\n",
    "        \n",
    "        print('addfasafsdf')\n",
    "        \n",
    "        # initialize array of losses \n",
    "        losses = np.full(n_epochs, np.nan)\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # calculate number of batch iterations\n",
    "        n_batches = int(input_tensor.shape[0] / batch_size)\n",
    "        \n",
    "        # torch.Size([158859, 20, 128])\n",
    "\n",
    "        with trange(n_epochs) as tr: # USING TGE \n",
    "            for it in tr:\n",
    "                \n",
    "                batch_loss = 0.\n",
    "                batch_loss_tf = 0.\n",
    "                batch_loss_no_tf = 0.\n",
    "                num_tf = 0\n",
    "                num_no_tf = 0\n",
    "\n",
    "                for b in range(n_batches):\n",
    "                    # select data \n",
    "                    input_batch = input_tensor[:, b: b + batch_size, :]\n",
    "                    #print(input_tensor.shape)\n",
    "                    #print(input_batch.shape)\n",
    "                    \n",
    "                    time_batch = time_tensor[:, b: b + batch_size]\n",
    "                    \n",
    "                    target_batch = input_tensor[:, b: b + batch_size, :]\n",
    "\n",
    "                    # outputs tensor\n",
    "                    #outputs = torch.zeros(target_len, batch_size, input_batch.shape[2])\n",
    "                    outputs = torch.zeros(input_tensor.shape[0], batch_size, input_tensor.shape[2])\n",
    "\n",
    "                    # initialize hidden state\n",
    "                    encoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "\n",
    "                    # zero the gradient\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # encoder outputs\n",
    "                    encoder_output, encoder_hidden = self.encoder(input_batch, \n",
    "                                                                  time_batch\n",
    "                                                                 )\n",
    "\n",
    "                    # decoder with teacher forcing\n",
    "                    #decoder_input = input_batch[-1, :, :]   # taking the last time step // shape: (batch_size, input_size)\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    decoder_input = torch.ones(input_batch[-1,:,:].shape) # SOS token\n",
    "                    #print('decoder_input')\n",
    "                    #print(decoder_input.shape)\n",
    "                    time = time_batch[0,:]\n",
    "\n",
    "                    decoder_hidden = encoder_hidden\n",
    "                    \n",
    "                    target_len = input_batch.shape[0] # new modification\n",
    "\n",
    "                    if training_prediction == 'recursive':\n",
    "                        # predict recursively\n",
    "                        for t in range(target_len): \n",
    "                            decoder_output, decoder_hidden = self.decoder(decoder_input, time, decoder_hidden)\n",
    "                            time = time_batch[t,:]\n",
    "                            outputs[t] = decoder_output\n",
    "                            decoder_input = decoder_output\n",
    "\n",
    "                    if training_prediction == 'teacher_forcing':\n",
    "                        # use teacher forcing\n",
    "                        if random.random() < teacher_forcing_ratio:\n",
    "                            for t in range(target_len): \n",
    "                                decoder_output, decoder_hidden = self.decoder(decoder_input, time, decoder_hidden)\n",
    "                                time = time_batch[t,:]\n",
    "                                outputs[t] = decoder_output\n",
    "                                decoder_input = target_batch[t, :, :]\n",
    "\n",
    "                        # predict recursively \n",
    "                        else:\n",
    "                            for t in range(target_len): \n",
    "                                decoder_output, decoder_hidden = self.decoder(decoder_input, time,  decoder_hidden)\n",
    "                                time = time_batch[t,:]\n",
    "                                outputs[t] = decoder_output\n",
    "                                decoder_input = decoder_output\n",
    "\n",
    "                    if training_prediction == 'mixed_teacher_forcing':\n",
    "                        # predict using mixed teacher forcing\n",
    "                        for t in range(target_len): # IN REVERSE\n",
    "                            time = time_batch[t,:]\n",
    "                            \n",
    "                            #print('afsasfdfaf')\n",
    "                            \n",
    "                            decoder_output, decoder_hidden = self.decoder(decoder_input, time, decoder_hidden)\n",
    "                            \n",
    "                            #print(b)\n",
    "                            #print(outputs[t].shape)\n",
    "                            #print(decoder_output.shape)\n",
    "                            \n",
    "                            outputs[t] = decoder_output\n",
    "                            \n",
    "                            # predict with teacher forcing\n",
    "                            if random.random() < teacher_forcing_ratio:\n",
    "                                decoder_input = target_batch[t, :, :]\n",
    "                            \n",
    "                            # predict recursively \n",
    "                            else:\n",
    "                                decoder_input = decoder_output\n",
    "\n",
    "                    # compute the loss \n",
    "                    loss = criterion(outputs, target_batch)\n",
    "                    #loss = torch.norm(outputs - target_batch)\n",
    "                    batch_loss += loss.item()\n",
    "                    \n",
    "                    # backpropagation\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # loss for epoch \n",
    "                batch_loss /= n_batches \n",
    "                losses[it] = batch_loss\n",
    "\n",
    "                # dynamic teacher forcing\n",
    "                if dynamic_tf and teacher_forcing_ratio > 0:\n",
    "                    teacher_forcing_ratio = teacher_forcing_ratio - 0.02 \n",
    "\n",
    "                # progress bar \n",
    "                tr.set_postfix(loss=\"{0:.10f}\".format(batch_loss))\n",
    "                    \n",
    "        return losses\n",
    "    \n",
    "    # TIME SERIES PREDICTION: take 10 actions, predict next 2 with time inputs\n",
    "    def train_predecoder(self, input_tensor, \n",
    "                         time_tensor,\n",
    "                         target_len,\n",
    "                         n_epochs,\n",
    "                         batch_size = 5, \n",
    "                         training_prediction = 'recursive', teacher_forcing_ratio = 0.5, learning_rate = 0.01, dynamic_tf = False):\n",
    "        \n",
    "        # IMPORTANT: THIS PREVENTS ENCODER MODEL FROM BEING RE-TRAINED\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        # initialize array of losses \n",
    "        losses = np.full(n_epochs, np.nan)\n",
    "\n",
    "        optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # calculate number of batch iterations\n",
    "        n_batches = int(input_tensor.shape[0] / batch_size)\n",
    "        \n",
    "        with trange(n_epochs) as tr: # USING TGE \n",
    "            for it in tr:\n",
    "                \n",
    "                batch_loss = 0.\n",
    "                batch_loss_tf = 0.\n",
    "                batch_loss_no_tf = 0.\n",
    "                num_tf = 0\n",
    "                num_no_tf = 0\n",
    "\n",
    "                for b in range(n_batches):\n",
    "                    \n",
    "                    # select data \n",
    "                    input_batch = input_tensor[:-target_len, b: b + batch_size, :]\n",
    "                    time_batch = time_tensor[:-target_len, b: b + batch_size]\n",
    "                    \n",
    "                    target_time_batch = time_tensor[-target_len:, b: b + batch_size]\n",
    "                    target_batch = input_tensor[-target_len:, b: b + batch_size, :]\n",
    "                    \n",
    "                    # outputs tensor\n",
    "                    #outputs = torch.zeros(target_len, batch_size, input_batch.shape[2])\n",
    "                    outputs = torch.zeros(target_len, batch_size, input_tensor.shape[2])\n",
    "\n",
    "                    # initialize hidden state\n",
    "                    encoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "\n",
    "                    # zero the gradient\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # encoder outputs\n",
    "                    encoder_output, encoder_hidden = self.encoder(input_batch, \n",
    "                                                                  time_batch)\n",
    "                    \n",
    "                    decoder_input = torch.ones(input_batch[-1,:,:].shape) # SOS token\n",
    "                    #print('decoder_input')\n",
    "                    #print(decoder_input.shape)\n",
    "                    time = time_batch[0,:]\n",
    "\n",
    "                    decoder_hidden = encoder_hidden\n",
    "                \n",
    "                    if training_prediction == 'recursive':\n",
    "                        # predict recursively\n",
    "                        for t in range(target_len): \n",
    "                            decoder_output, decoder_hidden = self.predictor(decoder_input, time, decoder_hidden)\n",
    "                            time = target_time_batch[t,:]\n",
    "                            outputs[t] = decoder_output\n",
    "                            decoder_input = decoder_output\n",
    "\n",
    "                    if training_prediction == 'teacher_forcing':\n",
    "                        # use teacher forcing\n",
    "                        if random.random() < teacher_forcing_ratio:\n",
    "                            for t in range(target_len): \n",
    "                                decoder_output, decoder_hidden = self.predictor(decoder_input, time, decoder_hidden)\n",
    "                                time = target_time_batch[t,:]\n",
    "                                outputs[t] = decoder_output\n",
    "                                decoder_input = target_batch[t, :, :]\n",
    "\n",
    "                        # predict recursively \n",
    "                        else:\n",
    "                            for t in range(target_len): \n",
    "                                decoder_output, decoder_hidden = self.predictor(decoder_input, time,  decoder_hidden)\n",
    "                                time = target_time_batch[t,:]\n",
    "                                outputs[t] = decoder_output\n",
    "                                decoder_input = decoder_output\n",
    "\n",
    "                    if training_prediction == 'mixed_teacher_forcing':\n",
    "                        # predict using mixed teacher forcing\n",
    "                        for t in range(target_len):\n",
    "                            time = target_time_batch[t,:]\n",
    "                            decoder_output, decoder_hidden = self.predictor(decoder_input, time, decoder_hidden)\n",
    "                            \n",
    "                            #print('sayoooo')\n",
    "                            \n",
    "                            outputs[t] = decoder_output\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            # predict with teacher forcing\n",
    "                            if random.random() < teacher_forcing_ratio:\n",
    "                                decoder_input = target_batch[t, :, :]\n",
    "                            \n",
    "                            # predict recursively \n",
    "                            else:\n",
    "                                decoder_input = decoder_output\n",
    "\n",
    "                    # compute the loss \n",
    "                    loss = criterion(outputs, target_batch)\n",
    "                    #loss = torch.norm(outputs-target_batch)\n",
    "                    batch_loss += loss.item()\n",
    "                    \n",
    "                    # backpropagation\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # loss for epoch \n",
    "                batch_loss /= n_batches \n",
    "                losses[it] = batch_loss\n",
    "\n",
    "                # dynamic teacher forcing\n",
    "                if dynamic_tf and teacher_forcing_ratio > 0:\n",
    "                    teacher_forcing_ratio = teacher_forcing_ratio - 0.02 \n",
    "\n",
    "                # progress bar \n",
    "                tr.set_postfix(loss=\"{0:.10f}\".format(batch_loss))\n",
    "        \n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "                    \n",
    "        return losses\n",
    "    \n",
    "    def test(self, input_tensor, time_tensor, batch_size = 5, teacher_forcing_ratio = 0.6): # TEST AUTOENCODER\n",
    "        \n",
    "        score = 0\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        n_batches = int(input_tensor.shape[0] / batch_size)\n",
    "        \n",
    "        batch_loss = 0.\n",
    "\n",
    "        for b in range(n_batches):\n",
    "\n",
    "            input_batch = input_tensor[:, b: b + batch_size, :]\n",
    "\n",
    "            time_batch = time_tensor[:, b: b + batch_size]\n",
    "\n",
    "            target_batch = input_tensor[:, b: b + batch_size, :]\n",
    "\n",
    "            outputs = torch.zeros(input_tensor.shape[0], batch_size, input_tensor.shape[2])\n",
    "\n",
    "            encoder_hidden = self.encoder.init_hidden(batch_size)\n",
    "\n",
    "            encoder_output, encoder_hidden = self.encoder(input_batch, \n",
    "                                                          time_batch\n",
    "                                                         )\n",
    "\n",
    "            decoder_input = torch.ones(input_batch[-1,:,:].shape) \n",
    "\n",
    "            time = time_batch[0,:]\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            target_len = input_batch.shape[0] \n",
    "\n",
    "            for t in range(target_len): \n",
    "                time = time_batch[t,:]\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, time, decoder_hidden)\n",
    "                #print('hiiiiiiii')\n",
    "                outputs[t] = decoder_output\n",
    "\n",
    "                # predict with teacher forcing\n",
    "                if random.random() < teacher_forcing_ratio:\n",
    "                    decoder_input = target_batch[t, :, :]\n",
    "\n",
    "                # predict recursively \n",
    "                else:\n",
    "                    decoder_input = decoder_output\n",
    "\n",
    "            # compute the loss \n",
    "            \n",
    "            loss = criterion(outputs, target_batch) \n",
    "            #loss = torch.norm(outputs-target_batch)\n",
    "            \n",
    "            score += loss\n",
    "        \n",
    "        score /= n_batches\n",
    "                    \n",
    "        return score\n",
    "    \n",
    "    # predicts one at a time\n",
    "    \n",
    "    def predict(self, input_tensor, \n",
    "                time_tensor):\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        target_len = input_tensor.shape[0] # new modification\n",
    "        \n",
    "        # encode input_tensor\n",
    "        \n",
    "        input_tensor = input_tensor.unsqueeze(1)     # add in batch size of 1\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder(input_tensor, time_tensor)\n",
    "\n",
    "        # initialize tensor for predictions\n",
    "        outputs = torch.zeros(target_len, input_tensor.shape[2])\n",
    "\n",
    "        # decode input_tensor\n",
    "        decoder_input = torch.ones(input_tensor[-1,:,:].shape)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for t in range(target_len):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, time_tensor, decoder_hidden)\n",
    "            outputs[t] = decoder_output\n",
    "            decoder_input = decoder_output\n",
    "   \n",
    "        np_outputs = outputs.detach().numpy()\n",
    "\n",
    "        return np_outputs, encoder_hidden, criterion(outputs, input_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16dda607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 158859, 128])\n",
      "torch.Size([20, 158859])\n"
     ]
    }
   ],
   "source": [
    "print(torched_windowed_sequences.shape)\n",
    "print(torched_windowed_timestamps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cb1bb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addfasafsdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:02<00:00,  7.97it/s, loss=0.0000089115]\n"
     ]
    }
   ],
   "source": [
    "model = lstm_autoencoder(input_size = torched_windowed_sequences.shape[2], hidden_size = 16)\n",
    "\n",
    "loss = model.train_autoencoder(torched_windowed_sequences, \n",
    "                               torched_windowed_timestamps\n",
    "                  , n_epochs = 500\n",
    "                  , batch_size = 5\n",
    "                  , training_prediction = 'mixed_teacher_forcing' \n",
    "                  , teacher_forcing_ratio = 0.6\n",
    "                  , learning_rate = 0.01, dynamic_tf = False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fce609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027347211923704397"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(0.0000074787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for seq in torched_windowed_sequences:\n",
    "    for op in seq:\n",
    "        total += torch.sum(torch.abs(op)) / op.shape[0]\n",
    "\n",
    "score = total / (torched_windowed_sequences.shape[1] * torched_windowed_sequences.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)\n",
    "print(torched_windowed_sequences[0])\n",
    "print(torched_windowed_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4a099cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([80, 1, 128])) that is different to the input size (torch.Size([80, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([250, 1, 128])) that is different to the input size (torch.Size([250, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([7, 1, 128])) that is different to the input size (torch.Size([7, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([6, 1, 128])) that is different to the input size (torch.Size([6, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "0\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "1\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "2\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1664, 1, 128])) that is different to the input size (torch.Size([1664, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2671, grad_fn=<MseLossBackward0>)\n",
      "4\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([207, 1, 128])) that is different to the input size (torch.Size([207, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([637, 1, 128])) that is different to the input size (torch.Size([637, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([524, 1, 128])) that is different to the input size (torch.Size([524, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([12, 1, 128])) that is different to the input size (torch.Size([12, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "7\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "8\n",
      "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([257, 1, 128])) that is different to the input size (torch.Size([257, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([184, 1, 128])) that is different to the input size (torch.Size([184, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([34, 1, 128])) that is different to the input size (torch.Size([34, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "10\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "11\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([174, 1, 128])) that is different to the input size (torch.Size([174, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([267, 1, 128])) that is different to the input size (torch.Size([267, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10, 1, 128])) that is different to the input size (torch.Size([10, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "13\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "14\n",
      "tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([245, 1, 128])) that is different to the input size (torch.Size([245, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([49, 1, 128])) that is different to the input size (torch.Size([49, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([198, 1, 128])) that is different to the input size (torch.Size([198, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "16\n",
      "tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([322, 1, 128])) that is different to the input size (torch.Size([322, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([43, 1, 128])) that is different to the input size (torch.Size([43, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([199, 1, 128])) that is different to the input size (torch.Size([199, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2, 1, 128])) that is different to the input size (torch.Size([2, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "18\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "19\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "20\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "21\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([14, 1, 128])) that is different to the input size (torch.Size([14, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([28, 1, 128])) that is different to the input size (torch.Size([28, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([226, 1, 128])) that is different to the input size (torch.Size([226, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "23\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([380, 1, 128])) that is different to the input size (torch.Size([380, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 1, 128])) that is different to the input size (torch.Size([64, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([15, 1, 128])) that is different to the input size (torch.Size([15, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21, 1, 128])) that is different to the input size (torch.Size([21, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([5, 1, 128])) that is different to the input size (torch.Size([5, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "25\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "26\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "27\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "28\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "29\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([635, 1, 128])) that is different to the input size (torch.Size([635, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([51, 1, 128])) that is different to the input size (torch.Size([51, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([58, 1, 128])) that is different to the input size (torch.Size([58, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "31\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "32\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "33\n",
      "tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "34\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([83, 1, 128])) that is different to the input size (torch.Size([83, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([554, 1, 128])) that is different to the input size (torch.Size([554, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([18, 1, 128])) that is different to the input size (torch.Size([18, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([66, 1, 128])) that is different to the input size (torch.Size([66, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "36\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "37\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1041, 1, 128])) that is different to the input size (torch.Size([1041, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "39\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "40\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([95, 1, 128])) that is different to the input size (torch.Size([95, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([79, 1, 128])) that is different to the input size (torch.Size([79, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1155, 1, 128])) that is different to the input size (torch.Size([1155, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "42\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "43\n",
      "tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "44\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([45, 1, 128])) that is different to the input size (torch.Size([45, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([78, 1, 128])) that is different to the input size (torch.Size([78, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([8, 1, 128])) that is different to the input size (torch.Size([8, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([242, 1, 128])) that is different to the input size (torch.Size([242, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([121, 1, 128])) that is different to the input size (torch.Size([121, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "46\n",
      "tensor(0.1144, grad_fn=<MseLossBackward0>)\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([795, 1, 128])) that is different to the input size (torch.Size([795, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "48\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([164, 1, 128])) that is different to the input size (torch.Size([164, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([229, 1, 128])) that is different to the input size (torch.Size([229, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([352, 1, 128])) that is different to the input size (torch.Size([352, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([320, 1, 128])) that is different to the input size (torch.Size([320, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([147, 1, 128])) that is different to the input size (torch.Size([147, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([42, 1, 128])) that is different to the input size (torch.Size([42, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "52\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "53\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([337, 1, 128])) that is different to the input size (torch.Size([337, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([163, 1, 128])) that is different to the input size (torch.Size([163, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "55\n",
      "tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "56\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([801, 1, 128])) that is different to the input size (torch.Size([801, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "58\n",
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([120, 1, 128])) that is different to the input size (torch.Size([120, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([240, 1, 128])) that is different to the input size (torch.Size([240, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([504, 1, 128])) that is different to the input size (torch.Size([504, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([29, 1, 128])) that is different to the input size (torch.Size([29, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "61\n",
      "tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([284, 1, 128])) that is different to the input size (torch.Size([284, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([578, 1, 128])) that is different to the input size (torch.Size([578, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "64\n",
      "tensor(0.2789, grad_fn=<MseLossBackward0>)\n",
      "65\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "66\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([173, 1, 128])) that is different to the input size (torch.Size([173, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "68\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "69\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "70\n",
      "tensor(0.1128, grad_fn=<MseLossBackward0>)\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([141, 1, 128])) that is different to the input size (torch.Size([141, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([219, 1, 128])) that is different to the input size (torch.Size([219, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([81, 1, 128])) that is different to the input size (torch.Size([81, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "72\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "73\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([365, 1, 128])) that is different to the input size (torch.Size([365, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([50, 1, 128])) that is different to the input size (torch.Size([50, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1464, grad_fn=<MseLossBackward0>)\n",
      "75\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "76\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1684, 1, 128])) that is different to the input size (torch.Size([1684, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "78\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "79\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([109, 1, 128])) that is different to the input size (torch.Size([109, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([383, 1, 128])) that is different to the input size (torch.Size([383, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([111, 1, 128])) that is different to the input size (torch.Size([111, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2272, grad_fn=<MseLossBackward0>)\n",
      "81\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([272, 1, 128])) that is different to the input size (torch.Size([272, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([9, 1, 128])) that is different to the input size (torch.Size([9, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([54, 1, 128])) that is different to the input size (torch.Size([54, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([85, 1, 128])) that is different to the input size (torch.Size([85, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "83\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "84\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "85\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "86\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "87\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([166, 1, 128])) that is different to the input size (torch.Size([166, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([378, 1, 128])) that is different to the input size (torch.Size([378, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([13, 1, 128])) that is different to the input size (torch.Size([13, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "90\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "91\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "92\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "93\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "94\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([202, 1, 128])) that is different to the input size (torch.Size([202, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([448, 1, 128])) that is different to the input size (torch.Size([448, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([108, 1, 128])) that is different to the input size (torch.Size([108, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "96\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "97\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "98\n",
      "tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([208, 1, 128])) that is different to the input size (torch.Size([208, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([876, 1, 128])) that is different to the input size (torch.Size([876, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "101\n",
      "tensor(0.1791, grad_fn=<MseLossBackward0>)\n",
      "102\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([168, 1, 128])) that is different to the input size (torch.Size([168, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([122, 1, 128])) that is different to the input size (torch.Size([122, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1215, grad_fn=<MseLossBackward0>)\n",
      "104\n",
      "tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "105\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([100, 1, 128])) that is different to the input size (torch.Size([100, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([214, 1, 128])) that is different to the input size (torch.Size([214, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([814, 1, 128])) that is different to the input size (torch.Size([814, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([52, 1, 128])) that is different to the input size (torch.Size([52, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "108\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([333, 1, 128])) that is different to the input size (torch.Size([333, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([26, 1, 128])) that is different to the input size (torch.Size([26, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1779, grad_fn=<MseLossBackward0>)\n",
      "110\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "111\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "112\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([265, 1, 128])) that is different to the input size (torch.Size([265, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([129, 1, 128])) that is different to the input size (torch.Size([129, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "115\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([683, 1, 128])) that is different to the input size (torch.Size([683, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([48, 1, 128])) that is different to the input size (torch.Size([48, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "117\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "118\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "119\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "120\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([134, 1, 128])) that is different to the input size (torch.Size([134, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([334, 1, 128])) that is different to the input size (torch.Size([334, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "122\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "123\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([27, 1, 128])) that is different to the input size (torch.Size([27, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([283, 1, 128])) that is different to the input size (torch.Size([283, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "125\n",
      "tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "126\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "127\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "128\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "129\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1, 128])) that is different to the input size (torch.Size([32, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([178, 1, 128])) that is different to the input size (torch.Size([178, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([363, 1, 128])) that is different to the input size (torch.Size([363, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([119, 1, 128])) that is different to the input size (torch.Size([119, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([20, 1, 128])) that is different to the input size (torch.Size([20, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([77, 1, 128])) that is different to the input size (torch.Size([77, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([17, 1, 128])) that is different to the input size (torch.Size([17, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "131\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "132\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "133\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "134\n",
      "tensor(0.1814, grad_fn=<MseLossBackward0>)\n",
      "135\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "136\n",
      "tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "137\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "138\n",
      "tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "139\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "140\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "141\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([482, 1, 128])) that is different to the input size (torch.Size([482, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([24, 1, 128])) that is different to the input size (torch.Size([24, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([46, 1, 128])) that is different to the input size (torch.Size([46, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "143\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "144\n",
      "tensor(0.1567, grad_fn=<MseLossBackward0>)\n",
      "145\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "146\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "147\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "148\n",
      "tensor(0.1551, grad_fn=<MseLossBackward0>)\n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([180, 1, 128])) that is different to the input size (torch.Size([180, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([183, 1, 128])) that is different to the input size (torch.Size([183, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "150\n",
      "tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "151\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([515, 1, 128])) that is different to the input size (torch.Size([515, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([195, 1, 128])) that is different to the input size (torch.Size([195, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "153\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "154\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "155\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "156\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "157\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "158\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([41, 1, 128])) that is different to the input size (torch.Size([41, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([31, 1, 128])) that is different to the input size (torch.Size([31, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "160\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([798, 1, 128])) that is different to the input size (torch.Size([798, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([25, 1, 128])) that is different to the input size (torch.Size([25, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "162\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "163\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "164\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([205, 1, 128])) that is different to the input size (torch.Size([205, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([225, 1, 128])) that is different to the input size (torch.Size([225, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "166\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "167\n",
      "tensor(0.2960, grad_fn=<MseLossBackward0>)\n",
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([145, 1, 128])) that is different to the input size (torch.Size([145, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([517, 1, 128])) that is different to the input size (torch.Size([517, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([361, 1, 128])) that is different to the input size (torch.Size([361, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "170\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([990, 1, 128])) that is different to the input size (torch.Size([990, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "172\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([253, 1, 128])) that is different to the input size (torch.Size([253, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([63, 1, 128])) that is different to the input size (torch.Size([63, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "174\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2129, 1, 128])) that is different to the input size (torch.Size([2129, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "176\n",
      "tensor(0.2757, grad_fn=<MseLossBackward0>)\n",
      "177\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "178\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([19, 1, 128])) that is different to the input size (torch.Size([19, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([104, 1, 128])) that is different to the input size (torch.Size([104, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([40, 1, 128])) that is different to the input size (torch.Size([40, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([116, 1, 128])) that is different to the input size (torch.Size([116, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "180\n",
      "tensor(0.1641, grad_fn=<MseLossBackward0>)\n",
      "181\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "182\n",
      "tensor(0.2148, grad_fn=<MseLossBackward0>)\n",
      "183\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "184\n",
      "tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "185\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "186\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "187\n",
      "tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "188\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "189\n",
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 1, 128])) that is different to the input size (torch.Size([4, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([75, 1, 128])) that is different to the input size (torch.Size([75, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([285, 1, 128])) that is different to the input size (torch.Size([285, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([30, 1, 128])) that is different to the input size (torch.Size([30, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "191\n",
      "tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "192\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "193\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([377, 1, 128])) that is different to the input size (torch.Size([377, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([11, 1, 128])) that is different to the input size (torch.Size([11, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "195\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "196\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([306, 1, 128])) that is different to the input size (torch.Size([306, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([23, 1, 128])) that is different to the input size (torch.Size([23, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([56, 1, 128])) that is different to the input size (torch.Size([56, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([144, 1, 128])) that is different to the input size (torch.Size([144, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "198\n",
      "tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "199\n",
      "tensor(0.1675, grad_fn=<MseLossBackward0>)\n",
      "200\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "201\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "202\n",
      "tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([112, 1, 128])) that is different to the input size (torch.Size([112, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([67, 1, 128])) that is different to the input size (torch.Size([67, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1485, grad_fn=<MseLossBackward0>)\n",
      "204\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "205\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "206\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([358, 1, 128])) that is different to the input size (torch.Size([358, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "208\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "209\n",
      "tensor(0.1209, grad_fn=<MseLossBackward0>)\n",
      "210\n",
      "tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "211\n",
      "tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "212\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([387, 1, 128])) that is different to the input size (torch.Size([387, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([231, 1, 128])) that is different to the input size (torch.Size([231, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "214\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "215\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "216\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "217\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([750, 1, 128])) that is different to the input size (torch.Size([750, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([68, 1, 128])) that is different to the input size (torch.Size([68, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "219\n",
      "tensor(0.1992, grad_fn=<MseLossBackward0>)\n",
      "220\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "221\n",
      "tensor(0.3186, grad_fn=<MseLossBackward0>)\n",
      "222\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "223\n",
      "tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "224\n",
      "tensor(0.2626, grad_fn=<MseLossBackward0>)\n",
      "225\n",
      "tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
      "226\n",
      "tensor(0.1807, grad_fn=<MseLossBackward0>)\n",
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([110, 1, 128])) that is different to the input size (torch.Size([110, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([179, 1, 128])) that is different to the input size (torch.Size([179, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "228\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "229\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([84, 1, 128])) that is different to the input size (torch.Size([84, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([286, 1, 128])) that is different to the input size (torch.Size([286, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "231\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "232\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "233\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "234\n",
      "tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "235\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "236\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "237\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([218, 1, 128])) that is different to the input size (torch.Size([218, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([106, 1, 128])) that is different to the input size (torch.Size([106, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "239\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "240\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "241\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "242\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "243\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "244\n",
      "tensor(0.2449, grad_fn=<MseLossBackward0>)\n",
      "245\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "246\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "247\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([396, 1, 128])) that is different to the input size (torch.Size([396, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16, 1, 128])) that is different to the input size (torch.Size([16, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([203, 1, 128])) that is different to the input size (torch.Size([203, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "249\n",
      "tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "250\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "251\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "252\n",
      "tensor(0.1191, grad_fn=<MseLossBackward0>)\n",
      "253\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "254\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([332, 1, 128])) that is different to the input size (torch.Size([332, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "256\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([420, 1, 128])) that is different to the input size (torch.Size([420, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "258\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "259\n",
      "tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "260\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "261\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([298, 1, 128])) that is different to the input size (torch.Size([298, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([246, 1, 128])) that is different to the input size (torch.Size([246, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "263\n",
      "tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "264\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "265\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "266\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "267\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "268\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([103, 1, 128])) that is different to the input size (torch.Size([103, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([57, 1, 128])) that is different to the input size (torch.Size([57, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([96, 1, 128])) that is different to the input size (torch.Size([96, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "270\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "271\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "272\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "273\n",
      "tensor(0.1334, grad_fn=<MseLossBackward0>)\n",
      "274\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([416, 1, 128])) that is different to the input size (torch.Size([416, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([252, 1, 128])) that is different to the input size (torch.Size([252, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "276\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([69, 1, 128])) that is different to the input size (torch.Size([69, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([44, 1, 128])) that is different to the input size (torch.Size([44, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([197, 1, 128])) that is different to the input size (torch.Size([197, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "278\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "279\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([87, 1, 128])) that is different to the input size (torch.Size([87, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "281\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([374, 1, 128])) that is different to the input size (torch.Size([374, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "283\n",
      "tensor(0.1728, grad_fn=<MseLossBackward0>)\n",
      "284\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([566, 1, 128])) that is different to the input size (torch.Size([566, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([60, 1, 128])) that is different to the input size (torch.Size([60, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "286\n",
      "tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([244, 1, 128])) that is different to the input size (torch.Size([244, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "288\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "289\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([330, 1, 128])) that is different to the input size (torch.Size([330, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([37, 1, 128])) that is different to the input size (torch.Size([37, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "291\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "292\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "293\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "294\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "295\n",
      "tensor(0.1869, grad_fn=<MseLossBackward0>)\n",
      "296\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([170, 1, 128])) that is different to the input size (torch.Size([170, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "298\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "299\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "300\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "301\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "302\n",
      "tensor(0.1922, grad_fn=<MseLossBackward0>)\n",
      "303\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([230, 1, 128])) that is different to the input size (torch.Size([230, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([47, 1, 128])) that is different to the input size (torch.Size([47, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35, 1, 128])) that is different to the input size (torch.Size([35, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([190, 1, 128])) that is different to the input size (torch.Size([190, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1573, grad_fn=<MseLossBackward0>)\n",
      "305\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "306\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "307\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "308\n",
      "tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "309\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "310\n",
      "tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "311\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "312\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "313\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "314\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "315\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "316\n",
      "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([72, 1, 128])) that is different to the input size (torch.Size([72, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([167, 1, 128])) that is different to the input size (torch.Size([167, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([323, 1, 128])) that is different to the input size (torch.Size([323, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([132, 1, 128])) that is different to the input size (torch.Size([132, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "318\n",
      "tensor(0.2523, grad_fn=<MseLossBackward0>)\n",
      "319\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "320\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "321\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([215, 1, 128])) that is different to the input size (torch.Size([215, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([263, 1, 128])) that is different to the input size (torch.Size([263, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "323\n",
      "tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "324\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "325\n",
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([897, 1, 128])) that is different to the input size (torch.Size([897, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "327\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "328\n",
      "tensor(0.2397, grad_fn=<MseLossBackward0>)\n",
      "329\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([105, 1, 128])) that is different to the input size (torch.Size([105, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "331\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "332\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "333\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "334\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([276, 1, 128])) that is different to the input size (torch.Size([276, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([33, 1, 128])) that is different to the input size (torch.Size([33, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "336\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "337\n",
      "tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "338\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "339\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "340\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "341\n",
      "tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "342\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "343\n",
      "tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([318, 1, 128])) that is different to the input size (torch.Size([318, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "345\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([59, 1, 128])) that is different to the input size (torch.Size([59, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "347\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "348\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "349\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "350\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "351\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "352\n",
      "tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "353\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "354\n",
      "tensor(0.1980, grad_fn=<MseLossBackward0>)\n",
      "355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([74, 1, 128])) that is different to the input size (torch.Size([74, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([126, 1, 128])) that is different to the input size (torch.Size([126, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([92, 1, 128])) that is different to the input size (torch.Size([92, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "356\n",
      "tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "357\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([70, 1, 128])) that is different to the input size (torch.Size([70, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2041, 1, 128])) that is different to the input size (torch.Size([2041, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "359\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "360\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "361\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "362\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "363\n",
      "tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "364\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "365\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([137, 1, 128])) that is different to the input size (torch.Size([137, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([444, 1, 128])) that is different to the input size (torch.Size([444, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([3, 1, 128])) that is different to the input size (torch.Size([3, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "368\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "369\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "370\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "371\n",
      "tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "372\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "373\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "374\n",
      "tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "375\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "376\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "377\n",
      "tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([114, 1, 128])) that is different to the input size (torch.Size([114, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "379\n",
      "tensor(0.1723, grad_fn=<MseLossBackward0>)\n",
      "380\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "381\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([139, 1, 128])) that is different to the input size (torch.Size([139, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([91, 1, 128])) that is different to the input size (torch.Size([91, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "383\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "384\n",
      "tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "385\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "386\n",
      "tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "387\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "388\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "389\n",
      "tensor(0.1189, grad_fn=<MseLossBackward0>)\n",
      "390\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "391\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "392\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "393\n",
      "tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "394\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "395\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "396\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "397\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "398\n",
      "tensor(0.2675, grad_fn=<MseLossBackward0>)\n",
      "399\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "400\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "401\n",
      "tensor(0.1360, grad_fn=<MseLossBackward0>)\n",
      "402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([38, 1, 128])) that is different to the input size (torch.Size([38, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 1, 128])) that is different to the input size (torch.Size([256, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "403\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "404\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "405\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "406\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "407\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "408\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "409\n",
      "tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([234, 1, 128])) that is different to the input size (torch.Size([234, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "411\n",
      "tensor(0.1631, grad_fn=<MseLossBackward0>)\n",
      "412\n",
      "tensor(0.1551, grad_fn=<MseLossBackward0>)\n",
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([468, 1, 128])) that is different to the input size (torch.Size([468, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "414\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([266, 1, 128])) that is different to the input size (torch.Size([266, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "416\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "417\n",
      "tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "418\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([889, 1, 128])) that is different to the input size (torch.Size([889, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "420\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "421\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "422\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "423\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([93, 1, 128])) that is different to the input size (torch.Size([93, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([217, 1, 128])) that is different to the input size (torch.Size([217, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "425\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "426\n",
      "tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([321, 1, 128])) that is different to the input size (torch.Size([321, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([489, 1, 128])) that is different to the input size (torch.Size([489, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([345, 1, 128])) that is different to the input size (torch.Size([345, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([271, 1, 128])) that is different to the input size (torch.Size([271, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "430\n",
      "tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "431\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "432\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "433\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "434\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "435\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "436\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([53, 1, 128])) that is different to the input size (torch.Size([53, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "438\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "439\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "440\n",
      "tensor(0.1786, grad_fn=<MseLossBackward0>)\n",
      "441\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "442\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "443\n",
      "tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "444\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([187, 1, 128])) that is different to the input size (torch.Size([187, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([99, 1, 128])) that is different to the input size (torch.Size([99, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3263, grad_fn=<MseLossBackward0>)\n",
      "446\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "447\n",
      "tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "448\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "449\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "450\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "451\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "452\n",
      "tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "453\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "454\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "455\n",
      "tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "456\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([724, 1, 128])) that is different to the input size (torch.Size([724, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1379, grad_fn=<MseLossBackward0>)\n",
      "458\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "459\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "460\n",
      "tensor(0.1348, grad_fn=<MseLossBackward0>)\n",
      "461\n",
      "tensor(0.2148, grad_fn=<MseLossBackward0>)\n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([596, 1, 128])) that is different to the input size (torch.Size([596, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "463\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "464\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "465\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([367, 1, 128])) that is different to the input size (torch.Size([367, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([82, 1, 128])) that is different to the input size (torch.Size([82, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "467\n",
      "tensor(0.1807, grad_fn=<MseLossBackward0>)\n",
      "468\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "469\n",
      "tensor(0.0980, grad_fn=<MseLossBackward0>)\n",
      "470\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "471\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "472\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([22, 1, 128])) that is different to the input size (torch.Size([22, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([525, 1, 128])) that is different to the input size (torch.Size([525, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([162, 1, 128])) that is different to the input size (torch.Size([162, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "474\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "475\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "476\n",
      "tensor(0.1917, grad_fn=<MseLossBackward0>)\n",
      "477\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "478\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([247, 1, 128])) that is different to the input size (torch.Size([247, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "480\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "481\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "482\n",
      "tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
      "483\n",
      "tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "484\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "485\n",
      "tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "486\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "487\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "488\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4707, 1, 128])) that is different to the input size (torch.Size([4707, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1671, grad_fn=<MseLossBackward0>)\n",
      "490\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "491\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([210, 1, 128])) that is different to the input size (torch.Size([210, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([602, 1, 128])) that is different to the input size (torch.Size([602, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "493\n",
      "tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([698, 1, 128])) that is different to the input size (torch.Size([698, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([65, 1, 128])) that is different to the input size (torch.Size([65, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "495\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "496\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "497\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "498\n",
      "tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
      "499\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "500\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "501\n",
      "tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "502\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "503\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "504\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "505\n",
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "506\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "507\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([90, 1, 128])) that is different to the input size (torch.Size([90, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "509\n",
      "tensor(0.1947, grad_fn=<MseLossBackward0>)\n",
      "510\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "511\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "512\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "513\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([239, 1, 128])) that is different to the input size (torch.Size([239, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([533, 1, 128])) that is different to the input size (torch.Size([533, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "516\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "517\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "518\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "519\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([249, 1, 128])) that is different to the input size (torch.Size([249, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([98, 1, 128])) that is different to the input size (torch.Size([98, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "521\n",
      "tensor(0.1557, grad_fn=<MseLossBackward0>)\n",
      "522\n",
      "tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "523\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "524\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "525\n",
      "tensor(0.2167, grad_fn=<MseLossBackward0>)\n",
      "526\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "527\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "528\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "529\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "530\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "531\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "532\n",
      "tensor(0.2414, grad_fn=<MseLossBackward0>)\n",
      "533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([101, 1, 128])) that is different to the input size (torch.Size([101, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1242, 1, 128])) that is different to the input size (torch.Size([1242, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "534\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "535\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "536\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "537\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "538\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "539\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "540\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "541\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "542\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "543\n",
      "tensor(0.1625, grad_fn=<MseLossBackward0>)\n",
      "544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([273, 1, 128])) that is different to the input size (torch.Size([273, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([36, 1, 128])) that is different to the input size (torch.Size([36, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "545\n",
      "tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "546\n",
      "tensor(0.1171, grad_fn=<MseLossBackward0>)\n",
      "547\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "548\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "549\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "550\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "551\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "552\n",
      "tensor(0.2198, grad_fn=<MseLossBackward0>)\n",
      "553\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "554\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "555\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([424, 1, 128])) that is different to the input size (torch.Size([424, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "557\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "558\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "559\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "560\n",
      "tensor(0.1863, grad_fn=<MseLossBackward0>)\n",
      "561\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "562\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "563\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "564\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "565\n",
      "tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "566\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "567\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "568\n",
      "tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([523, 1, 128])) that is different to the input size (torch.Size([523, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([89, 1, 128])) that is different to the input size (torch.Size([89, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "570\n",
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "571\n",
      "tensor(0.1675, grad_fn=<MseLossBackward0>)\n",
      "572\n",
      "tensor(0.1672, grad_fn=<MseLossBackward0>)\n",
      "573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([177, 1, 128])) that is different to the input size (torch.Size([177, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([191, 1, 128])) that is different to the input size (torch.Size([191, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "574\n",
      "tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "575\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "576\n",
      "tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "577\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "578\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "579\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "580\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "581\n",
      "tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([394, 1, 128])) that is different to the input size (torch.Size([394, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "583\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([728, 1, 128])) that is different to the input size (torch.Size([728, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "585\n",
      "tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "586\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "587\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "588\n",
      "tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "589\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "590\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "591\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "592\n",
      "tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "593\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "594\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "595\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "596\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "597\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "598\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "599\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "600\n",
      "tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "601\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "602\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "603\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "604\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([165, 1, 128])) that is different to the input size (torch.Size([165, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([152, 1, 128])) that is different to the input size (torch.Size([152, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "606\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "607\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "608\n",
      "tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "609\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "610\n",
      "tensor(0.1585, grad_fn=<MseLossBackward0>)\n",
      "611\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "612\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "613\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "614\n",
      "tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "615\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([39, 1, 128])) that is different to the input size (torch.Size([39, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([61, 1, 128])) that is different to the input size (torch.Size([61, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "617\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "618\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "619\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "620\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "621\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "622\n",
      "tensor(0.1710, grad_fn=<MseLossBackward0>)\n",
      "623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([182, 1, 128])) that is different to the input size (torch.Size([182, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "624\n",
      "tensor(0.1709, grad_fn=<MseLossBackward0>)\n",
      "625\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "626\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "627\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "628\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "629\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "630\n",
      "tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "631\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([287, 1, 128])) that is different to the input size (torch.Size([287, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "633\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "634\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "635\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "636\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "637\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "638\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "639\n",
      "tensor(0.1683, grad_fn=<MseLossBackward0>)\n",
      "640\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "641\n",
      "tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "642\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "643\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "644\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "645\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "646\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([391, 1, 128])) that is different to the input size (torch.Size([391, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "648\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "649\n",
      "tensor(0.1253, grad_fn=<MseLossBackward0>)\n",
      "650\n",
      "tensor(0.1876, grad_fn=<MseLossBackward0>)\n",
      "651\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "652\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "653\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([185, 1, 128])) that is different to the input size (torch.Size([185, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([319, 1, 128])) that is different to the input size (torch.Size([319, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([113, 1, 128])) that is different to the input size (torch.Size([113, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "655\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "656\n",
      "tensor(0.1317, grad_fn=<MseLossBackward0>)\n",
      "657\n",
      "tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "658\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([55, 1, 128])) that is different to the input size (torch.Size([55, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([248, 1, 128])) that is different to the input size (torch.Size([248, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "660\n",
      "tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "661\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "662\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "663\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([115, 1, 128])) that is different to the input size (torch.Size([115, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([264, 1, 128])) that is different to the input size (torch.Size([264, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "665\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "666\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "667\n",
      "tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "668\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([316, 1, 128])) that is different to the input size (torch.Size([316, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([125, 1, 128])) that is different to the input size (torch.Size([125, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "670\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "671\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "672\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "673\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "674\n",
      "tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "675\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "676\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "677\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([506, 1, 128])) that is different to the input size (torch.Size([506, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "679\n",
      "tensor(0.1928, grad_fn=<MseLossBackward0>)\n",
      "680\n",
      "tensor(0.1588, grad_fn=<MseLossBackward0>)\n",
      "681\n",
      "tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
      "682\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "683\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "684\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "685\n",
      "tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "686\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "687\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "688\n",
      "tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "689\n",
      "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "690\n",
      "tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "691\n",
      "tensor(0.1397, grad_fn=<MseLossBackward0>)\n",
      "692\n",
      "tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "693\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "694\n",
      "tensor(0.2123, grad_fn=<MseLossBackward0>)\n",
      "695\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "696\n",
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "697\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "698\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "699\n",
      "tensor(0.1928, grad_fn=<MseLossBackward0>)\n",
      "700\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([142, 1, 128])) that is different to the input size (torch.Size([142, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "702\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "703\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([138, 1, 128])) that is different to the input size (torch.Size([138, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "705\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "706\n",
      "tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "707\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "708\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "709\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "710\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "711\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "712\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "713\n",
      "tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
      "714\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "715\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "716\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "717\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "718\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "719\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "720\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "721\n",
      "tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "722\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "723\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1303, 1, 128])) that is different to the input size (torch.Size([1303, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "725\n",
      "tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "726\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "727\n",
      "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "728\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "729\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([88, 1, 128])) that is different to the input size (torch.Size([88, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([455, 1, 128])) that is different to the input size (torch.Size([455, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1642, grad_fn=<MseLossBackward0>)\n",
      "731\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "732\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "733\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "734\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([346, 1, 128])) that is different to the input size (torch.Size([346, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "736\n",
      "tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
      "737\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "738\n",
      "tensor(0.2002, grad_fn=<MseLossBackward0>)\n",
      "739\n",
      "tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "740\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "741\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "742\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "743\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "744\n",
      "tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "745\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "746\n",
      "tensor(0.1377, grad_fn=<MseLossBackward0>)\n",
      "747\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "748\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([143, 1, 128])) that is different to the input size (torch.Size([143, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([726, 1, 128])) that is different to the input size (torch.Size([726, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1396, grad_fn=<MseLossBackward0>)\n",
      "750\n",
      "tensor(0.1946, grad_fn=<MseLossBackward0>)\n",
      "751\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "752\n",
      "tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "753\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "754\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "755\n",
      "tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "756\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "757\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "758\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "759\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "760\n",
      "tensor(0.1354, grad_fn=<MseLossBackward0>)\n",
      "761\n",
      "tensor(0.1115, grad_fn=<MseLossBackward0>)\n",
      "762\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "763\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "764\n",
      "tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "765\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "766\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([188, 1, 128])) that is different to the input size (torch.Size([188, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1545, grad_fn=<MseLossBackward0>)\n",
      "768\n",
      "tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "769\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "770\n",
      "tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "771\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "772\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "773\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "774\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "775\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "776\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "777\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([169, 1, 128])) that is different to the input size (torch.Size([169, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([151, 1, 128])) that is different to the input size (torch.Size([151, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "779\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "780\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "781\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "782\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "783\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "784\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "785\n",
      "tensor(0.4326, grad_fn=<MseLossBackward0>)\n",
      "786\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "787\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "788\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "789\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([243, 1, 128])) that is different to the input size (torch.Size([243, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([130, 1, 128])) that is different to the input size (torch.Size([130, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "791\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "792\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "793\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "794\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "795\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "796\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "797\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "798\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "799\n",
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "800\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "801\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "802\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "803\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "804\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "805\n",
      "tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "806\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "807\n",
      "tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "808\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "809\n",
      "tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([902, 1, 128])) that is different to the input size (torch.Size([902, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "811\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "812\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "813\n",
      "tensor(0.1670, grad_fn=<MseLossBackward0>)\n",
      "814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([212, 1, 128])) that is different to the input size (torch.Size([212, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([194, 1, 128])) that is different to the input size (torch.Size([194, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "815\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "816\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "817\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "818\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "819\n",
      "tensor(0.1577, grad_fn=<MseLossBackward0>)\n",
      "820\n",
      "tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "821\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "822\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "823\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "824\n",
      "tensor(0.2435, grad_fn=<MseLossBackward0>)\n",
      "825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([845, 1, 128])) that is different to the input size (torch.Size([845, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "826\n",
      "tensor(0.2073, grad_fn=<MseLossBackward0>)\n",
      "827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([331, 1, 128])) that is different to the input size (torch.Size([331, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "828\n",
      "tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "829\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "830\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "831\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "832\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "833\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "834\n",
      "tensor(0.5512, grad_fn=<MseLossBackward0>)\n",
      "835\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([703, 1, 128])) that is different to the input size (torch.Size([703, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([574, 1, 128])) that is different to the input size (torch.Size([574, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "838\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "839\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "840\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "841\n",
      "tensor(0.2098, grad_fn=<MseLossBackward0>)\n",
      "842\n",
      "tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
      "843\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "844\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "845\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "846\n",
      "tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "847\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "848\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "849\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "850\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([201, 1, 128])) that is different to the input size (torch.Size([201, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1632, grad_fn=<MseLossBackward0>)\n",
      "852\n",
      "tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "853\n",
      "tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "854\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "855\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "856\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "857\n",
      "tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "858\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "859\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "860\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "861\n",
      "tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "862\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "863\n",
      "tensor(0.1544, grad_fn=<MseLossBackward0>)\n",
      "864\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "865\n",
      "tensor(0.1899, grad_fn=<MseLossBackward0>)\n",
      "866\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "867\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([154, 1, 128])) that is different to the input size (torch.Size([154, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1812, grad_fn=<MseLossBackward0>)\n",
      "869\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "870\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([435, 1, 128])) that is different to the input size (torch.Size([435, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([135, 1, 128])) that is different to the input size (torch.Size([135, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "872\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "873\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "874\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "875\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "876\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "877\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "878\n",
      "tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "879\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "880\n",
      "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "881\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "882\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "883\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "884\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "885\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([453, 1, 128])) that is different to the input size (torch.Size([453, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "887\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "888\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "889\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "890\n",
      "tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "891\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "892\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "893\n",
      "tensor(0.1237, grad_fn=<MseLossBackward0>)\n",
      "894\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "895\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "896\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "897\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "898\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "899\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "900\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "901\n",
      "tensor(0.1532, grad_fn=<MseLossBackward0>)\n",
      "902\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "903\n",
      "tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "904\n",
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "905\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "906\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "907\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "908\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "909\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "910\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "911\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "912\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([156, 1, 128])) that is different to the input size (torch.Size([156, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([131, 1, 128])) that is different to the input size (torch.Size([131, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "914\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "915\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "916\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "917\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "918\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "919\n",
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "920\n",
      "tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "921\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "922\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([117, 1, 128])) that is different to the input size (torch.Size([117, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "924\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "925\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "926\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "927\n",
      "tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([149, 1, 128])) that is different to the input size (torch.Size([149, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "929\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "930\n",
      "tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "931\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "932\n",
      "tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "933\n",
      "tensor(0.2138, grad_fn=<MseLossBackward0>)\n",
      "934\n",
      "tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "935\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "936\n",
      "tensor(0.1496, grad_fn=<MseLossBackward0>)\n",
      "937\n",
      "tensor(0.1469, grad_fn=<MseLossBackward0>)\n",
      "938\n",
      "tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "939\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "940\n",
      "tensor(0.2103, grad_fn=<MseLossBackward0>)\n",
      "941\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "942\n",
      "tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "943\n",
      "tensor(0.1991, grad_fn=<MseLossBackward0>)\n",
      "944\n",
      "tensor(0.2246, grad_fn=<MseLossBackward0>)\n",
      "945\n",
      "tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "946\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "947\n",
      "tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "948\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "949\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "950\n",
      "tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "951\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "952\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "953\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "954\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "955\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "956\n",
      "tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "957\n",
      "tensor(0.1756, grad_fn=<MseLossBackward0>)\n",
      "958\n",
      "tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "959\n",
      "tensor(0.0980, grad_fn=<MseLossBackward0>)\n",
      "960\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "961\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "962\n",
      "tensor(0.1806, grad_fn=<MseLossBackward0>)\n",
      "963\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "964\n",
      "tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "965\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([237, 1, 128])) that is different to the input size (torch.Size([237, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "967\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "968\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "969\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "970\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "971\n",
      "tensor(0.1915, grad_fn=<MseLossBackward0>)\n",
      "972\n",
      "tensor(0.1345, grad_fn=<MseLossBackward0>)\n",
      "973\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "974\n",
      "tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "975\n",
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "976\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "977\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "978\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "979\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "980\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "981\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "982\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "983\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "984\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "985\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "986\n",
      "tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "987\n",
      "tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([211, 1, 128])) that is different to the input size (torch.Size([211, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "989\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "990\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "991\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "992\n",
      "tensor(0.2530, grad_fn=<MseLossBackward0>)\n",
      "993\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "994\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "995\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "996\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "997\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "998\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "999\n",
      "tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "1000\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "1001\n",
      "tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "1002\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "1003\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "1004\n",
      "tensor(0.2104, grad_fn=<MseLossBackward0>)\n",
      "1005\n",
      "tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "1006\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "1007\n",
      "tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "1008\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "1009\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "1010\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "1011\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "1012\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "1013\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "1014\n",
      "tensor(0.1766, grad_fn=<MseLossBackward0>)\n",
      "1015\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128, 1, 128])) that is different to the input size (torch.Size([128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "1017\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "1018\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "1019\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "1020\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "1021\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "1022\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "1023\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "1024\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "1025\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "1026\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "1027\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "1028\n",
      "tensor(0.1953, grad_fn=<MseLossBackward0>)\n",
      "1029\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "1030\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "1031\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "1032\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "1033\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "1034\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "1035\n",
      "tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "1036\n",
      "tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "1037\n",
      "tensor(0.1365, grad_fn=<MseLossBackward0>)\n",
      "1038\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "1039\n",
      "tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "1040\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([404, 1, 128])) that is different to the input size (torch.Size([404, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "1042\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "1043\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([475, 1, 128])) that is different to the input size (torch.Size([475, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "1045\n",
      "tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "1046\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "1047\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1718, 1, 128])) that is different to the input size (torch.Size([1718, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "1049\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "1050\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "1051\n",
      "tensor(0.1860, grad_fn=<MseLossBackward0>)\n",
      "1052\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "1053\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "1054\n",
      "tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "1055\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "1056\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "1057\n",
      "tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "1058\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "1059\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "1060\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "1061\n",
      "tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "1062\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1063\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "1064\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "1065\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "1066\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([259, 1, 128])) that is different to the input size (torch.Size([259, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "1068\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "1069\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "1070\n",
      "tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "1071\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "1072\n",
      "tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "1073\n",
      "tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "1074\n",
      "tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "1075\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "1076\n",
      "tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "1077\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "1078\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "1079\n",
      "tensor(0.2577, grad_fn=<MseLossBackward0>)\n",
      "1080\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "1081\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "1082\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "1083\n",
      "tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
      "1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([509, 1, 128])) that is different to the input size (torch.Size([509, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "1085\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "1086\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "1087\n",
      "tensor(0.1997, grad_fn=<MseLossBackward0>)\n",
      "1088\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "1089\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "1090\n",
      "tensor(0.1646, grad_fn=<MseLossBackward0>)\n",
      "1091\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([62, 1, 128])) that is different to the input size (torch.Size([62, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([153, 1, 128])) that is different to the input size (torch.Size([153, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1863, grad_fn=<MseLossBackward0>)\n",
      "1093\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1094\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "1095\n",
      "tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "1096\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([251, 1, 128])) that is different to the input size (torch.Size([251, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "1098\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "1099\n",
      "tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "1100\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "1101\n",
      "tensor(0.1338, grad_fn=<MseLossBackward0>)\n",
      "1102\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "1103\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1104\n",
      "tensor(0.1431, grad_fn=<MseLossBackward0>)\n",
      "1105\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "1106\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "1107\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1108\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "1109\n",
      "tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "1110\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([86, 1, 128])) that is different to the input size (torch.Size([86, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "1112\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "1113\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "1114\n",
      "tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "1115\n",
      "tensor(0.1934, grad_fn=<MseLossBackward0>)\n",
      "1116\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1117\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "1118\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "1119\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "1120\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "1121\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "1122\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "1123\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "1124\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "1125\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "1126\n",
      "tensor(0.2174, grad_fn=<MseLossBackward0>)\n",
      "1127\n",
      "tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "1128\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "1129\n",
      "tensor(0.2973, grad_fn=<MseLossBackward0>)\n",
      "1130\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "1131\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "1132\n",
      "tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "1133\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "1134\n",
      "tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "1135\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "1136\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "1137\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "1138\n",
      "tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "1139\n",
      "tensor(0.1428, grad_fn=<MseLossBackward0>)\n",
      "1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([351, 1, 128])) that is different to the input size (torch.Size([351, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2904, grad_fn=<MseLossBackward0>)\n",
      "1141\n",
      "tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "1142\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "1143\n",
      "tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "1144\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1145\n",
      "tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "1146\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "1147\n",
      "tensor(0.1508, grad_fn=<MseLossBackward0>)\n",
      "1148\n",
      "tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
      "1149\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "1150\n",
      "tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "1151\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "1152\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1153\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "1154\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "1155\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "1156\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "1157\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "1158\n",
      "tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "1159\n",
      "tensor(0.1589, grad_fn=<MseLossBackward0>)\n",
      "1160\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "1161\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "1162\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "1163\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "1164\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "1165\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "1166\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "1167\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "1168\n",
      "tensor(0.2680, grad_fn=<MseLossBackward0>)\n",
      "1169\n",
      "tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "1170\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([301, 1, 128])) that is different to the input size (torch.Size([301, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "1172\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "1173\n",
      "tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "1174\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1175\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "1176\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "1177\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "1178\n",
      "tensor(0.2707, grad_fn=<MseLossBackward0>)\n",
      "1179\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "1180\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "1181\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "1182\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "1183\n",
      "tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
      "1184\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "1185\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "1186\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "1187\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "1188\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "1189\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "1190\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "1191\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150, 1, 128])) that is different to the input size (torch.Size([150, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1528, grad_fn=<MseLossBackward0>)\n",
      "1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([223, 1, 128])) that is different to the input size (torch.Size([223, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "1194\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([457, 1, 128])) that is different to the input size (torch.Size([457, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "1196\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "1197\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "1198\n",
      "tensor(0.2483, grad_fn=<MseLossBackward0>)\n",
      "1199\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "1200\n",
      "tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "1201\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "1202\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "1203\n",
      "tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "1204\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "1205\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "1206\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "1207\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "1208\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "1209\n",
      "tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "1210\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "1211\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "1212\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1213\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "1214\n",
      "tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "1215\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "1216\n",
      "tensor(0.1642, grad_fn=<MseLossBackward0>)\n",
      "1217\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "1218\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "1219\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "1220\n",
      "tensor(0.1846, grad_fn=<MseLossBackward0>)\n",
      "1221\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([870, 1, 128])) that is different to the input size (torch.Size([870, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "1223\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "1224\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "1225\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1226\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "1227\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "1228\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "1229\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "1230\n",
      "tensor(0.2110, grad_fn=<MseLossBackward0>)\n",
      "1231\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "1232\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "1233\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "1234\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "1235\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "1236\n",
      "tensor(0.1854, grad_fn=<MseLossBackward0>)\n",
      "1237\n",
      "tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "1238\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "1239\n",
      "tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "1240\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "1241\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "1242\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "1243\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1244\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "1245\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "1246\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "1247\n",
      "tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([97, 1, 128])) that is different to the input size (torch.Size([97, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "1249\n",
      "tensor(0.2022, grad_fn=<MseLossBackward0>)\n",
      "1250\n",
      "tensor(0.1341, grad_fn=<MseLossBackward0>)\n",
      "1251\n",
      "tensor(0.1171, grad_fn=<MseLossBackward0>)\n",
      "1252\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "1253\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "1254\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "1255\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "1256\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "1257\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "1258\n",
      "tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "1259\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "1260\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "1261\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "1262\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "1263\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "1264\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "1265\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "1266\n",
      "tensor(0.2771, grad_fn=<MseLossBackward0>)\n",
      "1267\n",
      "tensor(0.2114, grad_fn=<MseLossBackward0>)\n",
      "1268\n",
      "tensor(0.1539, grad_fn=<MseLossBackward0>)\n",
      "1269\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "1270\n",
      "tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "1271\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "1272\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([73, 1, 128])) that is different to the input size (torch.Size([73, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1838, grad_fn=<MseLossBackward0>)\n",
      "1274\n",
      "tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "1275\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "1276\n",
      "tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "1277\n",
      "tensor(0.1460, grad_fn=<MseLossBackward0>)\n",
      "1278\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "1279\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "1280\n",
      "tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "1281\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "1282\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "1283\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "1284\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "1285\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "1286\n",
      "tensor(0.1577, grad_fn=<MseLossBackward0>)\n",
      "1287\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "1288\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "1289\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([159, 1, 128])) that is different to the input size (torch.Size([159, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "1291\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "1292\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "1293\n",
      "tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "1294\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "1295\n",
      "tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "1296\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "1297\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "1298\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "1299\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "1300\n",
      "tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "1301\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "1302\n",
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "1303\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "1304\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "1305\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "1306\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "1307\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1308\n",
      "tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "1309\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "1310\n",
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "1311\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "1312\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "1313\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "1314\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "1315\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "1316\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "1317\n",
      "tensor(0.2199, grad_fn=<MseLossBackward0>)\n",
      "1318\n",
      "tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "1319\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "1320\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "1321\n",
      "tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "1322\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "1323\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "1324\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "1325\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "1326\n",
      "tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "1327\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "1328\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "1329\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1330\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "1331\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "1332\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "1333\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "1334\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "1335\n",
      "tensor(0.1451, grad_fn=<MseLossBackward0>)\n",
      "1336\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "1337\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "1338\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "1339\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([71, 1, 128])) that is different to the input size (torch.Size([71, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0980, grad_fn=<MseLossBackward0>)\n",
      "1341\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1342\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "1343\n",
      "tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "1344\n",
      "tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "1345\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1346\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "1347\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([290, 1, 128])) that is different to the input size (torch.Size([290, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1349\n",
      "tensor(0.1726, grad_fn=<MseLossBackward0>)\n",
      "1350\n",
      "tensor(0.1514, grad_fn=<MseLossBackward0>)\n",
      "1351\n",
      "tensor(0.1521, grad_fn=<MseLossBackward0>)\n",
      "1352\n",
      "tensor(0.1549, grad_fn=<MseLossBackward0>)\n",
      "1353\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "1354\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1355\n",
      "tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "1356\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([372, 1, 128])) that is different to the input size (torch.Size([372, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
      "1358\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "1359\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "1360\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "1361\n",
      "tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "1362\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "1363\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "1364\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "1365\n",
      "tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "1366\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "1367\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "1368\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "1369\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "1370\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1371\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1372\n",
      "tensor(0.1253, grad_fn=<MseLossBackward0>)\n",
      "1373\n",
      "tensor(0.1697, grad_fn=<MseLossBackward0>)\n",
      "1374\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "1375\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "1376\n",
      "tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "1377\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "1378\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "1379\n",
      "tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "1380\n",
      "tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "1381\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "1382\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "1383\n",
      "tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([76, 1, 128])) that is different to the input size (torch.Size([76, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([224, 1, 128])) that is different to the input size (torch.Size([224, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "1385\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "1386\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "1387\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1388\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "1389\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "1390\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "1391\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "1392\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "1393\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "1394\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "1395\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "1396\n",
      "tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "1397\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "1398\n",
      "tensor(0.1252, grad_fn=<MseLossBackward0>)\n",
      "1399\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "1400\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "1401\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "1402\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "1403\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "1404\n",
      "tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "1405\n",
      "tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
      "1406\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "1407\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "1408\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "1409\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "1410\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "1411\n",
      "tensor(0.1915, grad_fn=<MseLossBackward0>)\n",
      "1412\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "1413\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "1414\n",
      "tensor(0.1666, grad_fn=<MseLossBackward0>)\n",
      "1415\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "1416\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([650, 1, 128])) that is different to the input size (torch.Size([650, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([227, 1, 128])) that is different to the input size (torch.Size([227, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "1418\n",
      "tensor(0.1191, grad_fn=<MseLossBackward0>)\n",
      "1419\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "1420\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "1421\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "1422\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "1423\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([567, 1, 128])) that is different to the input size (torch.Size([567, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "1425\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "1426\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "1427\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "1428\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "1429\n",
      "tensor(0.1644, grad_fn=<MseLossBackward0>)\n",
      "1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([343, 1, 128])) that is different to the input size (torch.Size([343, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "1431\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "1432\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "1433\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "1434\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "1435\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "1436\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "1437\n",
      "tensor(0.1604, grad_fn=<MseLossBackward0>)\n",
      "1438\n",
      "tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "1439\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "1440\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([292, 1, 128])) that is different to the input size (torch.Size([292, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "1442\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "1443\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1444\n",
      "tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "1445\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "1446\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "1447\n",
      "tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
      "1448\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "1449\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "1450\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "1451\n",
      "tensor(0.1606, grad_fn=<MseLossBackward0>)\n",
      "1452\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "1453\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1454\n",
      "tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "1455\n",
      "tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
      "1456\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "1457\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "1458\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "1459\n",
      "tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "1460\n",
      "tensor(0.1329, grad_fn=<MseLossBackward0>)\n",
      "1461\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "1462\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "1463\n",
      "tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "1464\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "1465\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "1466\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "1467\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "1468\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "1469\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "1470\n",
      "tensor(0.1156, grad_fn=<MseLossBackward0>)\n",
      "1471\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "1472\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "1473\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "1474\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "1475\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "1476\n",
      "tensor(0.1767, grad_fn=<MseLossBackward0>)\n",
      "1477\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "1478\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "1479\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "1480\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "1481\n",
      "tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "1482\n",
      "tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "1483\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "1484\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "1485\n",
      "tensor(0.1694, grad_fn=<MseLossBackward0>)\n",
      "1486\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "1487\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "1488\n",
      "tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "1489\n",
      "tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "1490\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "1491\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "1492\n",
      "tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "1493\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "1494\n",
      "tensor(0.2769, grad_fn=<MseLossBackward0>)\n",
      "1495\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "1496\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "1497\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "1498\n",
      "tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "1499\n",
      "tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "1500\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "1501\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "1502\n",
      "tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "1503\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "1504\n",
      "tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "1505\n",
      "tensor(0.1780, grad_fn=<MseLossBackward0>)\n",
      "1506\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1507\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "1508\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "1509\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "1510\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "1511\n",
      "tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "1512\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "1513\n",
      "tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "1514\n",
      "tensor(0.2844, grad_fn=<MseLossBackward0>)\n",
      "1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([811, 1, 128])) that is different to the input size (torch.Size([811, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "1516\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "1517\n",
      "tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "1518\n",
      "tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "1519\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "1520\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1521\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1522\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "1523\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "1524\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "1525\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "1526\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "1527\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "1528\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "1529\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "1530\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "1531\n",
      "tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "1532\n",
      "tensor(0.1209, grad_fn=<MseLossBackward0>)\n",
      "1533\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "1534\n",
      "tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "1535\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "1536\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "1537\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "1538\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "1539\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "1540\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "1541\n",
      "tensor(0.1343, grad_fn=<MseLossBackward0>)\n",
      "1542\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "1543\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "1544\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "1545\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "1546\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1547\n",
      "tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "1548\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1549\n",
      "tensor(0.1812, grad_fn=<MseLossBackward0>)\n",
      "1550\n",
      "tensor(0.1784, grad_fn=<MseLossBackward0>)\n",
      "1551\n",
      "tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "1552\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "1553\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "1554\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "1555\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "1556\n",
      "tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "1557\n",
      "tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "1558\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "1559\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([133, 1, 128])) that is different to the input size (torch.Size([133, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([107, 1, 128])) that is different to the input size (torch.Size([107, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "1561\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "1562\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "1563\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "1564\n",
      "tensor(0.1465, grad_fn=<MseLossBackward0>)\n",
      "1565\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "1566\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "1567\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "1568\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "1569\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "1570\n",
      "tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "1571\n",
      "tensor(0.1540, grad_fn=<MseLossBackward0>)\n",
      "1572\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "1573\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "1574\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "1575\n",
      "tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "1576\n",
      "tensor(0.1934, grad_fn=<MseLossBackward0>)\n",
      "1577\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "1578\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "1579\n",
      "tensor(0.1379, grad_fn=<MseLossBackward0>)\n",
      "1580\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "1581\n",
      "tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "1582\n",
      "tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "1583\n",
      "tensor(0.2144, grad_fn=<MseLossBackward0>)\n",
      "1584\n",
      "tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "1585\n",
      "tensor(0.1854, grad_fn=<MseLossBackward0>)\n",
      "1586\n",
      "tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "1587\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "1588\n",
      "tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "1589\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "1590\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([233, 1, 128])) that is different to the input size (torch.Size([233, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([102, 1, 128])) that is different to the input size (torch.Size([102, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "1592\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "1593\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "1594\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "1595\n",
      "tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "1596\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "1597\n",
      "tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "1598\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "1599\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "1600\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([303, 1, 128])) that is different to the input size (torch.Size([303, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "1602\n",
      "tensor(0.1532, grad_fn=<MseLossBackward0>)\n",
      "1603\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "1604\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "1605\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "1606\n",
      "tensor(0.1560, grad_fn=<MseLossBackward0>)\n",
      "1607\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "1608\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "1609\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1610\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "1611\n",
      "tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "1612\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "1613\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "1614\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "1615\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "1616\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1617\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "1618\n",
      "tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "1619\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "1620\n",
      "tensor(0.1947, grad_fn=<MseLossBackward0>)\n",
      "1621\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "1622\n",
      "tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "1623\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "1624\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "1625\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "1626\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([443, 1, 128])) that is different to the input size (torch.Size([443, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n",
      "1628\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "1629\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "1630\n",
      "tensor(0.1744, grad_fn=<MseLossBackward0>)\n",
      "1631\n",
      "tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "1632\n",
      "tensor(0.1382, grad_fn=<MseLossBackward0>)\n",
      "1633\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "1634\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "1635\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "1636\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "1637\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "1638\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "1639\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "1640\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "1641\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "1642\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "1643\n",
      "tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "1644\n",
      "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "1645\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "1646\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "1647\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "1648\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "1649\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "1650\n",
      "tensor(0.2781, grad_fn=<MseLossBackward0>)\n",
      "1651\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1652\n",
      "tensor(0.3046, grad_fn=<MseLossBackward0>)\n",
      "1653\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "1654\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "1655\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "1656\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "1657\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "1658\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "1659\n",
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "1660\n",
      "tensor(0.2202, grad_fn=<MseLossBackward0>)\n",
      "1661\n",
      "tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "1662\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "1663\n",
      "tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "1664\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "1665\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "1666\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "1667\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "1668\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "1669\n",
      "tensor(0.1919, grad_fn=<MseLossBackward0>)\n",
      "1670\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "1671\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "1672\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "1673\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "1674\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "1675\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "1676\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "1677\n",
      "tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "1678\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "1679\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "1680\n",
      "tensor(0.3207, grad_fn=<MseLossBackward0>)\n",
      "1681\n",
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "1682\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "1683\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "1684\n",
      "tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "1685\n",
      "tensor(0.1776, grad_fn=<MseLossBackward0>)\n",
      "1686\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "1687\n",
      "tensor(0.3966, grad_fn=<MseLossBackward0>)\n",
      "1688\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "1689\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "1690\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "1691\n",
      "tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "1692\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "1693\n",
      "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "1694\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "1695\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([255, 1, 128])) that is different to the input size (torch.Size([255, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "1697\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "1698\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "1699\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "1700\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "1701\n",
      "tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
      "1702\n",
      "tensor(0.1279, grad_fn=<MseLossBackward0>)\n",
      "1703\n",
      "tensor(0.1456, grad_fn=<MseLossBackward0>)\n",
      "1704\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "1705\n",
      "tensor(0.1798, grad_fn=<MseLossBackward0>)\n",
      "1706\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "1707\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([196, 1, 128])) that is different to the input size (torch.Size([196, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "1709\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "1710\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "1711\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "1712\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "1713\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "1714\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "1715\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1716\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "1717\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "1718\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "1719\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "1720\n",
      "tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "1721\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "1722\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "1723\n",
      "tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "1724\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "1725\n",
      "tensor(0.1464, grad_fn=<MseLossBackward0>)\n",
      "1726\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "1727\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "1728\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "1729\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "1730\n",
      "tensor(0.1334, grad_fn=<MseLossBackward0>)\n",
      "1731\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "1732\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "1733\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "1734\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "1735\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "1736\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "1737\n",
      "tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
      "1738\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "1739\n",
      "tensor(0.1519, grad_fn=<MseLossBackward0>)\n",
      "1740\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "1741\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "1742\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "1743\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "1744\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "1745\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "1746\n",
      "tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "1747\n",
      "tensor(0.2133, grad_fn=<MseLossBackward0>)\n",
      "1748\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "1749\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "1750\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "1751\n",
      "tensor(0.1635, grad_fn=<MseLossBackward0>)\n",
      "1752\n",
      "tensor(0.1506, grad_fn=<MseLossBackward0>)\n",
      "1753\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([175, 1, 128])) that is different to the input size (torch.Size([175, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "1755\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "1756\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "1757\n",
      "tensor(0.1942, grad_fn=<MseLossBackward0>)\n",
      "1758\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "1759\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "1760\n",
      "tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "1761\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "1762\n",
      "tensor(0.1769, grad_fn=<MseLossBackward0>)\n",
      "1763\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "1764\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "1765\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "1766\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "1767\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "1768\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "1769\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "1770\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "1771\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "1772\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "1773\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "1774\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "1775\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "1776\n",
      "tensor(0.3496, grad_fn=<MseLossBackward0>)\n",
      "1777\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "1778\n",
      "tensor(0.1491, grad_fn=<MseLossBackward0>)\n",
      "1779\n",
      "tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
      "1780\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "1781\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "1782\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "1783\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "1784\n",
      "tensor(0.2517, grad_fn=<MseLossBackward0>)\n",
      "1785\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "1786\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "1787\n",
      "tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "1788\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "1789\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "1790\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "1791\n",
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "1792\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "1793\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "1794\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "1795\n",
      "tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "1796\n",
      "tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "1797\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "1798\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "1799\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "1800\n",
      "tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "1801\n",
      "tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "1802\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "1803\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "1804\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "1805\n",
      "tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "1806\n",
      "tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "1807\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "1808\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "1809\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "1810\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "1811\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "1812\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "1813\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "1814\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "1815\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([399, 1, 128])) that is different to the input size (torch.Size([399, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "1817\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "1818\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "1819\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "1820\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "1821\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "1822\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "1823\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "1824\n",
      "tensor(0.2091, grad_fn=<MseLossBackward0>)\n",
      "1825\n",
      "tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "1826\n",
      "tensor(0.2140, grad_fn=<MseLossBackward0>)\n",
      "1827\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "1828\n",
      "tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
      "1829\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "1830\n",
      "tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "1831\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "1832\n",
      "tensor(0.1377, grad_fn=<MseLossBackward0>)\n",
      "1833\n",
      "tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "1834\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "1835\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "1836\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "1837\n",
      "tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
      "1838\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "1839\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "1840\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "1841\n",
      "tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "1842\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "1843\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "1844\n",
      "tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "1845\n",
      "tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "1846\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "1847\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "1848\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1849\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "1850\n",
      "tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "1851\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "1852\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "1853\n",
      "tensor(0.1942, grad_fn=<MseLossBackward0>)\n",
      "1854\n",
      "tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "1855\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "1856\n",
      "tensor(0.2088, grad_fn=<MseLossBackward0>)\n",
      "1857\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "1858\n",
      "tensor(0.1719, grad_fn=<MseLossBackward0>)\n",
      "1859\n",
      "tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "1860\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "1861\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "1862\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "1863\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "1864\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "1865\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "1866\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "1867\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "1868\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "1869\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "1870\n",
      "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "1871\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "1872\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "1873\n",
      "tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "1874\n",
      "tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "1875\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1876\n",
      "tensor(0.2029, grad_fn=<MseLossBackward0>)\n",
      "1877\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "1878\n",
      "tensor(0.4217, grad_fn=<MseLossBackward0>)\n",
      "1879\n",
      "tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "1880\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "1881\n",
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "1882\n",
      "tensor(0.2569, grad_fn=<MseLossBackward0>)\n",
      "1883\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "1884\n",
      "tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "1885\n",
      "tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "1886\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "1887\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "1888\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "1889\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "1890\n",
      "tensor(0.1144, grad_fn=<MseLossBackward0>)\n",
      "1891\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1892\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "1893\n",
      "tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "1894\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "1895\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "1896\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([181, 1, 128])) that is different to the input size (torch.Size([181, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "1898\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "1899\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "1900\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "1901\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "1902\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "1903\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "1904\n",
      "tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "1905\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "1906\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "1907\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "1908\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "1909\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "1910\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "1911\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "1912\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "1913\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "1914\n",
      "tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "1915\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "1916\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "1917\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "1918\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "1919\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "1920\n",
      "tensor(0.1938, grad_fn=<MseLossBackward0>)\n",
      "1921\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "1922\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "1923\n",
      "tensor(0.1599, grad_fn=<MseLossBackward0>)\n",
      "1924\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "1925\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "1926\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "1927\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "1928\n",
      "tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "1929\n",
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "1930\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "1931\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "1932\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "1933\n",
      "tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "1934\n",
      "tensor(0.1612, grad_fn=<MseLossBackward0>)\n",
      "1935\n",
      "tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "1936\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "1937\n",
      "tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([136, 1, 128])) that is different to the input size (torch.Size([136, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1605, grad_fn=<MseLossBackward0>)\n",
      "1939\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "1940\n",
      "tensor(0.1187, grad_fn=<MseLossBackward0>)\n",
      "1941\n",
      "tensor(0.0980, grad_fn=<MseLossBackward0>)\n",
      "1942\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "1943\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "1944\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "1945\n",
      "tensor(0.1599, grad_fn=<MseLossBackward0>)\n",
      "1946\n",
      "tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "1947\n",
      "tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "1948\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "1949\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "1950\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "1951\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "1952\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "1953\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "1954\n",
      "tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "1955\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "1956\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "1957\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "1958\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "1959\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "1960\n",
      "tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "1961\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "1962\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "1963\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "1964\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "1965\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "1966\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "1967\n",
      "tensor(0.1989, grad_fn=<MseLossBackward0>)\n",
      "1968\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "1969\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "1970\n",
      "tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "1971\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "1972\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "1973\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "1974\n",
      "tensor(0.1432, grad_fn=<MseLossBackward0>)\n",
      "1975\n",
      "tensor(0.1929, grad_fn=<MseLossBackward0>)\n",
      "1976\n",
      "tensor(0.1706, grad_fn=<MseLossBackward0>)\n",
      "1977\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "1978\n",
      "tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([385, 1, 128])) that is different to the input size (torch.Size([385, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "1980\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "1981\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "1982\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "1983\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "1984\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "1985\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "1986\n",
      "tensor(0.1693, grad_fn=<MseLossBackward0>)\n",
      "1987\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "1988\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "1989\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "1990\n",
      "tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
      "1991\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "1992\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "1993\n",
      "tensor(0.1599, grad_fn=<MseLossBackward0>)\n",
      "1994\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "1995\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "1996\n",
      "tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "1997\n",
      "tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "1998\n",
      "tensor(0.1726, grad_fn=<MseLossBackward0>)\n",
      "1999\n",
      "tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
      "2000\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "2001\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "2002\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "2003\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "2004\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "2005\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "2006\n",
      "tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "2007\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "2008\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "2009\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "2010\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "2011\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "2012\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "2013\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "2014\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "2015\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "2016\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "2017\n",
      "tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "2018\n",
      "tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "2019\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "2020\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "2021\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "2022\n",
      "tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "2023\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "2024\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2025\n",
      "tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "2026\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "2027\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "2028\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "2029\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "2030\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "2031\n",
      "tensor(0.1354, grad_fn=<MseLossBackward0>)\n",
      "2032\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "2033\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "2034\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "2035\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "2036\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "2037\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "2038\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([193, 1, 128])) that is different to the input size (torch.Size([193, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "2040\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "2041\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "2042\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "2043\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "2044\n",
      "tensor(0.1332, grad_fn=<MseLossBackward0>)\n",
      "2045\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "2046\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "2047\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "2048\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "2049\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "2050\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "2051\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([362, 1, 128])) that is different to the input size (torch.Size([362, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "2053\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "2054\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "2055\n",
      "tensor(0.1913, grad_fn=<MseLossBackward0>)\n",
      "2056\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "2057\n",
      "tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "2058\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "2059\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2060\n",
      "tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "2061\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "2062\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "2063\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "2064\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "2065\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "2066\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "2067\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "2068\n",
      "tensor(0.2901, grad_fn=<MseLossBackward0>)\n",
      "2069\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "2070\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "2071\n",
      "tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "2072\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2073\n",
      "tensor(0.1577, grad_fn=<MseLossBackward0>)\n",
      "2074\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "2075\n",
      "tensor(0.2807, grad_fn=<MseLossBackward0>)\n",
      "2076\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "2077\n",
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "2078\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "2079\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "2080\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "2081\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "2082\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "2083\n",
      "tensor(0.1578, grad_fn=<MseLossBackward0>)\n",
      "2084\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "2085\n",
      "tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
      "2086\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "2087\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "2088\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "2089\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "2090\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "2091\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([258, 1, 128])) that is different to the input size (torch.Size([258, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1733, grad_fn=<MseLossBackward0>)\n",
      "2093\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "2094\n",
      "tensor(0.1653, grad_fn=<MseLossBackward0>)\n",
      "2095\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "2096\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2097\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "2098\n",
      "tensor(0.1482, grad_fn=<MseLossBackward0>)\n",
      "2099\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "2100\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2101\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "2102\n",
      "tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "2103\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2104\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "2105\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "2106\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "2107\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "2108\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2109\n",
      "tensor(0.1308, grad_fn=<MseLossBackward0>)\n",
      "2110\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "2111\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2112\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "2113\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2114\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "2115\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "2116\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "2117\n",
      "tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "2118\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "2119\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2120\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "2121\n",
      "tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "2122\n",
      "tensor(0.1623, grad_fn=<MseLossBackward0>)\n",
      "2123\n",
      "tensor(0.1373, grad_fn=<MseLossBackward0>)\n",
      "2124\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2125\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "2126\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "2127\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "2128\n",
      "tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "2129\n",
      "tensor(0.1884, grad_fn=<MseLossBackward0>)\n",
      "2130\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "2131\n",
      "tensor(0.1450, grad_fn=<MseLossBackward0>)\n",
      "2132\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "2133\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "2134\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "2135\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "2136\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "2137\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "2138\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "2139\n",
      "tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "2140\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2141\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "2142\n",
      "tensor(0.2465, grad_fn=<MseLossBackward0>)\n",
      "2143\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "2144\n",
      "tensor(0.1315, grad_fn=<MseLossBackward0>)\n",
      "2145\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "2146\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "2147\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "2148\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "2149\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "2150\n",
      "tensor(0.1522, grad_fn=<MseLossBackward0>)\n",
      "2151\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "2152\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "2153\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "2154\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "2155\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "2156\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "2157\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "2158\n",
      "tensor(0.1308, grad_fn=<MseLossBackward0>)\n",
      "2159\n",
      "tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "2160\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "2161\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "2162\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "2163\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "2164\n",
      "tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "2165\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "2166\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "2167\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "2168\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "2169\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "2170\n",
      "tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "2171\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "2172\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "2173\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2174\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "2175\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "2176\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "2177\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "2178\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "2179\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "2180\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "2181\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "2182\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "2183\n",
      "tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "2184\n",
      "tensor(0.1386, grad_fn=<MseLossBackward0>)\n",
      "2185\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "2186\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2187\n",
      "tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "2188\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "2189\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "2190\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "2191\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "2192\n",
      "tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "2193\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "2194\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "2195\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "2196\n",
      "tensor(0.1564, grad_fn=<MseLossBackward0>)\n",
      "2197\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2198\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "2199\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "2200\n",
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "2201\n",
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "2202\n",
      "tensor(0.1532, grad_fn=<MseLossBackward0>)\n",
      "2203\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "2204\n",
      "tensor(0.1764, grad_fn=<MseLossBackward0>)\n",
      "2205\n",
      "tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "2206\n",
      "tensor(0.1646, grad_fn=<MseLossBackward0>)\n",
      "2207\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2208\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "2209\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "2210\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2211\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "2212\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2213\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "2214\n",
      "tensor(0.3367, grad_fn=<MseLossBackward0>)\n",
      "2215\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "2216\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "2217\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "2218\n",
      "tensor(0.1508, grad_fn=<MseLossBackward0>)\n",
      "2219\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "2220\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "2221\n",
      "tensor(0.2464, grad_fn=<MseLossBackward0>)\n",
      "2222\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "2223\n",
      "tensor(0.2199, grad_fn=<MseLossBackward0>)\n",
      "2224\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "2225\n",
      "tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "2226\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "2227\n",
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "2228\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "2229\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "2230\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "2231\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "2232\n",
      "tensor(0.2562, grad_fn=<MseLossBackward0>)\n",
      "2233\n",
      "tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "2234\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "2235\n",
      "tensor(0.1602, grad_fn=<MseLossBackward0>)\n",
      "2236\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "2237\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "2238\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "2239\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "2240\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "2241\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "2242\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "2243\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "2244\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "2245\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "2246\n",
      "tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "2247\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "2248\n",
      "tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "2249\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "2250\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "2251\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "2252\n",
      "tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "2253\n",
      "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "2254\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "2255\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "2256\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "2257\n",
      "tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "2258\n",
      "tensor(0.1339, grad_fn=<MseLossBackward0>)\n",
      "2259\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "2260\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "2261\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "2262\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "2263\n",
      "tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "2264\n",
      "tensor(0.1531, grad_fn=<MseLossBackward0>)\n",
      "2265\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "2266\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "2267\n",
      "tensor(0.1308, grad_fn=<MseLossBackward0>)\n",
      "2268\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "2269\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "2270\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "2271\n",
      "tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "2272\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "2273\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "2274\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "2275\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "2276\n",
      "tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "2277\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "2278\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "2279\n",
      "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "2280\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "2281\n",
      "tensor(0.1540, grad_fn=<MseLossBackward0>)\n",
      "2282\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2283\n",
      "tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "2284\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "2285\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "2286\n",
      "tensor(0.1450, grad_fn=<MseLossBackward0>)\n",
      "2287\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "2288\n",
      "tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
      "2289\n",
      "tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "2290\n",
      "tensor(0.1314, grad_fn=<MseLossBackward0>)\n",
      "2291\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "2292\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "2293\n",
      "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "2294\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "2295\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "2296\n",
      "tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "2297\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "2298\n",
      "tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "2299\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([222, 1, 128])) that is different to the input size (torch.Size([222, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2494, grad_fn=<MseLossBackward0>)\n",
      "2301\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "2302\n",
      "tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
      "2303\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "2304\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "2305\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "2306\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "2307\n",
      "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "2308\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "2309\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "2310\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2311\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "2312\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "2313\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "2314\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "2315\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "2316\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "2317\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "2318\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "2319\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "2320\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "2321\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([393, 1, 128])) that is different to the input size (torch.Size([393, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "2323\n",
      "tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "2324\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "2325\n",
      "tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "2326\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "2327\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "2328\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2329\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "2330\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "2331\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "2332\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "2333\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "2334\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "2335\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "2336\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2337\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "2338\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2339\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "2340\n",
      "tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "2341\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "2342\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "2343\n",
      "tensor(0.2257, grad_fn=<MseLossBackward0>)\n",
      "2344\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "2345\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "2346\n",
      "tensor(0.1814, grad_fn=<MseLossBackward0>)\n",
      "2347\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "2348\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "2349\n",
      "tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "2350\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "2351\n",
      "tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "2352\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "2353\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "2354\n",
      "tensor(0.1543, grad_fn=<MseLossBackward0>)\n",
      "2355\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2356\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "2357\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "2358\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "2359\n",
      "tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "2360\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "2361\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "2362\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "2363\n",
      "tensor(0.2191, grad_fn=<MseLossBackward0>)\n",
      "2364\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "2365\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "2366\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "2367\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "2368\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "2369\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "2370\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "2371\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "2372\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "2373\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "2374\n",
      "tensor(0.1780, grad_fn=<MseLossBackward0>)\n",
      "2375\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "2376\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "2377\n",
      "tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "2378\n",
      "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "2379\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "2380\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "2381\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "2382\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "2383\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "2384\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "2385\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "2386\n",
      "tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "2387\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "2388\n",
      "tensor(0.1419, grad_fn=<MseLossBackward0>)\n",
      "2389\n",
      "tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "2390\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "2391\n",
      "tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "2392\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "2393\n",
      "tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "2394\n",
      "tensor(0.1128, grad_fn=<MseLossBackward0>)\n",
      "2395\n",
      "tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "2396\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "2397\n",
      "tensor(0.2508, grad_fn=<MseLossBackward0>)\n",
      "2398\n",
      "tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "2399\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "2400\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2401\n",
      "tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "2402\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "2403\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "2404\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "2405\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "2406\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "2407\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "2408\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "2409\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "2410\n",
      "tensor(0.2510, grad_fn=<MseLossBackward0>)\n",
      "2411\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "2412\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "2413\n",
      "tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "2414\n",
      "tensor(0.1519, grad_fn=<MseLossBackward0>)\n",
      "2415\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "2416\n",
      "tensor(0.1196, grad_fn=<MseLossBackward0>)\n",
      "2417\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "2418\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "2419\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "2420\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "2421\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "2422\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "2423\n",
      "tensor(0.1926, grad_fn=<MseLossBackward0>)\n",
      "2424\n",
      "tensor(0.1373, grad_fn=<MseLossBackward0>)\n",
      "2425\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "2426\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "2427\n",
      "tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "2428\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "2429\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2430\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "2431\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "2432\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "2433\n",
      "tensor(0.1722, grad_fn=<MseLossBackward0>)\n",
      "2434\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "2435\n",
      "tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "2436\n",
      "tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "2437\n",
      "tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "2438\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "2439\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "2440\n",
      "tensor(0.1528, grad_fn=<MseLossBackward0>)\n",
      "2441\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "2442\n",
      "tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "2443\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "2444\n",
      "tensor(0.1973, grad_fn=<MseLossBackward0>)\n",
      "2445\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "2446\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "2447\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "2448\n",
      "tensor(0.2131, grad_fn=<MseLossBackward0>)\n",
      "2449\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2450\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "2451\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "2452\n",
      "tensor(0.1588, grad_fn=<MseLossBackward0>)\n",
      "2453\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "2454\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "2455\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2456\n",
      "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "2457\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "2458\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([232, 1, 128])) that is different to the input size (torch.Size([232, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "2460\n",
      "tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "2461\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "2462\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "2463\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "2464\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2465\n",
      "tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "2466\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "2467\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "2468\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "2469\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "2470\n",
      "tensor(0.2079, grad_fn=<MseLossBackward0>)\n",
      "2471\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "2472\n",
      "tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "2473\n",
      "tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "2474\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "2475\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "2476\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "2477\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "2478\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "2479\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "2480\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "2481\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "2482\n",
      "tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "2483\n",
      "tensor(0.2081, grad_fn=<MseLossBackward0>)\n",
      "2484\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([157, 1, 128])) that is different to the input size (torch.Size([157, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([206, 1, 128])) that is different to the input size (torch.Size([206, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1378, grad_fn=<MseLossBackward0>)\n",
      "2486\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "2487\n",
      "tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "2488\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "2489\n",
      "tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "2490\n",
      "tensor(0.1757, grad_fn=<MseLossBackward0>)\n",
      "2491\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "2492\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "2493\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "2494\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2495\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "2496\n",
      "tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "2497\n",
      "tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "2498\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2499\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "2500\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "2501\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "2502\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "2503\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "2504\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "2505\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "2506\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "2507\n",
      "tensor(0.1155, grad_fn=<MseLossBackward0>)\n",
      "2508\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "2509\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "2510\n",
      "tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "2511\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "2512\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "2513\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "2514\n",
      "tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "2515\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "2516\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "2517\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "2518\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "2519\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "2520\n",
      "tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "2521\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "2522\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "2523\n",
      "tensor(0.2597, grad_fn=<MseLossBackward0>)\n",
      "2524\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "2525\n",
      "tensor(0.1365, grad_fn=<MseLossBackward0>)\n",
      "2526\n",
      "tensor(0.1758, grad_fn=<MseLossBackward0>)\n",
      "2527\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2528\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "2529\n",
      "tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "2530\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "2531\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "2532\n",
      "tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
      "2533\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "2534\n",
      "tensor(0.1578, grad_fn=<MseLossBackward0>)\n",
      "2535\n",
      "tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "2536\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "2537\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "2538\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "2539\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "2540\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "2541\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "2542\n",
      "tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "2543\n",
      "tensor(0.1165, grad_fn=<MseLossBackward0>)\n",
      "2544\n",
      "tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "2545\n",
      "tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "2546\n",
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "2547\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "2548\n",
      "tensor(0.1587, grad_fn=<MseLossBackward0>)\n",
      "2549\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "2550\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2551\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "2552\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "2553\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "2554\n",
      "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "2555\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "2556\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "2557\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "2558\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2559\n",
      "tensor(0.1997, grad_fn=<MseLossBackward0>)\n",
      "2560\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "2561\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "2562\n",
      "tensor(0.1456, grad_fn=<MseLossBackward0>)\n",
      "2563\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "2564\n",
      "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([315, 1, 128])) that is different to the input size (torch.Size([315, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "2566\n",
      "tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "2567\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "2568\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "2569\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "2570\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "2571\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "2572\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "2573\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "2574\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "2575\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "2576\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "2577\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "2578\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2579\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "2580\n",
      "tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "2581\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "2582\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "2583\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "2584\n",
      "tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "2585\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "2586\n",
      "tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
      "2587\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "2588\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "2589\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2590\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "2591\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "2592\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "2593\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "2594\n",
      "tensor(0.1255, grad_fn=<MseLossBackward0>)\n",
      "2595\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2596\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2597\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "2598\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "2599\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([439, 1, 128])) that is different to the input size (torch.Size([439, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1681, grad_fn=<MseLossBackward0>)\n",
      "2601\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "2602\n",
      "tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "2603\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "2604\n",
      "tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "2605\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "2606\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "2607\n",
      "tensor(0.2017, grad_fn=<MseLossBackward0>)\n",
      "2608\n",
      "tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "2609\n",
      "tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "2610\n",
      "tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "2611\n",
      "tensor(0.1364, grad_fn=<MseLossBackward0>)\n",
      "2612\n",
      "tensor(0.1504, grad_fn=<MseLossBackward0>)\n",
      "2613\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "2614\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "2615\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2616\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2617\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "2618\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2619\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "2620\n",
      "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "2621\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "2622\n",
      "tensor(0.2162, grad_fn=<MseLossBackward0>)\n",
      "2623\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "2624\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "2625\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "2626\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "2627\n",
      "tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "2628\n",
      "tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "2629\n",
      "tensor(0.1848, grad_fn=<MseLossBackward0>)\n",
      "2630\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2631\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "2632\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "2633\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "2634\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "2635\n",
      "tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "2636\n",
      "tensor(0.1189, grad_fn=<MseLossBackward0>)\n",
      "2637\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "2638\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "2639\n",
      "tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
      "2640\n",
      "tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "2641\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2642\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "2643\n",
      "tensor(0.1431, grad_fn=<MseLossBackward0>)\n",
      "2644\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "2645\n",
      "tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "2646\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "2647\n",
      "tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "2648\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "2649\n",
      "tensor(0.1337, grad_fn=<MseLossBackward0>)\n",
      "2650\n",
      "tensor(0.1997, grad_fn=<MseLossBackward0>)\n",
      "2651\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "2652\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "2653\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "2654\n",
      "tensor(0.1362, grad_fn=<MseLossBackward0>)\n",
      "2655\n",
      "tensor(0.1913, grad_fn=<MseLossBackward0>)\n",
      "2656\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2657\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "2658\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "2659\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "2660\n",
      "tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "2661\n",
      "tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "2662\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "2663\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "2664\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "2665\n",
      "tensor(0.1338, grad_fn=<MseLossBackward0>)\n",
      "2666\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "2667\n",
      "tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "2668\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "2669\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2670\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "2671\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "2672\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "2673\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "2674\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "2675\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "2676\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "2677\n",
      "tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "2678\n",
      "tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "2679\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "2680\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "2681\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "2682\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "2683\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "2684\n",
      "tensor(0.2463, grad_fn=<MseLossBackward0>)\n",
      "2685\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "2686\n",
      "tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "2687\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "2688\n",
      "tensor(0.3635, grad_fn=<MseLossBackward0>)\n",
      "2689\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2690\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "2691\n",
      "tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "2692\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "2693\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "2694\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "2695\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "2696\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "2697\n",
      "tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
      "2698\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "2699\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "2700\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "2701\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "2702\n",
      "tensor(0.1339, grad_fn=<MseLossBackward0>)\n",
      "2703\n",
      "tensor(0.2101, grad_fn=<MseLossBackward0>)\n",
      "2704\n",
      "tensor(0.1165, grad_fn=<MseLossBackward0>)\n",
      "2705\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "2706\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "2707\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "2708\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "2709\n",
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "2710\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "2711\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "2712\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "2713\n",
      "tensor(0.2180, grad_fn=<MseLossBackward0>)\n",
      "2714\n",
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "2715\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "2716\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "2717\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "2718\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "2719\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "2720\n",
      "tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "2721\n",
      "tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "2722\n",
      "tensor(0.1353, grad_fn=<MseLossBackward0>)\n",
      "2723\n",
      "tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "2724\n",
      "tensor(0.1492, grad_fn=<MseLossBackward0>)\n",
      "2725\n",
      "tensor(0.1993, grad_fn=<MseLossBackward0>)\n",
      "2726\n",
      "tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "2727\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "2728\n",
      "tensor(0.1728, grad_fn=<MseLossBackward0>)\n",
      "2729\n",
      "tensor(0.1884, grad_fn=<MseLossBackward0>)\n",
      "2730\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "2731\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "2732\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "2733\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "2734\n",
      "tensor(0.1492, grad_fn=<MseLossBackward0>)\n",
      "2735\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "2736\n",
      "tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "2737\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "2738\n",
      "tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "2739\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "2740\n",
      "tensor(0.2202, grad_fn=<MseLossBackward0>)\n",
      "2741\n",
      "tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "2742\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2743\n",
      "tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "2744\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "2745\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "2746\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "2747\n",
      "tensor(0.1392, grad_fn=<MseLossBackward0>)\n",
      "2748\n",
      "tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "2749\n",
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "2750\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "2751\n",
      "tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
      "2752\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "2753\n",
      "tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "2754\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "2755\n",
      "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "2756\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "2757\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "2758\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "2759\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "2760\n",
      "tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "2761\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "2762\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "2763\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "2764\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "2765\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "2766\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "2767\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "2768\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "2769\n",
      "tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "2770\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "2771\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "2772\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "2773\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2774\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "2775\n",
      "tensor(0.1552, grad_fn=<MseLossBackward0>)\n",
      "2776\n",
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "2777\n",
      "tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "2778\n",
      "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "2779\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "2780\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "2781\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "2782\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "2783\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "2784\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "2785\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "2786\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "2787\n",
      "tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "2788\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "2789\n",
      "tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "2790\n",
      "tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "2791\n",
      "tensor(0.1309, grad_fn=<MseLossBackward0>)\n",
      "2792\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "2793\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "2794\n",
      "tensor(0.1897, grad_fn=<MseLossBackward0>)\n",
      "2795\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "2796\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "2797\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "2798\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "2799\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "2800\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "2801\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "2802\n",
      "tensor(0.3496, grad_fn=<MseLossBackward0>)\n",
      "2803\n",
      "tensor(0.1634, grad_fn=<MseLossBackward0>)\n",
      "2804\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "2805\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "2806\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "2807\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2808\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "2809\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "2810\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "2811\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "2812\n",
      "tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "2813\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "2814\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "2815\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "2816\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "2817\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "2818\n",
      "tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "2819\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "2820\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "2821\n",
      "tensor(0.1828, grad_fn=<MseLossBackward0>)\n",
      "2822\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "2823\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "2824\n",
      "tensor(0.2187, grad_fn=<MseLossBackward0>)\n",
      "2825\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "2826\n",
      "tensor(0.1733, grad_fn=<MseLossBackward0>)\n",
      "2827\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2828\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "2829\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "2830\n",
      "tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "2831\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "2832\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "2833\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "2834\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "2835\n",
      "tensor(0.1486, grad_fn=<MseLossBackward0>)\n",
      "2836\n",
      "tensor(0.1826, grad_fn=<MseLossBackward0>)\n",
      "2837\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "2838\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "2839\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "2840\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2841\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "2842\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "2843\n",
      "tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "2844\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "2845\n",
      "tensor(0.1808, grad_fn=<MseLossBackward0>)\n",
      "2846\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "2847\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "2848\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "2849\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "2850\n",
      "tensor(0.1451, grad_fn=<MseLossBackward0>)\n",
      "2851\n",
      "tensor(0.2100, grad_fn=<MseLossBackward0>)\n",
      "2852\n",
      "tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "2853\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "2854\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "2855\n",
      "tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "2856\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "2857\n",
      "tensor(0.1782, grad_fn=<MseLossBackward0>)\n",
      "2858\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "2859\n",
      "tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "2860\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "2861\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "2862\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "2863\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "2864\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "2865\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2866\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "2867\n",
      "tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "2868\n",
      "tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "2869\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "2870\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "2871\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "2872\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "2873\n",
      "tensor(0.1615, grad_fn=<MseLossBackward0>)\n",
      "2874\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "2875\n",
      "tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "2876\n",
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "2877\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "2878\n",
      "tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "2879\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "2880\n",
      "tensor(0.1729, grad_fn=<MseLossBackward0>)\n",
      "2881\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "2882\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "2883\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "2884\n",
      "tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "2885\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "2886\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "2887\n",
      "tensor(0.1983, grad_fn=<MseLossBackward0>)\n",
      "2888\n",
      "tensor(0.1389, grad_fn=<MseLossBackward0>)\n",
      "2889\n",
      "tensor(0.1755, grad_fn=<MseLossBackward0>)\n",
      "2890\n",
      "tensor(0.1996, grad_fn=<MseLossBackward0>)\n",
      "2891\n",
      "tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "2892\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "2893\n",
      "tensor(0.1549, grad_fn=<MseLossBackward0>)\n",
      "2894\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "2895\n",
      "tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "2896\n",
      "tensor(0.1800, grad_fn=<MseLossBackward0>)\n",
      "2897\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "2898\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "2899\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "2900\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2901\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "2902\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "2903\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "2904\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "2905\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "2906\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "2907\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "2908\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2909\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "2910\n",
      "tensor(0.1809, grad_fn=<MseLossBackward0>)\n",
      "2911\n",
      "tensor(0.2131, grad_fn=<MseLossBackward0>)\n",
      "2912\n",
      "tensor(0.1317, grad_fn=<MseLossBackward0>)\n",
      "2913\n",
      "tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "2914\n",
      "tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "2915\n",
      "tensor(0.1343, grad_fn=<MseLossBackward0>)\n",
      "2916\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "2917\n",
      "tensor(0.3845, grad_fn=<MseLossBackward0>)\n",
      "2918\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "2919\n",
      "tensor(0.1787, grad_fn=<MseLossBackward0>)\n",
      "2920\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "2921\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "2922\n",
      "tensor(0.2016, grad_fn=<MseLossBackward0>)\n",
      "2923\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "2924\n",
      "tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "2925\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "2926\n",
      "tensor(0.2654, grad_fn=<MseLossBackward0>)\n",
      "2927\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "2928\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "2929\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "2930\n",
      "tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "2931\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "2932\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "2933\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "2934\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "2935\n",
      "tensor(0.3426, grad_fn=<MseLossBackward0>)\n",
      "2936\n",
      "tensor(0.1613, grad_fn=<MseLossBackward0>)\n",
      "2937\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "2938\n",
      "tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "2939\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "2940\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "2941\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "2942\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2943\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "2944\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "2945\n",
      "tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "2946\n",
      "tensor(0.3045, grad_fn=<MseLossBackward0>)\n",
      "2947\n",
      "tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "2948\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "2949\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "2950\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "2951\n",
      "tensor(0.2872, grad_fn=<MseLossBackward0>)\n",
      "2952\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "2953\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "2954\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "2955\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "2956\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "2957\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "2958\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "2959\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "2960\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "2961\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "2962\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "2963\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "2964\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "2965\n",
      "tensor(0.2004, grad_fn=<MseLossBackward0>)\n",
      "2966\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "2967\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "2968\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2969\n",
      "tensor(0.2214, grad_fn=<MseLossBackward0>)\n",
      "2970\n",
      "tensor(0.1115, grad_fn=<MseLossBackward0>)\n",
      "2971\n",
      "tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "2972\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "2973\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "2974\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "2975\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "2976\n",
      "tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "2977\n",
      "tensor(0.2921, grad_fn=<MseLossBackward0>)\n",
      "2978\n",
      "tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "2979\n",
      "tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "2980\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "2981\n",
      "tensor(0.1665, grad_fn=<MseLossBackward0>)\n",
      "2982\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "2983\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "2984\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "2985\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "2986\n",
      "tensor(0.1631, grad_fn=<MseLossBackward0>)\n",
      "2987\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "2988\n",
      "tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "2989\n",
      "tensor(0.2097, grad_fn=<MseLossBackward0>)\n",
      "2990\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "2991\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "2992\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "2993\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "2994\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "2995\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "2996\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "2997\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "2998\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "2999\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "3000\n",
      "tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "3001\n",
      "tensor(0.1323, grad_fn=<MseLossBackward0>)\n",
      "3002\n",
      "tensor(0.1365, grad_fn=<MseLossBackward0>)\n",
      "3003\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3004\n",
      "tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "3005\n",
      "tensor(0.1929, grad_fn=<MseLossBackward0>)\n",
      "3006\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "3007\n",
      "tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "3008\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "3009\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "3010\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "3011\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3012\n",
      "tensor(0.1509, grad_fn=<MseLossBackward0>)\n",
      "3013\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "3014\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "3015\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "3016\n",
      "tensor(0.1232, grad_fn=<MseLossBackward0>)\n",
      "3017\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "3018\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "3019\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "3020\n",
      "tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "3021\n",
      "tensor(0.2827, grad_fn=<MseLossBackward0>)\n",
      "3022\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3023\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "3024\n",
      "tensor(0.1194, grad_fn=<MseLossBackward0>)\n",
      "3025\n",
      "tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "3026\n",
      "tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
      "3027\n",
      "tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "3028\n",
      "tensor(0.1994, grad_fn=<MseLossBackward0>)\n",
      "3029\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "3030\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "3031\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "3032\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "3033\n",
      "tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "3034\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "3035\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "3036\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "3037\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "3038\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "3039\n",
      "tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "3040\n",
      "tensor(0.1880, grad_fn=<MseLossBackward0>)\n",
      "3041\n",
      "tensor(0.2023, grad_fn=<MseLossBackward0>)\n",
      "3042\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "3043\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "3044\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "3045\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "3046\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "3047\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3048\n",
      "tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "3049\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "3050\n",
      "tensor(0.1939, grad_fn=<MseLossBackward0>)\n",
      "3051\n",
      "tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "3052\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "3053\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "3054\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "3055\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "3056\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "3057\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "3058\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "3059\n",
      "tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "3060\n",
      "tensor(0.2564, grad_fn=<MseLossBackward0>)\n",
      "3061\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "3062\n",
      "tensor(0.1529, grad_fn=<MseLossBackward0>)\n",
      "3063\n",
      "tensor(0.1596, grad_fn=<MseLossBackward0>)\n",
      "3064\n",
      "tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "3065\n",
      "tensor(0.2082, grad_fn=<MseLossBackward0>)\n",
      "3066\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "3067\n",
      "tensor(0.1932, grad_fn=<MseLossBackward0>)\n",
      "3068\n",
      "tensor(0.1563, grad_fn=<MseLossBackward0>)\n",
      "3069\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3070\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "3071\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "3072\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "3073\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "3074\n",
      "tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "3075\n",
      "tensor(0.1560, grad_fn=<MseLossBackward0>)\n",
      "3076\n",
      "tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "3077\n",
      "tensor(0.1614, grad_fn=<MseLossBackward0>)\n",
      "3078\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "3079\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "3080\n",
      "tensor(0.1768, grad_fn=<MseLossBackward0>)\n",
      "3081\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "3082\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "3083\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "3084\n",
      "tensor(0.1917, grad_fn=<MseLossBackward0>)\n",
      "3085\n",
      "tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "3086\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "3087\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "3088\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "3089\n",
      "tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "3090\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "3091\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "3092\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3093\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "3094\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "3095\n",
      "tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "3096\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "3097\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "3098\n",
      "tensor(0.0958, grad_fn=<MseLossBackward0>)\n",
      "3099\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([507, 1, 128])) that is different to the input size (torch.Size([507, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "3101\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "3102\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "3103\n",
      "tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "3104\n",
      "tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "3105\n",
      "tensor(0.1607, grad_fn=<MseLossBackward0>)\n",
      "3106\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "3107\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "3108\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "3109\n",
      "tensor(0.1621, grad_fn=<MseLossBackward0>)\n",
      "3110\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "3111\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "3112\n",
      "tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "3113\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "3114\n",
      "tensor(0.0980, grad_fn=<MseLossBackward0>)\n",
      "3115\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "3116\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "3117\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "3118\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "3119\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "3120\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "3121\n",
      "tensor(0.1212, grad_fn=<MseLossBackward0>)\n",
      "3122\n",
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "3123\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "3124\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "3125\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "3126\n",
      "tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "3127\n",
      "tensor(0.2692, grad_fn=<MseLossBackward0>)\n",
      "3128\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "3129\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3130\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "3131\n",
      "tensor(0.2989, grad_fn=<MseLossBackward0>)\n",
      "3132\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "3133\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "3134\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "3135\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "3136\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3137\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "3138\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "3139\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "3140\n",
      "tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "3141\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3142\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "3143\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "3144\n",
      "tensor(0.2458, grad_fn=<MseLossBackward0>)\n",
      "3145\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "3146\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "3147\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "3148\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "3149\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "3150\n",
      "tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "3151\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "3152\n",
      "tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "3153\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "3154\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "3155\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "3156\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "3157\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "3158\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "3159\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "3160\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "3161\n",
      "tensor(0.1932, grad_fn=<MseLossBackward0>)\n",
      "3162\n",
      "tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "3163\n",
      "tensor(0.1808, grad_fn=<MseLossBackward0>)\n",
      "3164\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "3165\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "3166\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "3167\n",
      "tensor(0.1599, grad_fn=<MseLossBackward0>)\n",
      "3168\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "3169\n",
      "tensor(0.1874, grad_fn=<MseLossBackward0>)\n",
      "3170\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([140, 1, 128])) that is different to the input size (torch.Size([140, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([118, 1, 128])) that is different to the input size (torch.Size([118, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2599, grad_fn=<MseLossBackward0>)\n",
      "3172\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "3173\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "3174\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "3175\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "3176\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "3177\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "3178\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3179\n",
      "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "3180\n",
      "tensor(0.1300, grad_fn=<MseLossBackward0>)\n",
      "3181\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "3182\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "3183\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "3184\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "3185\n",
      "tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "3186\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "3187\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "3188\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "3189\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "3190\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "3191\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([467, 1, 128])) that is different to the input size (torch.Size([467, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "3193\n",
      "tensor(0.1518, grad_fn=<MseLossBackward0>)\n",
      "3194\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "3195\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "3196\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "3197\n",
      "tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "3198\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "3199\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "3200\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "3201\n",
      "tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "3202\n",
      "tensor(0.1627, grad_fn=<MseLossBackward0>)\n",
      "3203\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "3204\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "3205\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "3206\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "3207\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3208\n",
      "tensor(0.1679, grad_fn=<MseLossBackward0>)\n",
      "3209\n",
      "tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "3210\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "3211\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "3212\n",
      "tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "3213\n",
      "tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "3214\n",
      "tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "3215\n",
      "tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "3216\n",
      "tensor(0.2808, grad_fn=<MseLossBackward0>)\n",
      "3217\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "3218\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "3219\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "3220\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "3221\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "3222\n",
      "tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "3223\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "3224\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "3225\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "3226\n",
      "tensor(0.2170, grad_fn=<MseLossBackward0>)\n",
      "3227\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "3228\n",
      "tensor(0.3379, grad_fn=<MseLossBackward0>)\n",
      "3229\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "3230\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3231\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "3232\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "3233\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "3234\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "3235\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "3236\n",
      "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "3237\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "3238\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "3239\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "3240\n",
      "tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "3241\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "3242\n",
      "tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "3243\n",
      "tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "3244\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "3245\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "3246\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "3247\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "3248\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "3249\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "3250\n",
      "tensor(0.1374, grad_fn=<MseLossBackward0>)\n",
      "3251\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "3252\n",
      "tensor(0.2603, grad_fn=<MseLossBackward0>)\n",
      "3253\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "3254\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "3255\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "3256\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "3257\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "3258\n",
      "tensor(0.2877, grad_fn=<MseLossBackward0>)\n",
      "3259\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "3260\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "3261\n",
      "tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "3262\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "3263\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "3264\n",
      "tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "3265\n",
      "tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "3266\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "3267\n",
      "tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
      "3268\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "3269\n",
      "tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "3270\n",
      "tensor(0.1346, grad_fn=<MseLossBackward0>)\n",
      "3271\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "3272\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "3273\n",
      "tensor(0.1909, grad_fn=<MseLossBackward0>)\n",
      "3274\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "3275\n",
      "tensor(0.1617, grad_fn=<MseLossBackward0>)\n",
      "3276\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "3277\n",
      "tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "3278\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "3279\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "3280\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "3281\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "3282\n",
      "tensor(0.1261, grad_fn=<MseLossBackward0>)\n",
      "3283\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3284\n",
      "tensor(0.1783, grad_fn=<MseLossBackward0>)\n",
      "3285\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "3286\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "3287\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3288\n",
      "tensor(0.2077, grad_fn=<MseLossBackward0>)\n",
      "3289\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "3290\n",
      "tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "3291\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "3292\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "3293\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "3294\n",
      "tensor(0.1187, grad_fn=<MseLossBackward0>)\n",
      "3295\n",
      "tensor(0.1367, grad_fn=<MseLossBackward0>)\n",
      "3296\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "3297\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "3298\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "3299\n",
      "tensor(0.1565, grad_fn=<MseLossBackward0>)\n",
      "3300\n",
      "tensor(0.1615, grad_fn=<MseLossBackward0>)\n",
      "3301\n",
      "tensor(0.2459, grad_fn=<MseLossBackward0>)\n",
      "3302\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "3303\n",
      "tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "3304\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "3305\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "3306\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "3307\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3308\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3309\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "3310\n",
      "tensor(0.1604, grad_fn=<MseLossBackward0>)\n",
      "3311\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "3312\n",
      "tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
      "3313\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "3314\n",
      "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
      "3315\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "3316\n",
      "tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "3317\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "3318\n",
      "tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "3319\n",
      "tensor(0.1943, grad_fn=<MseLossBackward0>)\n",
      "3320\n",
      "tensor(0.1509, grad_fn=<MseLossBackward0>)\n",
      "3321\n",
      "tensor(0.2164, grad_fn=<MseLossBackward0>)\n",
      "3322\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "3323\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "3324\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "3325\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "3326\n",
      "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "3327\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "3328\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "3329\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "3330\n",
      "tensor(0.1080, grad_fn=<MseLossBackward0>)\n",
      "3331\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "3332\n",
      "tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "3333\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "3334\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "3335\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "3336\n",
      "tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "3337\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3338\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "3339\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "3340\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "3341\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "3342\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "3343\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "3344\n",
      "tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "3345\n",
      "tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "3346\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "3347\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "3348\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "3349\n",
      "tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "3350\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "3351\n",
      "tensor(0.1956, grad_fn=<MseLossBackward0>)\n",
      "3352\n",
      "tensor(0.1419, grad_fn=<MseLossBackward0>)\n",
      "3353\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "3354\n",
      "tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "3355\n",
      "tensor(0.1886, grad_fn=<MseLossBackward0>)\n",
      "3356\n",
      "tensor(0.1377, grad_fn=<MseLossBackward0>)\n",
      "3357\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "3358\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "3359\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "3360\n",
      "tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "3361\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "3362\n",
      "tensor(0.1648, grad_fn=<MseLossBackward0>)\n",
      "3363\n",
      "tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "3364\n",
      "tensor(0.1080, grad_fn=<MseLossBackward0>)\n",
      "3365\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "3366\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "3367\n",
      "tensor(0.1711, grad_fn=<MseLossBackward0>)\n",
      "3368\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "3369\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "3370\n",
      "tensor(0.1219, grad_fn=<MseLossBackward0>)\n",
      "3371\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "3372\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "3373\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "3374\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3375\n",
      "tensor(0.2177, grad_fn=<MseLossBackward0>)\n",
      "3376\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "3377\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "3378\n",
      "tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "3379\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "3380\n",
      "tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "3381\n",
      "tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "3382\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "3383\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "3384\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "3385\n",
      "tensor(0.1567, grad_fn=<MseLossBackward0>)\n",
      "3386\n",
      "tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "3387\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "3388\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "3389\n",
      "tensor(0.1450, grad_fn=<MseLossBackward0>)\n",
      "3390\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "3391\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "3392\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "3393\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "3394\n",
      "tensor(0.1378, grad_fn=<MseLossBackward0>)\n",
      "3395\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3396\n",
      "tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "3397\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "3398\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "3399\n",
      "tensor(0.1988, grad_fn=<MseLossBackward0>)\n",
      "3400\n",
      "tensor(0.1699, grad_fn=<MseLossBackward0>)\n",
      "3401\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "3402\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "3403\n",
      "tensor(0.2530, grad_fn=<MseLossBackward0>)\n",
      "3404\n",
      "tensor(0.1562, grad_fn=<MseLossBackward0>)\n",
      "3405\n",
      "tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "3406\n",
      "tensor(0.2124, grad_fn=<MseLossBackward0>)\n",
      "3407\n",
      "tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "3408\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "3409\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "3410\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "3411\n",
      "tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "3412\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "3413\n",
      "tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "3414\n",
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "3415\n",
      "tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "3416\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "3417\n",
      "tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "3418\n",
      "tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "3419\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "3420\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "3421\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "3422\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "3423\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "3424\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "3425\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "3426\n",
      "tensor(0.2148, grad_fn=<MseLossBackward0>)\n",
      "3427\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "3428\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "3429\n",
      "tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "3430\n",
      "tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "3431\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "3432\n",
      "tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "3433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([94, 1, 128])) that is different to the input size (torch.Size([94, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "3434\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "3435\n",
      "tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "3436\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "3437\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "3438\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "3439\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "3440\n",
      "tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "3441\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "3442\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "3443\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "3444\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "3445\n",
      "tensor(0.1617, grad_fn=<MseLossBackward0>)\n",
      "3446\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "3447\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3448\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "3449\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "3450\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "3451\n",
      "tensor(0.1616, grad_fn=<MseLossBackward0>)\n",
      "3452\n",
      "tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "3453\n",
      "tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "3454\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "3455\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "3456\n",
      "tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "3457\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "3458\n",
      "tensor(0.2167, grad_fn=<MseLossBackward0>)\n",
      "3459\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "3460\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "3461\n",
      "tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "3462\n",
      "tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "3463\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "3464\n",
      "tensor(0.1300, grad_fn=<MseLossBackward0>)\n",
      "3465\n",
      "tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "3466\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "3467\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "3468\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "3469\n",
      "tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "3470\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "3471\n",
      "tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
      "3472\n",
      "tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "3473\n",
      "tensor(0.2101, grad_fn=<MseLossBackward0>)\n",
      "3474\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "3475\n",
      "tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "3476\n",
      "tensor(0.1353, grad_fn=<MseLossBackward0>)\n",
      "3477\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "3478\n",
      "tensor(0.1104, grad_fn=<MseLossBackward0>)\n",
      "3479\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "3480\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "3481\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "3482\n",
      "tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "3483\n",
      "tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "3484\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([189, 1, 128])) that is different to the input size (torch.Size([189, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "3486\n",
      "tensor(0.1648, grad_fn=<MseLossBackward0>)\n",
      "3487\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "3488\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "3489\n",
      "tensor(0.1653, grad_fn=<MseLossBackward0>)\n",
      "3490\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "3491\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "3492\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "3493\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "3494\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "3495\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "3496\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "3497\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "3498\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "3499\n",
      "tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "3500\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "3501\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "3502\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "3503\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "3504\n",
      "tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "3505\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3506\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "3507\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "3508\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "3509\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "3510\n",
      "tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "3511\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "3512\n",
      "tensor(0.2638, grad_fn=<MseLossBackward0>)\n",
      "3513\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "3514\n",
      "tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "3515\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "3516\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "3517\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "3518\n",
      "tensor(0.2157, grad_fn=<MseLossBackward0>)\n",
      "3519\n",
      "tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "3520\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "3521\n",
      "tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "3522\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "3523\n",
      "tensor(0.1468, grad_fn=<MseLossBackward0>)\n",
      "3524\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "3525\n",
      "tensor(0.1802, grad_fn=<MseLossBackward0>)\n",
      "3526\n",
      "tensor(0.2005, grad_fn=<MseLossBackward0>)\n",
      "3527\n",
      "tensor(0.1909, grad_fn=<MseLossBackward0>)\n",
      "3528\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "3529\n",
      "tensor(0.3013, grad_fn=<MseLossBackward0>)\n",
      "3530\n",
      "tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "3531\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "3532\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "3533\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "3534\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "3535\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "3536\n",
      "tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
      "3537\n",
      "tensor(0.1449, grad_fn=<MseLossBackward0>)\n",
      "3538\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "3539\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "3540\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "3541\n",
      "tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
      "3542\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "3543\n",
      "tensor(0.2179, grad_fn=<MseLossBackward0>)\n",
      "3544\n",
      "tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "3545\n",
      "tensor(0.1880, grad_fn=<MseLossBackward0>)\n",
      "3546\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "3547\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "3548\n",
      "tensor(0.1351, grad_fn=<MseLossBackward0>)\n",
      "3549\n",
      "tensor(0.1477, grad_fn=<MseLossBackward0>)\n",
      "3550\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "3551\n",
      "tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "3552\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "3553\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "3554\n",
      "tensor(0.1846, grad_fn=<MseLossBackward0>)\n",
      "3555\n",
      "tensor(0.1662, grad_fn=<MseLossBackward0>)\n",
      "3556\n",
      "tensor(0.2488, grad_fn=<MseLossBackward0>)\n",
      "3557\n",
      "tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "3558\n",
      "tensor(0.1918, grad_fn=<MseLossBackward0>)\n",
      "3559\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "3560\n",
      "tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "3561\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "3562\n",
      "tensor(0.1538, grad_fn=<MseLossBackward0>)\n",
      "3563\n",
      "tensor(0.1726, grad_fn=<MseLossBackward0>)\n",
      "3564\n",
      "tensor(0.2161, grad_fn=<MseLossBackward0>)\n",
      "3565\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "3566\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "3567\n",
      "tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "3568\n",
      "tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "3569\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3570\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "3571\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "3572\n",
      "tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "3573\n",
      "tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "3574\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "3575\n",
      "tensor(0.1876, grad_fn=<MseLossBackward0>)\n",
      "3576\n",
      "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "3577\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "3578\n",
      "tensor(0.2770, grad_fn=<MseLossBackward0>)\n",
      "3579\n",
      "tensor(0.2431, grad_fn=<MseLossBackward0>)\n",
      "3580\n",
      "tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "3581\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "3582\n",
      "tensor(0.3101, grad_fn=<MseLossBackward0>)\n",
      "3583\n",
      "tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "3584\n",
      "tensor(0.1667, grad_fn=<MseLossBackward0>)\n",
      "3585\n",
      "tensor(0.1588, grad_fn=<MseLossBackward0>)\n",
      "3586\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3587\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "3588\n",
      "tensor(0.1858, grad_fn=<MseLossBackward0>)\n",
      "3589\n",
      "tensor(0.2253, grad_fn=<MseLossBackward0>)\n",
      "3590\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "3591\n",
      "tensor(0.1705, grad_fn=<MseLossBackward0>)\n",
      "3592\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "3593\n",
      "tensor(0.1717, grad_fn=<MseLossBackward0>)\n",
      "3594\n",
      "tensor(0.1843, grad_fn=<MseLossBackward0>)\n",
      "3595\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "3596\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "3597\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "3598\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "3599\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "3600\n",
      "tensor(0.3439, grad_fn=<MseLossBackward0>)\n",
      "3601\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "3602\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "3603\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "3604\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "3605\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "3606\n",
      "tensor(0.1579, grad_fn=<MseLossBackward0>)\n",
      "3607\n",
      "tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "3608\n",
      "tensor(0.3848, grad_fn=<MseLossBackward0>)\n",
      "3609\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "3610\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "3611\n",
      "tensor(0.2265, grad_fn=<MseLossBackward0>)\n",
      "3612\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "3613\n",
      "tensor(0.2235, grad_fn=<MseLossBackward0>)\n",
      "3614\n",
      "tensor(0.2073, grad_fn=<MseLossBackward0>)\n",
      "3615\n",
      "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "3616\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "3617\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "3618\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "3619\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "3620\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "3621\n",
      "tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "3622\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "3623\n",
      "tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "3624\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "3625\n",
      "tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "3626\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "3627\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "3628\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "3629\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "3630\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "3631\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "3632\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "3633\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "3634\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "3635\n",
      "tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "3636\n",
      "tensor(0.2082, grad_fn=<MseLossBackward0>)\n",
      "3637\n",
      "tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "3638\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "3639\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "3640\n",
      "tensor(0.2017, grad_fn=<MseLossBackward0>)\n",
      "3641\n",
      "tensor(0.1323, grad_fn=<MseLossBackward0>)\n",
      "3642\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "3643\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "3644\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "3645\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "3646\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "3647\n",
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "3648\n",
      "tensor(0.1734, grad_fn=<MseLossBackward0>)\n",
      "3649\n",
      "tensor(0.1867, grad_fn=<MseLossBackward0>)\n",
      "3650\n",
      "tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "3651\n",
      "tensor(0.3083, grad_fn=<MseLossBackward0>)\n",
      "3652\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "3653\n",
      "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "3654\n",
      "tensor(0.2157, grad_fn=<MseLossBackward0>)\n",
      "3655\n",
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "3656\n",
      "tensor(0.1973, grad_fn=<MseLossBackward0>)\n",
      "3657\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "3658\n",
      "tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "3659\n",
      "tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "3660\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "3661\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "3662\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "3663\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "3664\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "3665\n",
      "tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "3666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([262, 1, 128])) that is different to the input size (torch.Size([262, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "3667\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "3668\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "3669\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "3670\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "3671\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "3672\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "3673\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "3674\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "3675\n",
      "tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "3676\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "3677\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "3678\n",
      "tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "3679\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3680\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "3681\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "3682\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3683\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "3684\n",
      "tensor(0.2690, grad_fn=<MseLossBackward0>)\n",
      "3685\n",
      "tensor(0.2016, grad_fn=<MseLossBackward0>)\n",
      "3686\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "3687\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "3688\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "3689\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "3690\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "3691\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "3692\n",
      "tensor(0.1929, grad_fn=<MseLossBackward0>)\n",
      "3693\n",
      "tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "3694\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "3695\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3696\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "3697\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "3698\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "3699\n",
      "tensor(0.1814, grad_fn=<MseLossBackward0>)\n",
      "3700\n",
      "tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "3701\n",
      "tensor(0.2145, grad_fn=<MseLossBackward0>)\n",
      "3702\n",
      "tensor(0.1528, grad_fn=<MseLossBackward0>)\n",
      "3703\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "3704\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "3705\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "3706\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "3707\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "3708\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "3709\n",
      "tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "3710\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "3711\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "3712\n",
      "tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "3713\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "3714\n",
      "tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "3715\n",
      "tensor(0.2205, grad_fn=<MseLossBackward0>)\n",
      "3716\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "3717\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "3718\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3719\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "3720\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "3721\n",
      "tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "3722\n",
      "tensor(0.1503, grad_fn=<MseLossBackward0>)\n",
      "3723\n",
      "tensor(0.3153, grad_fn=<MseLossBackward0>)\n",
      "3724\n",
      "tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "3725\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "3726\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "3727\n",
      "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "3728\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "3729\n",
      "tensor(0.2468, grad_fn=<MseLossBackward0>)\n",
      "3730\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "3731\n",
      "tensor(0.1525, grad_fn=<MseLossBackward0>)\n",
      "3732\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "3733\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "3734\n",
      "tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
      "3735\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "3736\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "3737\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "3738\n",
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "3739\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "3740\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "3741\n",
      "tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "3742\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "3743\n",
      "tensor(0.1468, grad_fn=<MseLossBackward0>)\n",
      "3744\n",
      "tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "3745\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "3746\n",
      "tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "3747\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "3748\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "3749\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "3750\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "3751\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "3752\n",
      "tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "3753\n",
      "tensor(0.2203, grad_fn=<MseLossBackward0>)\n",
      "3754\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "3755\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "3756\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "3757\n",
      "tensor(0.1600, grad_fn=<MseLossBackward0>)\n",
      "3758\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "3759\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "3760\n",
      "tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "3761\n",
      "tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "3762\n",
      "tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "3763\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "3764\n",
      "tensor(0.3477, grad_fn=<MseLossBackward0>)\n",
      "3765\n",
      "tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "3766\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "3767\n",
      "tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "3768\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "3769\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "3770\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "3771\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "3772\n",
      "tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "3773\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "3774\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3775\n",
      "tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
      "3776\n",
      "tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "3777\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "3778\n",
      "tensor(0.1614, grad_fn=<MseLossBackward0>)\n",
      "3779\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "3780\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "3781\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "3782\n",
      "tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "3783\n",
      "tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "3784\n",
      "tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "3785\n",
      "tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "3786\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "3787\n",
      "tensor(0.1245, grad_fn=<MseLossBackward0>)\n",
      "3788\n",
      "tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "3789\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "3790\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "3791\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "3792\n",
      "tensor(0.1373, grad_fn=<MseLossBackward0>)\n",
      "3793\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "3794\n",
      "tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "3795\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "3796\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "3797\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "3798\n",
      "tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "3799\n",
      "tensor(0.1544, grad_fn=<MseLossBackward0>)\n",
      "3800\n",
      "tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "3801\n",
      "tensor(0.1754, grad_fn=<MseLossBackward0>)\n",
      "3802\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "3803\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "3804\n",
      "tensor(0.1396, grad_fn=<MseLossBackward0>)\n",
      "3805\n",
      "tensor(0.1998, grad_fn=<MseLossBackward0>)\n",
      "3806\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "3807\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "3808\n",
      "tensor(0.1337, grad_fn=<MseLossBackward0>)\n",
      "3809\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "3810\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "3811\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "3812\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "3813\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "3814\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "3815\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "3816\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "3817\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "3818\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "3819\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "3820\n",
      "tensor(0.1520, grad_fn=<MseLossBackward0>)\n",
      "3821\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "3822\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "3823\n",
      "tensor(0.1595, grad_fn=<MseLossBackward0>)\n",
      "3824\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "3825\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "3826\n",
      "tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "3827\n",
      "tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "3828\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "3829\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "3830\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "3831\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "3832\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "3833\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "3834\n",
      "tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "3835\n",
      "tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "3836\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "3837\n",
      "tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "3838\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "3839\n",
      "tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "3840\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "3841\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "3842\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "3843\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "3844\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "3845\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "3846\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "3847\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "3848\n",
      "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "3849\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "3850\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "3851\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "3852\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "3853\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "3854\n",
      "tensor(0.2181, grad_fn=<MseLossBackward0>)\n",
      "3855\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "3856\n",
      "tensor(0.1591, grad_fn=<MseLossBackward0>)\n",
      "3857\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "3858\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "3859\n",
      "tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "3860\n",
      "tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "3861\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "3862\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "3863\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "3864\n",
      "tensor(0.1769, grad_fn=<MseLossBackward0>)\n",
      "3865\n",
      "tensor(0.1583, grad_fn=<MseLossBackward0>)\n",
      "3866\n",
      "tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "3867\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "3868\n",
      "tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "3869\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "3870\n",
      "tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "3871\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "3872\n",
      "tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "3873\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "3874\n",
      "tensor(0.1938, grad_fn=<MseLossBackward0>)\n",
      "3875\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "3876\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "3877\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "3878\n",
      "tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
      "3879\n",
      "tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "3880\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "3881\n",
      "tensor(0.1650, grad_fn=<MseLossBackward0>)\n",
      "3882\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "3883\n",
      "tensor(0.1783, grad_fn=<MseLossBackward0>)\n",
      "3884\n",
      "tensor(0.3171, grad_fn=<MseLossBackward0>)\n",
      "3885\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "3886\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "3887\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "3888\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "3889\n",
      "tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "3890\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "3891\n",
      "tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "3892\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "3893\n",
      "tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "3894\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "3895\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "3896\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "3897\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "3898\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "3899\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "3900\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "3901\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "3902\n",
      "tensor(0.1460, grad_fn=<MseLossBackward0>)\n",
      "3903\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "3904\n",
      "tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
      "3905\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "3906\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "3907\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "3908\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "3909\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "3910\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "3911\n",
      "tensor(0.3482, grad_fn=<MseLossBackward0>)\n",
      "3912\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "3913\n",
      "tensor(0.1207, grad_fn=<MseLossBackward0>)\n",
      "3914\n",
      "tensor(0.1753, grad_fn=<MseLossBackward0>)\n",
      "3915\n",
      "tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "3916\n",
      "tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "3917\n",
      "tensor(0.2725, grad_fn=<MseLossBackward0>)\n",
      "3918\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "3919\n",
      "tensor(0.2822, grad_fn=<MseLossBackward0>)\n",
      "3920\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "3921\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "3922\n",
      "tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "3923\n",
      "tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "3924\n",
      "tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
      "3925\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "3926\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "3927\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "3928\n",
      "tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "3929\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "3930\n",
      "tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "3931\n",
      "tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "3932\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "3933\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "3934\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "3935\n",
      "tensor(0.1795, grad_fn=<MseLossBackward0>)\n",
      "3936\n",
      "tensor(0.1080, grad_fn=<MseLossBackward0>)\n",
      "3937\n",
      "tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "3938\n",
      "tensor(0.1846, grad_fn=<MseLossBackward0>)\n",
      "3939\n",
      "tensor(0.1317, grad_fn=<MseLossBackward0>)\n",
      "3940\n",
      "tensor(0.2196, grad_fn=<MseLossBackward0>)\n",
      "3941\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "3942\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "3943\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "3944\n",
      "tensor(0.1811, grad_fn=<MseLossBackward0>)\n",
      "3945\n",
      "tensor(0.0958, grad_fn=<MseLossBackward0>)\n",
      "3946\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "3947\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "3948\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "3949\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "3950\n",
      "tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "3951\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "3952\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "3953\n",
      "tensor(0.1849, grad_fn=<MseLossBackward0>)\n",
      "3954\n",
      "tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "3955\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "3956\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "3957\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "3958\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "3959\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "3960\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "3961\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "3962\n",
      "tensor(0.1191, grad_fn=<MseLossBackward0>)\n",
      "3963\n",
      "tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "3964\n",
      "tensor(0.1864, grad_fn=<MseLossBackward0>)\n",
      "3965\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "3966\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "3967\n",
      "tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "3968\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "3969\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "3970\n",
      "tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "3971\n",
      "tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "3972\n",
      "tensor(0.2660, grad_fn=<MseLossBackward0>)\n",
      "3973\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "3974\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "3975\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "3976\n",
      "tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "3977\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "3978\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "3979\n",
      "tensor(0.2209, grad_fn=<MseLossBackward0>)\n",
      "3980\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "3981\n",
      "tensor(0.1764, grad_fn=<MseLossBackward0>)\n",
      "3982\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "3983\n",
      "tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "3984\n",
      "tensor(0.1943, grad_fn=<MseLossBackward0>)\n",
      "3985\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "3986\n",
      "tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "3987\n",
      "tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "3988\n",
      "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "3989\n",
      "tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "3990\n",
      "tensor(0.1690, grad_fn=<MseLossBackward0>)\n",
      "3991\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "3992\n",
      "tensor(0.1245, grad_fn=<MseLossBackward0>)\n",
      "3993\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "3994\n",
      "tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "3995\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "3996\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "3997\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "3998\n",
      "tensor(0.1566, grad_fn=<MseLossBackward0>)\n",
      "3999\n",
      "tensor(0.3072, grad_fn=<MseLossBackward0>)\n",
      "4000\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "4001\n",
      "tensor(0.2550, grad_fn=<MseLossBackward0>)\n",
      "4002\n",
      "tensor(0.1336, grad_fn=<MseLossBackward0>)\n",
      "4003\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "4004\n",
      "tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "4005\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "4006\n",
      "tensor(0.1904, grad_fn=<MseLossBackward0>)\n",
      "4007\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "4008\n",
      "tensor(0.1637, grad_fn=<MseLossBackward0>)\n",
      "4009\n",
      "tensor(0.4596, grad_fn=<MseLossBackward0>)\n",
      "4010\n",
      "tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "4011\n",
      "tensor(0.2165, grad_fn=<MseLossBackward0>)\n",
      "4012\n",
      "tensor(0.1636, grad_fn=<MseLossBackward0>)\n",
      "4013\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4014\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "4015\n",
      "tensor(0.1691, grad_fn=<MseLossBackward0>)\n",
      "4016\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "4017\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "4018\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "4019\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "4020\n",
      "tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
      "4021\n",
      "tensor(0.1847, grad_fn=<MseLossBackward0>)\n",
      "4022\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "4023\n",
      "tensor(0.2565, grad_fn=<MseLossBackward0>)\n",
      "4024\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "4025\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "4026\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "4027\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "4028\n",
      "tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "4029\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "4030\n",
      "tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "4031\n",
      "tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "4032\n",
      "tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "4033\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "4034\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "4035\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "4036\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "4037\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "4038\n",
      "tensor(0.1791, grad_fn=<MseLossBackward0>)\n",
      "4039\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "4040\n",
      "tensor(0.1395, grad_fn=<MseLossBackward0>)\n",
      "4041\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "4042\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "4043\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "4044\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "4045\n",
      "tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "4046\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "4047\n",
      "tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "4048\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "4049\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "4050\n",
      "tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "4051\n",
      "tensor(0.2061, grad_fn=<MseLossBackward0>)\n",
      "4052\n",
      "tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "4053\n",
      "tensor(0.1252, grad_fn=<MseLossBackward0>)\n",
      "4054\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "4055\n",
      "tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "4056\n",
      "tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "4057\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "4058\n",
      "tensor(0.2197, grad_fn=<MseLossBackward0>)\n",
      "4059\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "4060\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "4061\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "4062\n",
      "tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "4063\n",
      "tensor(0.2440, grad_fn=<MseLossBackward0>)\n",
      "4064\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "4065\n",
      "tensor(0.2518, grad_fn=<MseLossBackward0>)\n",
      "4066\n",
      "tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "4067\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "4068\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "4069\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "4070\n",
      "tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "4071\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "4072\n",
      "tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "4073\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "4074\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "4075\n",
      "tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "4076\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "4077\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "4078\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "4079\n",
      "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "4080\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "4081\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "4082\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "4083\n",
      "tensor(0.3140, grad_fn=<MseLossBackward0>)\n",
      "4084\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "4085\n",
      "tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "4086\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "4087\n",
      "tensor(0.1941, grad_fn=<MseLossBackward0>)\n",
      "4088\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "4089\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "4090\n",
      "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "4091\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "4092\n",
      "tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "4093\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "4094\n",
      "tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "4095\n",
      "tensor(0.2037, grad_fn=<MseLossBackward0>)\n",
      "4096\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "4097\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "4098\n",
      "tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "4099\n",
      "tensor(0.1207, grad_fn=<MseLossBackward0>)\n",
      "4100\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "4101\n",
      "tensor(0.1207, grad_fn=<MseLossBackward0>)\n",
      "4102\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "4103\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "4104\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "4105\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "4106\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "4107\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "4108\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "4109\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "4110\n",
      "tensor(0.1803, grad_fn=<MseLossBackward0>)\n",
      "4111\n",
      "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "4112\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "4113\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "4114\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "4115\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "4116\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "4117\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4118\n",
      "tensor(0.2142, grad_fn=<MseLossBackward0>)\n",
      "4119\n",
      "tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "4120\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "4121\n",
      "tensor(0.1255, grad_fn=<MseLossBackward0>)\n",
      "4122\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "4123\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "4124\n",
      "tensor(0.1601, grad_fn=<MseLossBackward0>)\n",
      "4125\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "4126\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "4127\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "4128\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "4129\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "4130\n",
      "tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "4131\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "4132\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "4133\n",
      "tensor(0.1194, grad_fn=<MseLossBackward0>)\n",
      "4134\n",
      "tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "4135\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4136\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "4137\n",
      "tensor(0.1788, grad_fn=<MseLossBackward0>)\n",
      "4138\n",
      "tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "4139\n",
      "tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "4140\n",
      "tensor(0.1775, grad_fn=<MseLossBackward0>)\n",
      "4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([124, 1, 128])) that is different to the input size (torch.Size([124, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1921, grad_fn=<MseLossBackward0>)\n",
      "4142\n",
      "tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "4143\n",
      "tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "4144\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "4145\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "4146\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "4147\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "4148\n",
      "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "4149\n",
      "tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
      "4150\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "4151\n",
      "tensor(0.1497, grad_fn=<MseLossBackward0>)\n",
      "4152\n",
      "tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "4153\n",
      "tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "4154\n",
      "tensor(0.2562, grad_fn=<MseLossBackward0>)\n",
      "4155\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "4156\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "4157\n",
      "tensor(0.3111, grad_fn=<MseLossBackward0>)\n",
      "4158\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "4159\n",
      "tensor(0.1639, grad_fn=<MseLossBackward0>)\n",
      "4160\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "4161\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "4162\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "4163\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "4164\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "4165\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "4166\n",
      "tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
      "4167\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "4168\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "4169\n",
      "tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "4170\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "4171\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "4172\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "4173\n",
      "tensor(0.0748, grad_fn=<MseLossBackward0>)\n",
      "4174\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "4175\n",
      "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "4176\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "4177\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "4178\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "4179\n",
      "tensor(0.1700, grad_fn=<MseLossBackward0>)\n",
      "4180\n",
      "tensor(0.0995, grad_fn=<MseLossBackward0>)\n",
      "4181\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "4182\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "4183\n",
      "tensor(0.1194, grad_fn=<MseLossBackward0>)\n",
      "4184\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "4185\n",
      "tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "4186\n",
      "tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "4187\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "4188\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "4189\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "4190\n",
      "tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "4191\n",
      "tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "4192\n",
      "tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
      "4193\n",
      "tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "4194\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "4195\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "4196\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "4197\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "4198\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "4199\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "4200\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "4201\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "4202\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "4203\n",
      "tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
      "4204\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "4205\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "4206\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4207\n",
      "tensor(0.1144, grad_fn=<MseLossBackward0>)\n",
      "4208\n",
      "tensor(0.1328, grad_fn=<MseLossBackward0>)\n",
      "4209\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "4210\n",
      "tensor(0.1620, grad_fn=<MseLossBackward0>)\n",
      "4211\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "4212\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "4213\n",
      "tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
      "4214\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "4215\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "4216\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4217\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "4218\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "4219\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "4220\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4221\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "4222\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "4223\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "4224\n",
      "tensor(0.1955, grad_fn=<MseLossBackward0>)\n",
      "4225\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "4226\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "4227\n",
      "tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "4228\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "4229\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "4230\n",
      "tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "4231\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "4232\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "4233\n",
      "tensor(0.2471, grad_fn=<MseLossBackward0>)\n",
      "4234\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "4235\n",
      "tensor(0.1770, grad_fn=<MseLossBackward0>)\n",
      "4236\n",
      "tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "4237\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "4238\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "4239\n",
      "tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "4240\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "4241\n",
      "tensor(0.1734, grad_fn=<MseLossBackward0>)\n",
      "4242\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "4243\n",
      "tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "4244\n",
      "tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "4245\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4246\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4247\n",
      "tensor(0.2754, grad_fn=<MseLossBackward0>)\n",
      "4248\n",
      "tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "4249\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "4250\n",
      "tensor(0.1315, grad_fn=<MseLossBackward0>)\n",
      "4251\n",
      "tensor(0.1418, grad_fn=<MseLossBackward0>)\n",
      "4252\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "4253\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "4254\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "4255\n",
      "tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "4256\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4257\n",
      "tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "4258\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "4259\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "4260\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "4261\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "4262\n",
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "4263\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "4264\n",
      "tensor(0.1637, grad_fn=<MseLossBackward0>)\n",
      "4265\n",
      "tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "4266\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "4267\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "4268\n",
      "tensor(0.1155, grad_fn=<MseLossBackward0>)\n",
      "4269\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4270\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "4271\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "4272\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "4273\n",
      "tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
      "4274\n",
      "tensor(0.3369, grad_fn=<MseLossBackward0>)\n",
      "4275\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "4276\n",
      "tensor(0.1245, grad_fn=<MseLossBackward0>)\n",
      "4277\n",
      "tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "4278\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "4279\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "4280\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "4281\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "4282\n",
      "tensor(0.1155, grad_fn=<MseLossBackward0>)\n",
      "4283\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "4284\n",
      "tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "4285\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "4286\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "4287\n",
      "tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "4288\n",
      "tensor(0.1605, grad_fn=<MseLossBackward0>)\n",
      "4289\n",
      "tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "4290\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "4291\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "4292\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "4293\n",
      "tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "4294\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "4295\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "4296\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "4297\n",
      "tensor(0.4771, grad_fn=<MseLossBackward0>)\n",
      "4298\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "4299\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "4300\n",
      "tensor(0.1477, grad_fn=<MseLossBackward0>)\n",
      "4301\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "4302\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "4303\n",
      "tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "4304\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "4305\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "4306\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "4307\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4308\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "4309\n",
      "tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "4310\n",
      "tensor(0.1654, grad_fn=<MseLossBackward0>)\n",
      "4311\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "4312\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "4313\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4314\n",
      "tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "4315\n",
      "tensor(0.1375, grad_fn=<MseLossBackward0>)\n",
      "4316\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "4317\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4318\n",
      "tensor(0.1194, grad_fn=<MseLossBackward0>)\n",
      "4319\n",
      "tensor(0.3045, grad_fn=<MseLossBackward0>)\n",
      "4320\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "4321\n",
      "tensor(0.1431, grad_fn=<MseLossBackward0>)\n",
      "4322\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "4323\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "4324\n",
      "tensor(0.2148, grad_fn=<MseLossBackward0>)\n",
      "4325\n",
      "tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "4326\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "4327\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "4328\n",
      "tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "4329\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "4330\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "4331\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "4332\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "4333\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "4334\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "4335\n",
      "tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "4336\n",
      "tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "4337\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "4338\n",
      "tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "4339\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "4340\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "4341\n",
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "4342\n",
      "tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "4343\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "4344\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4345\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "4346\n",
      "tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "4347\n",
      "tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
      "4348\n",
      "tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "4349\n",
      "tensor(0.1848, grad_fn=<MseLossBackward0>)\n",
      "4350\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "4351\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "4352\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "4353\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "4354\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "4355\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4356\n",
      "tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "4357\n",
      "tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "4358\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "4359\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "4360\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4361\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "4362\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "4363\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "4364\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "4365\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "4366\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "4367\n",
      "tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "4368\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "4369\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4370\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "4371\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "4372\n",
      "tensor(0.1514, grad_fn=<MseLossBackward0>)\n",
      "4373\n",
      "tensor(0.1515, grad_fn=<MseLossBackward0>)\n",
      "4374\n",
      "tensor(0.1384, grad_fn=<MseLossBackward0>)\n",
      "4375\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "4376\n",
      "tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "4377\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "4378\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "4379\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4380\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "4381\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4382\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "4383\n",
      "tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "4384\n",
      "tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
      "4385\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4386\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "4387\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4388\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "4389\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "4390\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "4391\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "4392\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "4393\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4394\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "4395\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4396\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4397\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "4398\n",
      "tensor(0.1513, grad_fn=<MseLossBackward0>)\n",
      "4399\n",
      "tensor(0.1815, grad_fn=<MseLossBackward0>)\n",
      "4400\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "4401\n",
      "tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
      "4402\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "4403\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "4404\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4405\n",
      "tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "4406\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "4407\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "4408\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "4409\n",
      "tensor(0.1165, grad_fn=<MseLossBackward0>)\n",
      "4410\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "4411\n",
      "tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "4412\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "4413\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "4414\n",
      "tensor(0.1747, grad_fn=<MseLossBackward0>)\n",
      "4415\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "4416\n",
      "tensor(0.1911, grad_fn=<MseLossBackward0>)\n",
      "4417\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "4418\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "4419\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "4420\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "4421\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4422\n",
      "tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "4423\n",
      "tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "4424\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "4425\n",
      "tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "4426\n",
      "tensor(0.2458, grad_fn=<MseLossBackward0>)\n",
      "4427\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "4428\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4429\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "4430\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "4431\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "4432\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4433\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "4434\n",
      "tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "4435\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "4436\n",
      "tensor(0.1215, grad_fn=<MseLossBackward0>)\n",
      "4437\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "4438\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "4439\n",
      "tensor(0.1204, grad_fn=<MseLossBackward0>)\n",
      "4440\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "4441\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "4442\n",
      "tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "4443\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "4444\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "4445\n",
      "tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "4446\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "4447\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4448\n",
      "tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "4449\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "4450\n",
      "tensor(0.1301, grad_fn=<MseLossBackward0>)\n",
      "4451\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "4452\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "4453\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "4454\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4455\n",
      "tensor(0.1646, grad_fn=<MseLossBackward0>)\n",
      "4456\n",
      "tensor(0.1736, grad_fn=<MseLossBackward0>)\n",
      "4457\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "4458\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "4459\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "4460\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4461\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "4462\n",
      "tensor(0.1720, grad_fn=<MseLossBackward0>)\n",
      "4463\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "4464\n",
      "tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "4465\n",
      "tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "4466\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "4467\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4468\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "4469\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4470\n",
      "tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "4471\n",
      "tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "4472\n",
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "4473\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "4474\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "4475\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "4476\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "4477\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "4478\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "4479\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "4480\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "4481\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "4482\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "4483\n",
      "tensor(0.1754, grad_fn=<MseLossBackward0>)\n",
      "4484\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4485\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "4486\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4487\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "4488\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "4489\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "4490\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4491\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "4492\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "4493\n",
      "tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "4494\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "4495\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "4496\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "4497\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "4498\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "4499\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "4500\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "4501\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "4502\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "4503\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "4504\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "4505\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "4506\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "4507\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "4508\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "4509\n",
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "4510\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "4511\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "4512\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "4513\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "4514\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "4515\n",
      "tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "4516\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "4517\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "4518\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "4519\n",
      "tensor(0.1880, grad_fn=<MseLossBackward0>)\n",
      "4520\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "4521\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "4522\n",
      "tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "4523\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4524\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4525\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4526\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "4527\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4528\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "4529\n",
      "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "4530\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "4531\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "4532\n",
      "tensor(0.1675, grad_fn=<MseLossBackward0>)\n",
      "4533\n",
      "tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "4534\n",
      "tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "4535\n",
      "tensor(0.1665, grad_fn=<MseLossBackward0>)\n",
      "4536\n",
      "tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "4537\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "4538\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "4539\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "4540\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4541\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "4542\n",
      "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
      "4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([176, 1, 128])) that is different to the input size (torch.Size([176, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "4544\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "4545\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4546\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "4547\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "4548\n",
      "tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "4549\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "4550\n",
      "tensor(0.1815, grad_fn=<MseLossBackward0>)\n",
      "4551\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "4552\n",
      "tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "4553\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "4554\n",
      "tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "4555\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "4556\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "4557\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "4558\n",
      "tensor(0.1735, grad_fn=<MseLossBackward0>)\n",
      "4559\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "4560\n",
      "tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "4561\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "4562\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "4563\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "4564\n",
      "tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "4565\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4566\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "4567\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "4568\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "4569\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "4570\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "4571\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4572\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4573\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4574\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "4575\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4576\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "4577\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "4578\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4579\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4580\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4581\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "4582\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "4583\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "4584\n",
      "tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "4585\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "4586\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "4587\n",
      "tensor(0.1571, grad_fn=<MseLossBackward0>)\n",
      "4588\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "4589\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "4590\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "4591\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "4592\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "4593\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "4594\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "4595\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "4596\n",
      "tensor(0.2666, grad_fn=<MseLossBackward0>)\n",
      "4597\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4598\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "4599\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "4600\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "4601\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "4602\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4603\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "4604\n",
      "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "4605\n",
      "tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "4606\n",
      "tensor(0.2919, grad_fn=<MseLossBackward0>)\n",
      "4607\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4608\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "4609\n",
      "tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "4610\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "4611\n",
      "tensor(0.2636, grad_fn=<MseLossBackward0>)\n",
      "4612\n",
      "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "4613\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "4614\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "4615\n",
      "tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "4616\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4617\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "4618\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "4619\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "4620\n",
      "tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "4621\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "4622\n",
      "tensor(0.2495, grad_fn=<MseLossBackward0>)\n",
      "4623\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "4624\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "4625\n",
      "tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "4626\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "4627\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "4628\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "4629\n",
      "tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "4630\n",
      "tensor(0.1990, grad_fn=<MseLossBackward0>)\n",
      "4631\n",
      "tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "4632\n",
      "tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "4633\n",
      "tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "4634\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "4635\n",
      "tensor(0.1477, grad_fn=<MseLossBackward0>)\n",
      "4636\n",
      "tensor(0.1694, grad_fn=<MseLossBackward0>)\n",
      "4637\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4638\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "4639\n",
      "tensor(0.1551, grad_fn=<MseLossBackward0>)\n",
      "4640\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "4641\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4642\n",
      "tensor(0.1749, grad_fn=<MseLossBackward0>)\n",
      "4643\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "4644\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "4645\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "4646\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4647\n",
      "tensor(0.1314, grad_fn=<MseLossBackward0>)\n",
      "4648\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "4649\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4650\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "4651\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "4652\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "4653\n",
      "tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
      "4654\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "4655\n",
      "tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "4656\n",
      "tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "4657\n",
      "tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "4658\n",
      "tensor(0.2704, grad_fn=<MseLossBackward0>)\n",
      "4659\n",
      "tensor(0.1776, grad_fn=<MseLossBackward0>)\n",
      "4660\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "4661\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "4662\n",
      "tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "4663\n",
      "tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "4664\n",
      "tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "4665\n",
      "tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "4666\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "4667\n",
      "tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "4668\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "4669\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "4670\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "4671\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "4672\n",
      "tensor(0.1314, grad_fn=<MseLossBackward0>)\n",
      "4673\n",
      "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "4674\n",
      "tensor(0.1778, grad_fn=<MseLossBackward0>)\n",
      "4675\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "4676\n",
      "tensor(0.1766, grad_fn=<MseLossBackward0>)\n",
      "4677\n",
      "tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "4678\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "4679\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "4680\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4681\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "4682\n",
      "tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "4683\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "4684\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "4685\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "4686\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "4687\n",
      "tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "4688\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "4689\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "4690\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "4691\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "4692\n",
      "tensor(0.2619, grad_fn=<MseLossBackward0>)\n",
      "4693\n",
      "tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "4694\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "4695\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "4696\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "4697\n",
      "tensor(0.2833, grad_fn=<MseLossBackward0>)\n",
      "4698\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "4699\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "4700\n",
      "tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "4701\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "4702\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "4703\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "4704\n",
      "tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "4705\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "4706\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "4707\n",
      "tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
      "4708\n",
      "tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "4709\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "4710\n",
      "tensor(0.2557, grad_fn=<MseLossBackward0>)\n",
      "4711\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "4712\n",
      "tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "4713\n",
      "tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "4714\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4715\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "4716\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "4717\n",
      "tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "4718\n",
      "tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "4719\n",
      "tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "4720\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "4721\n",
      "tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "4722\n",
      "tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "4723\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "4724\n",
      "tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "4725\n",
      "tensor(0.1838, grad_fn=<MseLossBackward0>)\n",
      "4726\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "4727\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "4728\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "4729\n",
      "tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "4730\n",
      "tensor(0.1517, grad_fn=<MseLossBackward0>)\n",
      "4731\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "4732\n",
      "tensor(0.3166, grad_fn=<MseLossBackward0>)\n",
      "4733\n",
      "tensor(0.1253, grad_fn=<MseLossBackward0>)\n",
      "4734\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "4735\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "4736\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "4737\n",
      "tensor(0.1663, grad_fn=<MseLossBackward0>)\n",
      "4738\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "4739\n",
      "tensor(0.1667, grad_fn=<MseLossBackward0>)\n",
      "4740\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4741\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "4742\n",
      "tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "4743\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "4744\n",
      "tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
      "4745\n",
      "tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "4746\n",
      "tensor(0.1754, grad_fn=<MseLossBackward0>)\n",
      "4747\n",
      "tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "4748\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "4749\n",
      "tensor(0.1589, grad_fn=<MseLossBackward0>)\n",
      "4750\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "4751\n",
      "tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "4752\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "4753\n",
      "tensor(0.1991, grad_fn=<MseLossBackward0>)\n",
      "4754\n",
      "tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "4755\n",
      "tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "4756\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "4757\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "4758\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "4759\n",
      "tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "4760\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "4761\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "4762\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "4763\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "4764\n",
      "tensor(0.1975, grad_fn=<MseLossBackward0>)\n",
      "4765\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "4766\n",
      "tensor(0.1659, grad_fn=<MseLossBackward0>)\n",
      "4767\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "4768\n",
      "tensor(0.1595, grad_fn=<MseLossBackward0>)\n",
      "4769\n",
      "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "4770\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "4771\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "4772\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "4773\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "4774\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "4775\n",
      "tensor(0.2015, grad_fn=<MseLossBackward0>)\n",
      "4776\n",
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "4777\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "4778\n",
      "tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "4779\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "4780\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "4781\n",
      "tensor(0.1425, grad_fn=<MseLossBackward0>)\n",
      "4782\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "4783\n",
      "tensor(0.3855, grad_fn=<MseLossBackward0>)\n",
      "4784\n",
      "tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "4785\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "4786\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "4787\n",
      "tensor(0.1190, grad_fn=<MseLossBackward0>)\n",
      "4788\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "4789\n",
      "tensor(0.1904, grad_fn=<MseLossBackward0>)\n",
      "4790\n",
      "tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "4791\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "4792\n",
      "tensor(0.1397, grad_fn=<MseLossBackward0>)\n",
      "4793\n",
      "tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "4794\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "4795\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "4796\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "4797\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "4798\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "4799\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "4800\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "4801\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "4802\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "4803\n",
      "tensor(0.2762, grad_fn=<MseLossBackward0>)\n",
      "4804\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "4805\n",
      "tensor(0.1352, grad_fn=<MseLossBackward0>)\n",
      "4806\n",
      "tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "4807\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "4808\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "4809\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "4810\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "4811\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4812\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "4813\n",
      "tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "4814\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "4815\n",
      "tensor(0.2104, grad_fn=<MseLossBackward0>)\n",
      "4816\n",
      "tensor(0.1754, grad_fn=<MseLossBackward0>)\n",
      "4817\n",
      "tensor(0.1557, grad_fn=<MseLossBackward0>)\n",
      "4818\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "4819\n",
      "tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "4820\n",
      "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "4821\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "4822\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "4823\n",
      "tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "4824\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "4825\n",
      "tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "4826\n",
      "tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "4827\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "4828\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4829\n",
      "tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "4830\n",
      "tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "4831\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "4832\n",
      "tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "4833\n",
      "tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "4834\n",
      "tensor(0.1749, grad_fn=<MseLossBackward0>)\n",
      "4835\n",
      "tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "4836\n",
      "tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
      "4837\n",
      "tensor(0.1939, grad_fn=<MseLossBackward0>)\n",
      "4838\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "4839\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "4840\n",
      "tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "4841\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "4842\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "4843\n",
      "tensor(0.1639, grad_fn=<MseLossBackward0>)\n",
      "4844\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "4845\n",
      "tensor(0.1804, grad_fn=<MseLossBackward0>)\n",
      "4846\n",
      "tensor(0.1535, grad_fn=<MseLossBackward0>)\n",
      "4847\n",
      "tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "4848\n",
      "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "4849\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "4850\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "4851\n",
      "tensor(0.1807, grad_fn=<MseLossBackward0>)\n",
      "4852\n",
      "tensor(0.1185, grad_fn=<MseLossBackward0>)\n",
      "4853\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "4854\n",
      "tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "4855\n",
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "4856\n",
      "tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "4857\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "4858\n",
      "tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "4859\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "4860\n",
      "tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "4861\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "4862\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "4863\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4864\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "4865\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "4866\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "4867\n",
      "tensor(0.1996, grad_fn=<MseLossBackward0>)\n",
      "4868\n",
      "tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "4869\n",
      "tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "4870\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4871\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "4872\n",
      "tensor(0.1706, grad_fn=<MseLossBackward0>)\n",
      "4873\n",
      "tensor(0.1379, grad_fn=<MseLossBackward0>)\n",
      "4874\n",
      "tensor(0.2067, grad_fn=<MseLossBackward0>)\n",
      "4875\n",
      "tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "4876\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "4877\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "4878\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "4879\n",
      "tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "4880\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "4881\n",
      "tensor(0.3010, grad_fn=<MseLossBackward0>)\n",
      "4882\n",
      "tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "4883\n",
      "tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "4884\n",
      "tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "4885\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "4886\n",
      "tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "4887\n",
      "tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "4888\n",
      "tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "4889\n",
      "tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "4890\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "4891\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "4892\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "4893\n",
      "tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "4894\n",
      "tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "4895\n",
      "tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "4896\n",
      "tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "4897\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "4898\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "4899\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4900\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "4901\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "4902\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "4903\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "4904\n",
      "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "4905\n",
      "tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "4906\n",
      "tensor(0.1677, grad_fn=<MseLossBackward0>)\n",
      "4907\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4908\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "4909\n",
      "tensor(0.1752, grad_fn=<MseLossBackward0>)\n",
      "4910\n",
      "tensor(0.1923, grad_fn=<MseLossBackward0>)\n",
      "4911\n",
      "tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "4912\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "4913\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "4914\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1098, 1, 128])) that is different to the input size (torch.Size([1098, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "4916\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "4917\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "4918\n",
      "tensor(0.1982, grad_fn=<MseLossBackward0>)\n",
      "4919\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "4920\n",
      "tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "4921\n",
      "tensor(0.1755, grad_fn=<MseLossBackward0>)\n",
      "4922\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "4923\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "4924\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "4925\n",
      "tensor(0.1325, grad_fn=<MseLossBackward0>)\n",
      "4926\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "4927\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "4928\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "4929\n",
      "tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "4930\n",
      "tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "4931\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "4932\n",
      "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "4933\n",
      "tensor(0.1752, grad_fn=<MseLossBackward0>)\n",
      "4934\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "4935\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "4936\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "4937\n",
      "tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "4938\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "4939\n",
      "tensor(0.2084, grad_fn=<MseLossBackward0>)\n",
      "4940\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "4941\n",
      "tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "4942\n",
      "tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "4943\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "4944\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "4945\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "4946\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "4947\n",
      "tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "4948\n",
      "tensor(0.1515, grad_fn=<MseLossBackward0>)\n",
      "4949\n",
      "tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
      "4950\n",
      "tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "4951\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "4952\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "4953\n",
      "tensor(0.1547, grad_fn=<MseLossBackward0>)\n",
      "4954\n",
      "tensor(0.1814, grad_fn=<MseLossBackward0>)\n",
      "4955\n",
      "tensor(0.1704, grad_fn=<MseLossBackward0>)\n",
      "4956\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "4957\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4958\n",
      "tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "4959\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "4960\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([148, 1, 128])) that is different to the input size (torch.Size([148, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "4962\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "4963\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "4964\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "4965\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "4966\n",
      "tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
      "4967\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "4968\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "4969\n",
      "tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "4970\n",
      "tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "4971\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "4972\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "4973\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "4974\n",
      "tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "4975\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "4976\n",
      "tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "4977\n",
      "tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "4978\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "4979\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "4980\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "4981\n",
      "tensor(0.1444, grad_fn=<MseLossBackward0>)\n",
      "4982\n",
      "tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "4983\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "4984\n",
      "tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "4985\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "4986\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "4987\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "4988\n",
      "tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "4989\n",
      "tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "4990\n",
      "tensor(0.1998, grad_fn=<MseLossBackward0>)\n",
      "4991\n",
      "tensor(0.3814, grad_fn=<MseLossBackward0>)\n",
      "4992\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "4993\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "4994\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "4995\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "4996\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "4997\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "4998\n",
      "tensor(0.1419, grad_fn=<MseLossBackward0>)\n",
      "4999\n",
      "tensor(0.1918, grad_fn=<MseLossBackward0>)\n",
      "5000\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "5001\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "5002\n",
      "tensor(0.1785, grad_fn=<MseLossBackward0>)\n",
      "5003\n",
      "tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "5004\n",
      "tensor(0.2483, grad_fn=<MseLossBackward0>)\n",
      "5005\n",
      "tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "5006\n",
      "tensor(0.1479, grad_fn=<MseLossBackward0>)\n",
      "5007\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "5008\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "5009\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "5010\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "5011\n",
      "tensor(0.1541, grad_fn=<MseLossBackward0>)\n",
      "5012\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "5013\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "5014\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "5015\n",
      "tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "5016\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "5017\n",
      "tensor(0.1455, grad_fn=<MseLossBackward0>)\n",
      "5018\n",
      "tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "5019\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "5020\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "5021\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "5022\n",
      "tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "5023\n",
      "tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
      "5024\n",
      "tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "5025\n",
      "tensor(0.1382, grad_fn=<MseLossBackward0>)\n",
      "5026\n",
      "tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "5027\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "5028\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "5029\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "5030\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "5031\n",
      "tensor(0.2709, grad_fn=<MseLossBackward0>)\n",
      "5032\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "5033\n",
      "tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "5034\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "5035\n",
      "tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "5036\n",
      "tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "5037\n",
      "tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "5038\n",
      "tensor(0.1395, grad_fn=<MseLossBackward0>)\n",
      "5039\n",
      "tensor(0.1769, grad_fn=<MseLossBackward0>)\n",
      "5040\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "5041\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "5042\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "5043\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "5044\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "5045\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "5046\n",
      "tensor(0.1635, grad_fn=<MseLossBackward0>)\n",
      "5047\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "5048\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "5049\n",
      "tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
      "5050\n",
      "tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
      "5051\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "5052\n",
      "tensor(0.1806, grad_fn=<MseLossBackward0>)\n",
      "5053\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "5054\n",
      "tensor(0.1123, grad_fn=<MseLossBackward0>)\n",
      "5055\n",
      "tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "5056\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "5057\n",
      "tensor(0.1354, grad_fn=<MseLossBackward0>)\n",
      "5058\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "5059\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "5060\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "5061\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "5062\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "5063\n",
      "tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "5064\n",
      "tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "5065\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "5066\n",
      "tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "5067\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "5068\n",
      "tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "5069\n",
      "tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "5070\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5071\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "5072\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "5073\n",
      "tensor(0.1885, grad_fn=<MseLossBackward0>)\n",
      "5074\n",
      "tensor(0.2166, grad_fn=<MseLossBackward0>)\n",
      "5075\n",
      "tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "5076\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "5077\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "5078\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "5079\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "5080\n",
      "tensor(0.2020, grad_fn=<MseLossBackward0>)\n",
      "5081\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "5082\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "5083\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5084\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "5085\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "5086\n",
      "tensor(0.2530, grad_fn=<MseLossBackward0>)\n",
      "5087\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "5088\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "5089\n",
      "tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "5090\n",
      "tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "5091\n",
      "tensor(0.2832, grad_fn=<MseLossBackward0>)\n",
      "5092\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "5093\n",
      "tensor(0.1315, grad_fn=<MseLossBackward0>)\n",
      "5094\n",
      "tensor(0.1663, grad_fn=<MseLossBackward0>)\n",
      "5095\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5096\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "5097\n",
      "tensor(0.1375, grad_fn=<MseLossBackward0>)\n",
      "5098\n",
      "tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "5099\n",
      "tensor(0.1386, grad_fn=<MseLossBackward0>)\n",
      "5100\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "5101\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "5102\n",
      "tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "5103\n",
      "tensor(0.0976, grad_fn=<MseLossBackward0>)\n",
      "5104\n",
      "tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "5105\n",
      "tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "5106\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "5107\n",
      "tensor(0.1533, grad_fn=<MseLossBackward0>)\n",
      "5108\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "5109\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "5110\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "5111\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "5112\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "5113\n",
      "tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "5114\n",
      "tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "5115\n",
      "tensor(0.1516, grad_fn=<MseLossBackward0>)\n",
      "5116\n",
      "tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "5117\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "5118\n",
      "tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "5119\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "5120\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "5121\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "5122\n",
      "tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
      "5123\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "5124\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "5125\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "5126\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "5127\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5128\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "5129\n",
      "tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "5130\n",
      "tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "5131\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "5132\n",
      "tensor(0.1989, grad_fn=<MseLossBackward0>)\n",
      "5133\n",
      "tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "5134\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "5135\n",
      "tensor(0.1809, grad_fn=<MseLossBackward0>)\n",
      "5136\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5137\n",
      "tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "5138\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "5139\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "5140\n",
      "tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "5141\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "5142\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "5143\n",
      "tensor(0.1463, grad_fn=<MseLossBackward0>)\n",
      "5144\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "5145\n",
      "tensor(0.2489, grad_fn=<MseLossBackward0>)\n",
      "5146\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "5147\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "5148\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5149\n",
      "tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "5150\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "5151\n",
      "tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "5152\n",
      "tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "5153\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "5154\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "5155\n",
      "tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "5156\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "5157\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "5158\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "5159\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "5160\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "5161\n",
      "tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "5162\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "5163\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "5164\n",
      "tensor(0.1858, grad_fn=<MseLossBackward0>)\n",
      "5165\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "5166\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "5167\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "5168\n",
      "tensor(0.1509, grad_fn=<MseLossBackward0>)\n",
      "5169\n",
      "tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "5170\n",
      "tensor(0.1668, grad_fn=<MseLossBackward0>)\n",
      "5171\n",
      "tensor(0.1455, grad_fn=<MseLossBackward0>)\n",
      "5172\n",
      "tensor(0.2093, grad_fn=<MseLossBackward0>)\n",
      "5173\n",
      "tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "5174\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "5175\n",
      "tensor(0.2997, grad_fn=<MseLossBackward0>)\n",
      "5176\n",
      "tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "5177\n",
      "tensor(0.1237, grad_fn=<MseLossBackward0>)\n",
      "5178\n",
      "tensor(0.1393, grad_fn=<MseLossBackward0>)\n",
      "5179\n",
      "tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "5180\n",
      "tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "5181\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "5182\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "5183\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "5184\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "5185\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "5186\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "5187\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "5188\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "5189\n",
      "tensor(0.1309, grad_fn=<MseLossBackward0>)\n",
      "5190\n",
      "tensor(0.1921, grad_fn=<MseLossBackward0>)\n",
      "5191\n",
      "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "5192\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "5193\n",
      "tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "5194\n",
      "tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "5195\n",
      "tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "5196\n",
      "tensor(0.2603, grad_fn=<MseLossBackward0>)\n",
      "5197\n",
      "tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "5198\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "5199\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "5200\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "5201\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "5202\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "5203\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "5204\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "5205\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "5206\n",
      "tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "5207\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "5208\n",
      "tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "5209\n",
      "tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "5210\n",
      "tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "5211\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "5212\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "5213\n",
      "tensor(0.1449, grad_fn=<MseLossBackward0>)\n",
      "5214\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "5215\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "5216\n",
      "tensor(0.1756, grad_fn=<MseLossBackward0>)\n",
      "5217\n",
      "tensor(0.1913, grad_fn=<MseLossBackward0>)\n",
      "5218\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "5219\n",
      "tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "5220\n",
      "tensor(0.1594, grad_fn=<MseLossBackward0>)\n",
      "5221\n",
      "tensor(0.2088, grad_fn=<MseLossBackward0>)\n",
      "5222\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "5223\n",
      "tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "5224\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5225\n",
      "tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "5226\n",
      "tensor(0.1588, grad_fn=<MseLossBackward0>)\n",
      "5227\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "5228\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "5229\n",
      "tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "5230\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "5231\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "5232\n",
      "tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "5233\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "5234\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "5235\n",
      "tensor(0.2755, grad_fn=<MseLossBackward0>)\n",
      "5236\n",
      "tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "5237\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "5238\n",
      "tensor(0.2103, grad_fn=<MseLossBackward0>)\n",
      "5239\n",
      "tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "5240\n",
      "tensor(0.1785, grad_fn=<MseLossBackward0>)\n",
      "5241\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "5242\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "5243\n",
      "tensor(0.0932, grad_fn=<MseLossBackward0>)\n",
      "5244\n",
      "tensor(0.1699, grad_fn=<MseLossBackward0>)\n",
      "5245\n",
      "tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "5246\n",
      "tensor(0.1744, grad_fn=<MseLossBackward0>)\n",
      "5247\n",
      "tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "5248\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "5249\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "5250\n",
      "tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
      "5251\n",
      "tensor(0.2141, grad_fn=<MseLossBackward0>)\n",
      "5252\n",
      "tensor(0.1358, grad_fn=<MseLossBackward0>)\n",
      "5253\n",
      "tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "5254\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "5255\n",
      "tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "5256\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "5257\n",
      "tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "5258\n",
      "tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "5259\n",
      "tensor(0.1746, grad_fn=<MseLossBackward0>)\n",
      "5260\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "5261\n",
      "tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "5262\n",
      "tensor(0.1778, grad_fn=<MseLossBackward0>)\n",
      "5263\n",
      "tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "5264\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "5265\n",
      "tensor(0.1391, grad_fn=<MseLossBackward0>)\n",
      "5266\n",
      "tensor(0.1673, grad_fn=<MseLossBackward0>)\n",
      "5267\n",
      "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "5268\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "5269\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "5270\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "5271\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5272\n",
      "tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "5273\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "5274\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "5275\n",
      "tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "5276\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "5277\n",
      "tensor(0.2092, grad_fn=<MseLossBackward0>)\n",
      "5278\n",
      "tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "5279\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "5280\n",
      "tensor(0.1890, grad_fn=<MseLossBackward0>)\n",
      "5281\n",
      "tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "5282\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "5283\n",
      "tensor(0.1140, grad_fn=<MseLossBackward0>)\n",
      "5284\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5285\n",
      "tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "5286\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "5287\n",
      "tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "5288\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "5289\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5290\n",
      "tensor(0.1338, grad_fn=<MseLossBackward0>)\n",
      "5291\n",
      "tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "5292\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "5293\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "5294\n",
      "tensor(0.1683, grad_fn=<MseLossBackward0>)\n",
      "5295\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "5296\n",
      "tensor(0.2650, grad_fn=<MseLossBackward0>)\n",
      "5297\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "5298\n",
      "tensor(0.2139, grad_fn=<MseLossBackward0>)\n",
      "5299\n",
      "tensor(0.2204, grad_fn=<MseLossBackward0>)\n",
      "5300\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "5301\n",
      "tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "5302\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "5303\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "5304\n",
      "tensor(0.1469, grad_fn=<MseLossBackward0>)\n",
      "5305\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "5306\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "5307\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "5308\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "5309\n",
      "tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "5310\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "5311\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "5312\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "5313\n",
      "tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "5314\n",
      "tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "5315\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "5316\n",
      "tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "5317\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5318\n",
      "tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "5319\n",
      "tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "5320\n",
      "tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
      "5321\n",
      "tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "5322\n",
      "tensor(0.1492, grad_fn=<MseLossBackward0>)\n",
      "5323\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "5324\n",
      "tensor(0.1889, grad_fn=<MseLossBackward0>)\n",
      "5325\n",
      "tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "5326\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "5327\n",
      "tensor(0.2555, grad_fn=<MseLossBackward0>)\n",
      "5328\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "5329\n",
      "tensor(0.1560, grad_fn=<MseLossBackward0>)\n",
      "5330\n",
      "tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "5331\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "5332\n",
      "tensor(0.1712, grad_fn=<MseLossBackward0>)\n",
      "5333\n",
      "tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
      "5334\n",
      "tensor(0.1115, grad_fn=<MseLossBackward0>)\n",
      "5335\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "5336\n",
      "tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "5337\n",
      "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
      "5338\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5339\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "5340\n",
      "tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "5341\n",
      "tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "5342\n",
      "tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "5343\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5344\n",
      "tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
      "5345\n",
      "tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "5346\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5347\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5348\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5349\n",
      "tensor(0.1326, grad_fn=<MseLossBackward0>)\n",
      "5350\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "5351\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "5352\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "5353\n",
      "tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "5354\n",
      "tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "5355\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "5356\n",
      "tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "5357\n",
      "tensor(0.2890, grad_fn=<MseLossBackward0>)\n",
      "5358\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "5359\n",
      "tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "5360\n",
      "tensor(0.1668, grad_fn=<MseLossBackward0>)\n",
      "5361\n",
      "tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "5362\n",
      "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "5363\n",
      "tensor(0.1979, grad_fn=<MseLossBackward0>)\n",
      "5364\n",
      "tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "5365\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "5366\n",
      "tensor(0.1646, grad_fn=<MseLossBackward0>)\n",
      "5367\n",
      "tensor(0.2440, grad_fn=<MseLossBackward0>)\n",
      "5368\n",
      "tensor(0.1896, grad_fn=<MseLossBackward0>)\n",
      "5369\n",
      "tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "5370\n",
      "tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "5371\n",
      "tensor(0.2142, grad_fn=<MseLossBackward0>)\n",
      "5372\n",
      "tensor(0.2152, grad_fn=<MseLossBackward0>)\n",
      "5373\n",
      "tensor(0.1675, grad_fn=<MseLossBackward0>)\n",
      "5374\n",
      "tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "5375\n",
      "tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "5376\n",
      "tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "5377\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5378\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5379\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "5380\n",
      "tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "5381\n",
      "tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "5382\n",
      "tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "5383\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "5384\n",
      "tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
      "5385\n",
      "tensor(0.2504, grad_fn=<MseLossBackward0>)\n",
      "5386\n",
      "tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "5387\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "5388\n",
      "tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "5389\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "5390\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "5391\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "5392\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "5393\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5394\n",
      "tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "5395\n",
      "tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "5396\n",
      "tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "5397\n",
      "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "5398\n",
      "tensor(0.2667, grad_fn=<MseLossBackward0>)\n",
      "5399\n",
      "tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "5400\n",
      "tensor(0.1912, grad_fn=<MseLossBackward0>)\n",
      "5401\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "5402\n",
      "tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "5403\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "5404\n",
      "tensor(0.2086, grad_fn=<MseLossBackward0>)\n",
      "5405\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "5406\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "5407\n",
      "tensor(0.2098, grad_fn=<MseLossBackward0>)\n",
      "5408\n",
      "tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "5409\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "5410\n",
      "tensor(0.1715, grad_fn=<MseLossBackward0>)\n",
      "5411\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "5412\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "5413\n",
      "tensor(0.2209, grad_fn=<MseLossBackward0>)\n",
      "5414\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "5415\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "5416\n",
      "tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "5417\n",
      "tensor(0.1974, grad_fn=<MseLossBackward0>)\n",
      "5418\n",
      "tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "5419\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "5420\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "5421\n",
      "tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "5422\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "5423\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "5424\n",
      "tensor(0.1311, grad_fn=<MseLossBackward0>)\n",
      "5425\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "5426\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "5427\n",
      "tensor(0.2550, grad_fn=<MseLossBackward0>)\n",
      "5428\n",
      "tensor(0.1706, grad_fn=<MseLossBackward0>)\n",
      "5429\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "5430\n",
      "tensor(0.1783, grad_fn=<MseLossBackward0>)\n",
      "5431\n",
      "tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "5432\n",
      "tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "5433\n",
      "tensor(0.1566, grad_fn=<MseLossBackward0>)\n",
      "5434\n",
      "tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "5435\n",
      "tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "5436\n",
      "tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "5437\n",
      "tensor(0.1712, grad_fn=<MseLossBackward0>)\n",
      "5438\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "5439\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5440\n",
      "tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
      "5441\n",
      "tensor(0.2654, grad_fn=<MseLossBackward0>)\n",
      "5442\n",
      "tensor(0.1996, grad_fn=<MseLossBackward0>)\n",
      "5443\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "5444\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "5445\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "5446\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "5447\n",
      "tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "5448\n",
      "tensor(0.1516, grad_fn=<MseLossBackward0>)\n",
      "5449\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "5450\n",
      "tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "5451\n",
      "tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "5452\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "5453\n",
      "tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "5454\n",
      "tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "5455\n",
      "tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "5456\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "5457\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "5458\n",
      "tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "5459\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "5460\n",
      "tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
      "5461\n",
      "tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "5462\n",
      "tensor(0.1506, grad_fn=<MseLossBackward0>)\n",
      "5463\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "5464\n",
      "tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "5465\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "5466\n",
      "tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "5467\n",
      "tensor(0.2769, grad_fn=<MseLossBackward0>)\n",
      "5468\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "5469\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "5470\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "5471\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5472\n",
      "tensor(0.1809, grad_fn=<MseLossBackward0>)\n",
      "5473\n",
      "tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "5474\n",
      "tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "5475\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "5476\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "5477\n",
      "tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "5478\n",
      "tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "5479\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "5480\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "5481\n",
      "tensor(0.1775, grad_fn=<MseLossBackward0>)\n",
      "5482\n",
      "tensor(0.1482, grad_fn=<MseLossBackward0>)\n",
      "5483\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "5484\n",
      "tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "5485\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "5486\n",
      "tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "5487\n",
      "tensor(0.2181, grad_fn=<MseLossBackward0>)\n",
      "5488\n",
      "tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
      "5489\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "5490\n",
      "tensor(0.1993, grad_fn=<MseLossBackward0>)\n",
      "5491\n",
      "tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "5492\n",
      "tensor(0.1669, grad_fn=<MseLossBackward0>)\n",
      "5493\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5494\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "5495\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "5496\n",
      "tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "5497\n",
      "tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
      "5498\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "5499\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "5500\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "5501\n",
      "tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "5502\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5503\n",
      "tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "5504\n",
      "tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "5505\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "5506\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5507\n",
      "tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "5508\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5509\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "5510\n",
      "tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "5511\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "5512\n",
      "tensor(0.1463, grad_fn=<MseLossBackward0>)\n",
      "5513\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "5514\n",
      "tensor(0.1728, grad_fn=<MseLossBackward0>)\n",
      "5515\n",
      "tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "5516\n",
      "tensor(0.1630, grad_fn=<MseLossBackward0>)\n",
      "5517\n",
      "tensor(0.2101, grad_fn=<MseLossBackward0>)\n",
      "5518\n",
      "tensor(0.2672, grad_fn=<MseLossBackward0>)\n",
      "5519\n",
      "tensor(0.1543, grad_fn=<MseLossBackward0>)\n",
      "5520\n",
      "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "5521\n",
      "tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "5522\n",
      "tensor(0.1345, grad_fn=<MseLossBackward0>)\n",
      "5523\n",
      "tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "5524\n",
      "tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "5525\n",
      "tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "5526\n",
      "tensor(0.2127, grad_fn=<MseLossBackward0>)\n",
      "5527\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5528\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "5529\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "5530\n",
      "tensor(0.1619, grad_fn=<MseLossBackward0>)\n",
      "5531\n",
      "tensor(0.1529, grad_fn=<MseLossBackward0>)\n",
      "5532\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "5533\n",
      "tensor(0.1514, grad_fn=<MseLossBackward0>)\n",
      "5534\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "5535\n",
      "tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "5536\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "5537\n",
      "tensor(0.2571, grad_fn=<MseLossBackward0>)\n",
      "5538\n",
      "tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "5539\n",
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "5540\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5541\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5542\n",
      "tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "5543\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "5544\n",
      "tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
      "5545\n",
      "tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "5546\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "5547\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "5548\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "5549\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "5550\n",
      "tensor(0.1854, grad_fn=<MseLossBackward0>)\n",
      "5551\n",
      "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "5552\n",
      "tensor(0.1591, grad_fn=<MseLossBackward0>)\n",
      "5553\n",
      "tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "5554\n",
      "tensor(0.1774, grad_fn=<MseLossBackward0>)\n",
      "5555\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "5556\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "5557\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "5558\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "5559\n",
      "tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "5560\n",
      "tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "5561\n",
      "tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "5562\n",
      "tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "5563\n",
      "tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "5564\n",
      "tensor(0.2065, grad_fn=<MseLossBackward0>)\n",
      "5565\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "5566\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "5567\n",
      "tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "5568\n",
      "tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "5569\n",
      "tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "5570\n",
      "tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "5571\n",
      "tensor(0.1860, grad_fn=<MseLossBackward0>)\n",
      "5572\n",
      "tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "5573\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "5574\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "5575\n",
      "tensor(0.2433, grad_fn=<MseLossBackward0>)\n",
      "5576\n",
      "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "5577\n",
      "tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "5578\n",
      "tensor(0.1932, grad_fn=<MseLossBackward0>)\n",
      "5579\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "5580\n",
      "tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "5581\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "5582\n",
      "tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "5583\n",
      "tensor(0.1379, grad_fn=<MseLossBackward0>)\n",
      "5584\n",
      "tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "5585\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5586\n",
      "tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "5587\n",
      "tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "5588\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "5589\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "5590\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "5591\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "5592\n",
      "tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "5593\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5594\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "5595\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "5596\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "5597\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "5598\n",
      "tensor(0.1126, grad_fn=<MseLossBackward0>)\n",
      "5599\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "5600\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "5601\n",
      "tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "5602\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "5603\n",
      "tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "5604\n",
      "tensor(0.2436, grad_fn=<MseLossBackward0>)\n",
      "5605\n",
      "tensor(0.1942, grad_fn=<MseLossBackward0>)\n",
      "5606\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "5607\n",
      "tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "5608\n",
      "tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "5609\n",
      "tensor(0.1944, grad_fn=<MseLossBackward0>)\n",
      "5610\n",
      "tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "5611\n",
      "tensor(0.1552, grad_fn=<MseLossBackward0>)\n",
      "5612\n",
      "tensor(0.1290, grad_fn=<MseLossBackward0>)\n",
      "5613\n",
      "tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "5614\n",
      "tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "5615\n",
      "tensor(0.1163, grad_fn=<MseLossBackward0>)\n",
      "5616\n",
      "tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "5617\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "5618\n",
      "tensor(0.2110, grad_fn=<MseLossBackward0>)\n",
      "5619\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "5620\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "5621\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5622\n",
      "tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "5623\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "5624\n",
      "tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "5625\n",
      "tensor(0.1883, grad_fn=<MseLossBackward0>)\n",
      "5626\n",
      "tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "5627\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5628\n",
      "tensor(0.2183, grad_fn=<MseLossBackward0>)\n",
      "5629\n",
      "tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
      "5630\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "5631\n",
      "tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "5632\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "5633\n",
      "tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "5634\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "5635\n",
      "tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "5636\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "5637\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5638\n",
      "tensor(0.1582, grad_fn=<MseLossBackward0>)\n",
      "5639\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "5640\n",
      "tensor(0.1562, grad_fn=<MseLossBackward0>)\n",
      "5641\n",
      "tensor(0.2636, grad_fn=<MseLossBackward0>)\n",
      "5642\n",
      "tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "5643\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "5644\n",
      "tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "5645\n",
      "tensor(0.1685, grad_fn=<MseLossBackward0>)\n",
      "5646\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "5647\n",
      "tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "5648\n",
      "tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "5649\n",
      "tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "5650\n",
      "tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "5651\n",
      "tensor(0.1779, grad_fn=<MseLossBackward0>)\n",
      "5652\n",
      "tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "5653\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "5654\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5655\n",
      "tensor(0.2455, grad_fn=<MseLossBackward0>)\n",
      "5656\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5657\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "5658\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "5659\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5660\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "5661\n",
      "tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "5662\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "5663\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "5664\n",
      "tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "5665\n",
      "tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "5666\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5667\n",
      "tensor(0.2632, grad_fn=<MseLossBackward0>)\n",
      "5668\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "5669\n",
      "tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "5670\n",
      "tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "5671\n",
      "tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "5672\n",
      "tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "5673\n",
      "tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "5674\n",
      "tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "5675\n",
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "5676\n",
      "tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "5677\n",
      "tensor(0.1154, grad_fn=<MseLossBackward0>)\n",
      "5678\n",
      "tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "5679\n",
      "tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
      "5680\n",
      "tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "5681\n",
      "tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "5682\n",
      "tensor(0.1539, grad_fn=<MseLossBackward0>)\n",
      "5683\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "5684\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "5685\n",
      "tensor(0.1868, grad_fn=<MseLossBackward0>)\n",
      "5686\n",
      "tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "5687\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "5688\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "5689\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "5690\n",
      "tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "5691\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "5692\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5693\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "5694\n",
      "tensor(0.1835, grad_fn=<MseLossBackward0>)\n",
      "5695\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "5696\n",
      "tensor(0.2920, grad_fn=<MseLossBackward0>)\n",
      "5697\n",
      "tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "5698\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "5699\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "5700\n",
      "tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "5701\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "5702\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "5703\n",
      "tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "5704\n",
      "tensor(0.2160, grad_fn=<MseLossBackward0>)\n",
      "5705\n",
      "tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "5706\n",
      "tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "5707\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "5708\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "5709\n",
      "tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "5710\n",
      "tensor(0.1284, grad_fn=<MseLossBackward0>)\n",
      "5711\n",
      "tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "5712\n",
      "tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "5713\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "5714\n",
      "tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "5715\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "5716\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "5717\n",
      "tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "5718\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "5719\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5720\n",
      "tensor(0.1930, grad_fn=<MseLossBackward0>)\n",
      "5721\n",
      "tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "5722\n",
      "tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "5723\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "5724\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5725\n",
      "tensor(0.1482, grad_fn=<MseLossBackward0>)\n",
      "5726\n",
      "tensor(0.1719, grad_fn=<MseLossBackward0>)\n",
      "5727\n",
      "tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "5728\n",
      "tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "5729\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "5730\n",
      "tensor(0.1332, grad_fn=<MseLossBackward0>)\n",
      "5731\n",
      "tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "5732\n",
      "tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "5733\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "5734\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5735\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "5736\n",
      "tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
      "5737\n",
      "tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "5738\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5739\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "5740\n",
      "tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "5741\n",
      "tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "5742\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "5743\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "5744\n",
      "tensor(0.1759, grad_fn=<MseLossBackward0>)\n",
      "5745\n",
      "tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "5746\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "5747\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "5748\n",
      "tensor(0.1418, grad_fn=<MseLossBackward0>)\n",
      "5749\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "5750\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5751\n",
      "tensor(0.1539, grad_fn=<MseLossBackward0>)\n",
      "5752\n",
      "tensor(0.3304, grad_fn=<MseLossBackward0>)\n",
      "5753\n",
      "tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "5754\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "5755\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5756\n",
      "tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "5757\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "5758\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5759\n",
      "tensor(0.1593, grad_fn=<MseLossBackward0>)\n",
      "5760\n",
      "tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "5761\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "5762\n",
      "tensor(0.2118, grad_fn=<MseLossBackward0>)\n",
      "5763\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "5764\n",
      "tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "5765\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "5766\n",
      "tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "5767\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "5768\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "5769\n",
      "tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "5770\n",
      "tensor(0.2562, grad_fn=<MseLossBackward0>)\n",
      "5771\n",
      "tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "5772\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "5773\n",
      "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "5774\n",
      "tensor(0.1708, grad_fn=<MseLossBackward0>)\n",
      "5775\n",
      "tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "5776\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "5777\n",
      "tensor(0.1156, grad_fn=<MseLossBackward0>)\n",
      "5778\n",
      "tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "5779\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "5780\n",
      "tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "5781\n",
      "tensor(0.1339, grad_fn=<MseLossBackward0>)\n",
      "5782\n",
      "tensor(0.1912, grad_fn=<MseLossBackward0>)\n",
      "5783\n",
      "tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "5784\n",
      "tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "5785\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5786\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "5787\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "5788\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "5789\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5790\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "5791\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "5792\n",
      "tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "5793\n",
      "tensor(0.1372, grad_fn=<MseLossBackward0>)\n",
      "5794\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "5795\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "5796\n",
      "tensor(0.2142, grad_fn=<MseLossBackward0>)\n",
      "5797\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "5798\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "5799\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "5800\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "5801\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5802\n",
      "tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "5803\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "5804\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "5805\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "5806\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "5807\n",
      "tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "5808\n",
      "tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "5809\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "5810\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "5811\n",
      "tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "5812\n",
      "tensor(0.0999, grad_fn=<MseLossBackward0>)\n",
      "5813\n",
      "tensor(0.1195, grad_fn=<MseLossBackward0>)\n",
      "5814\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "5815\n",
      "tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "5816\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "5817\n",
      "tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "5818\n",
      "tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "5819\n",
      "tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "5820\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "5821\n",
      "tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "5822\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "5823\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5824\n",
      "tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "5825\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "5826\n",
      "tensor(0.1898, grad_fn=<MseLossBackward0>)\n",
      "5827\n",
      "tensor(0.1781, grad_fn=<MseLossBackward0>)\n",
      "5828\n",
      "tensor(0.2198, grad_fn=<MseLossBackward0>)\n",
      "5829\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "5830\n",
      "tensor(0.0966, grad_fn=<MseLossBackward0>)\n",
      "5831\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "5832\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "5833\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "5834\n",
      "tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "5835\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5836\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "5837\n",
      "tensor(0.1963, grad_fn=<MseLossBackward0>)\n",
      "5838\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "5839\n",
      "tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "5840\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "5841\n",
      "tensor(0.1710, grad_fn=<MseLossBackward0>)\n",
      "5842\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5843\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "5844\n",
      "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "5845\n",
      "tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "5846\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "5847\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "5848\n",
      "tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "5849\n",
      "tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "5850\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "5851\n",
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "5852\n",
      "tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "5853\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "5854\n",
      "tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "5855\n",
      "tensor(0.2000, grad_fn=<MseLossBackward0>)\n",
      "5856\n",
      "tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "5857\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "5858\n",
      "tensor(0.2274, grad_fn=<MseLossBackward0>)\n",
      "5859\n",
      "tensor(0.3025, grad_fn=<MseLossBackward0>)\n",
      "5860\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5861\n",
      "tensor(0.1988, grad_fn=<MseLossBackward0>)\n",
      "5862\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5863\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "5864\n",
      "tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "5865\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "5866\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "5867\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "5868\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "5869\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "5870\n",
      "tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "5871\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "5872\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "5873\n",
      "tensor(0.2117, grad_fn=<MseLossBackward0>)\n",
      "5874\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "5875\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "5876\n",
      "tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "5877\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "5878\n",
      "tensor(0.1793, grad_fn=<MseLossBackward0>)\n",
      "5879\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5880\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "5881\n",
      "tensor(0.0917, grad_fn=<MseLossBackward0>)\n",
      "5882\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5883\n",
      "tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "5884\n",
      "tensor(0.1617, grad_fn=<MseLossBackward0>)\n",
      "5885\n",
      "tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "5886\n",
      "tensor(0.1677, grad_fn=<MseLossBackward0>)\n",
      "5887\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5888\n",
      "tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "5889\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "5890\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "5891\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "5892\n",
      "tensor(0.1667, grad_fn=<MseLossBackward0>)\n",
      "5893\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "5894\n",
      "tensor(0.1869, grad_fn=<MseLossBackward0>)\n",
      "5895\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "5896\n",
      "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "5897\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "5898\n",
      "tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
      "5899\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "5900\n",
      "tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "5901\n",
      "tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "5902\n",
      "tensor(0.1454, grad_fn=<MseLossBackward0>)\n",
      "5903\n",
      "tensor(0.1678, grad_fn=<MseLossBackward0>)\n",
      "5904\n",
      "tensor(0.1746, grad_fn=<MseLossBackward0>)\n",
      "5905\n",
      "tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "5906\n",
      "tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "5907\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "5908\n",
      "tensor(0.1467, grad_fn=<MseLossBackward0>)\n",
      "5909\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "5910\n",
      "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "5911\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "5912\n",
      "tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "5913\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "5914\n",
      "tensor(0.2264, grad_fn=<MseLossBackward0>)\n",
      "5915\n",
      "tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "5916\n",
      "tensor(0.1392, grad_fn=<MseLossBackward0>)\n",
      "5917\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "5918\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "5919\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "5920\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5921\n",
      "tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "5922\n",
      "tensor(0.2094, grad_fn=<MseLossBackward0>)\n",
      "5923\n",
      "tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "5924\n",
      "tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "5925\n",
      "tensor(0.2054, grad_fn=<MseLossBackward0>)\n",
      "5926\n",
      "tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "5927\n",
      "tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "5928\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5929\n",
      "tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "5930\n",
      "tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "5931\n",
      "tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
      "5932\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5933\n",
      "tensor(0.2523, grad_fn=<MseLossBackward0>)\n",
      "5934\n",
      "tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "5935\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "5936\n",
      "tensor(0.1855, grad_fn=<MseLossBackward0>)\n",
      "5937\n",
      "tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "5938\n",
      "tensor(0.2399, grad_fn=<MseLossBackward0>)\n",
      "5939\n",
      "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
      "5940\n",
      "tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "5941\n",
      "tensor(0.1393, grad_fn=<MseLossBackward0>)\n",
      "5942\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5943\n",
      "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "5944\n",
      "tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "5945\n",
      "tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "5946\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "5947\n",
      "tensor(0.1534, grad_fn=<MseLossBackward0>)\n",
      "5948\n",
      "tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "5949\n",
      "tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "5950\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "5951\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "5952\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "5953\n",
      "tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "5954\n",
      "tensor(0.1771, grad_fn=<MseLossBackward0>)\n",
      "5955\n",
      "tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
      "5956\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "5957\n",
      "tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "5958\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "5959\n",
      "tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "5960\n",
      "tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "5961\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "5962\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "5963\n",
      "tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "5964\n",
      "tensor(0.1934, grad_fn=<MseLossBackward0>)\n",
      "5965\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "5966\n",
      "tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "5967\n",
      "tensor(0.3210, grad_fn=<MseLossBackward0>)\n",
      "5968\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "5969\n",
      "tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "5970\n",
      "tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "5971\n",
      "tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "5972\n",
      "tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "5973\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "5974\n",
      "tensor(0.1633, grad_fn=<MseLossBackward0>)\n",
      "5975\n",
      "tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "5976\n",
      "tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "5977\n",
      "tensor(0.1664, grad_fn=<MseLossBackward0>)\n",
      "5978\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "5979\n",
      "tensor(0.1737, grad_fn=<MseLossBackward0>)\n",
      "5980\n",
      "tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "5981\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "5982\n",
      "tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
      "5983\n",
      "tensor(0.1369, grad_fn=<MseLossBackward0>)\n",
      "5984\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "5985\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "5986\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "5987\n",
      "tensor(0.1557, grad_fn=<MseLossBackward0>)\n",
      "5988\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "5989\n",
      "tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "5990\n",
      "tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "5991\n",
      "tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "5992\n",
      "tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
      "5993\n",
      "tensor(0.1624, grad_fn=<MseLossBackward0>)\n",
      "5994\n",
      "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "5995\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "5996\n",
      "tensor(0.2201, grad_fn=<MseLossBackward0>)\n",
      "5997\n",
      "tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
      "5998\n",
      "tensor(0.1699, grad_fn=<MseLossBackward0>)\n",
      "5999\n",
      "tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "6000\n",
      "tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "6001\n",
      "tensor(0.2114, grad_fn=<MseLossBackward0>)\n",
      "6002\n",
      "tensor(0.1625, grad_fn=<MseLossBackward0>)\n",
      "6003\n",
      "tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "6004\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6005\n",
      "tensor(0.1878, grad_fn=<MseLossBackward0>)\n",
      "6006\n",
      "tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "6007\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "6008\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "6009\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "6010\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "6011\n",
      "tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "6012\n",
      "tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "6013\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6014\n",
      "tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "6015\n",
      "tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "6016\n",
      "tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "6017\n",
      "tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "6018\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "6019\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "6020\n",
      "tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "6021\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6022\n",
      "tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "6023\n",
      "tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "6024\n",
      "tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "6025\n",
      "tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "6026\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "6027\n",
      "tensor(0.1607, grad_fn=<MseLossBackward0>)\n",
      "6028\n",
      "tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "6029\n",
      "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "6030\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "6031\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "6032\n",
      "tensor(0.1816, grad_fn=<MseLossBackward0>)\n",
      "6033\n",
      "tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "6034\n",
      "tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "6035\n",
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "6036\n",
      "tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "6037\n",
      "tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "6038\n",
      "tensor(0.1622, grad_fn=<MseLossBackward0>)\n",
      "6039\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "6040\n",
      "tensor(0.1418, grad_fn=<MseLossBackward0>)\n",
      "6041\n",
      "tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "6042\n",
      "tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "6043\n",
      "tensor(0.1261, grad_fn=<MseLossBackward0>)\n",
      "6044\n",
      "tensor(0.2212, grad_fn=<MseLossBackward0>)\n",
      "6045\n",
      "tensor(0.1983, grad_fn=<MseLossBackward0>)\n",
      "6046\n",
      "tensor(0.1676, grad_fn=<MseLossBackward0>)\n",
      "6047\n",
      "tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "6048\n",
      "tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "6049\n",
      "tensor(0.1194, grad_fn=<MseLossBackward0>)\n",
      "6050\n",
      "tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "6051\n",
      "tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "6052\n",
      "tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "6053\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "6054\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "6055\n",
      "tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "6056\n",
      "tensor(0.1834, grad_fn=<MseLossBackward0>)\n",
      "6057\n",
      "tensor(0.1621, grad_fn=<MseLossBackward0>)\n",
      "6058\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6059\n",
      "tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "6060\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "6061\n",
      "tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "6062\n",
      "tensor(0.2011, grad_fn=<MseLossBackward0>)\n",
      "6063\n",
      "tensor(0.1698, grad_fn=<MseLossBackward0>)\n",
      "6064\n",
      "tensor(0.1569, grad_fn=<MseLossBackward0>)\n",
      "6065\n",
      "tensor(0.1745, grad_fn=<MseLossBackward0>)\n",
      "6066\n",
      "tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "6067\n",
      "tensor(0.2004, grad_fn=<MseLossBackward0>)\n",
      "6068\n",
      "tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "6069\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "6070\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "6071\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "6072\n",
      "tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "6073\n",
      "tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "6074\n",
      "tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "6075\n",
      "tensor(0.2131, grad_fn=<MseLossBackward0>)\n",
      "6076\n",
      "tensor(0.1570, grad_fn=<MseLossBackward0>)\n",
      "6077\n",
      "tensor(0.1587, grad_fn=<MseLossBackward0>)\n",
      "6078\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "6079\n",
      "tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "6080\n",
      "tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "6081\n",
      "tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "6082\n",
      "tensor(0.1885, grad_fn=<MseLossBackward0>)\n",
      "6083\n",
      "tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "6084\n",
      "tensor(0.1378, grad_fn=<MseLossBackward0>)\n",
      "6085\n",
      "tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "6086\n",
      "tensor(0.3880, grad_fn=<MseLossBackward0>)\n",
      "6087\n",
      "tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "6088\n",
      "tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
      "6089\n",
      "tensor(0.1672, grad_fn=<MseLossBackward0>)\n",
      "6090\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "6091\n",
      "tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "6092\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "6093\n",
      "tensor(0.0956, grad_fn=<MseLossBackward0>)\n",
      "6094\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "6095\n",
      "tensor(0.1995, grad_fn=<MseLossBackward0>)\n",
      "6096\n",
      "tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "6097\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "6098\n",
      "tensor(0.2014, grad_fn=<MseLossBackward0>)\n",
      "6099\n",
      "tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "6100\n",
      "tensor(0.2761, grad_fn=<MseLossBackward0>)\n",
      "6101\n",
      "tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "6102\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "6103\n",
      "tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "6104\n",
      "tensor(0.2188, grad_fn=<MseLossBackward0>)\n",
      "6105\n",
      "tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "6106\n",
      "tensor(0.1846, grad_fn=<MseLossBackward0>)\n",
      "6107\n",
      "tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "6108\n",
      "tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "6109\n",
      "tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "6110\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "6111\n",
      "tensor(0.1368, grad_fn=<MseLossBackward0>)\n",
      "6112\n",
      "tensor(0.1602, grad_fn=<MseLossBackward0>)\n",
      "6113\n",
      "tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "6114\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6115\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "6116\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "6117\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "6118\n",
      "tensor(0.2160, grad_fn=<MseLossBackward0>)\n",
      "6119\n",
      "tensor(0.2157, grad_fn=<MseLossBackward0>)\n",
      "6120\n",
      "tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
      "6121\n",
      "tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "6122\n",
      "tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "6123\n",
      "tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "6124\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6125\n",
      "tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "6126\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "6127\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "6128\n",
      "tensor(0.1339, grad_fn=<MseLossBackward0>)\n",
      "6129\n",
      "tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "6130\n",
      "tensor(0.1352, grad_fn=<MseLossBackward0>)\n",
      "6131\n",
      "tensor(0.1735, grad_fn=<MseLossBackward0>)\n",
      "6132\n",
      "tensor(0.2550, grad_fn=<MseLossBackward0>)\n",
      "6133\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6134\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "6135\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "6136\n",
      "tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "6137\n",
      "tensor(0.1751, grad_fn=<MseLossBackward0>)\n",
      "6138\n",
      "tensor(0.1753, grad_fn=<MseLossBackward0>)\n",
      "6139\n",
      "tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
      "6140\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "6141\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "6142\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "6143\n",
      "tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "6144\n",
      "tensor(0.2191, grad_fn=<MseLossBackward0>)\n",
      "6145\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "6146\n",
      "tensor(0.2092, grad_fn=<MseLossBackward0>)\n",
      "6147\n",
      "tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "6148\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6149\n",
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "6150\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6151\n",
      "tensor(0.2154, grad_fn=<MseLossBackward0>)\n",
      "6152\n",
      "tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "6153\n",
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "6154\n",
      "tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "6155\n",
      "tensor(0.4150, grad_fn=<MseLossBackward0>)\n",
      "6156\n",
      "tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "6157\n",
      "tensor(0.4368, grad_fn=<MseLossBackward0>)\n",
      "6158\n",
      "tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "6159\n",
      "tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
      "6160\n",
      "tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "6161\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6162\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "6163\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "6164\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6165\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "6166\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "6167\n",
      "tensor(0.1190, grad_fn=<MseLossBackward0>)\n",
      "6168\n",
      "tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "6169\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6170\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "6171\n",
      "tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
      "6172\n",
      "tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "6173\n",
      "tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "6174\n",
      "tensor(0.1749, grad_fn=<MseLossBackward0>)\n",
      "6175\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "6176\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "6177\n",
      "tensor(0.1583, grad_fn=<MseLossBackward0>)\n",
      "6178\n",
      "tensor(0.1980, grad_fn=<MseLossBackward0>)\n",
      "6179\n",
      "tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "6180\n",
      "tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "6181\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6182\n",
      "tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "6183\n",
      "tensor(0.1757, grad_fn=<MseLossBackward0>)\n",
      "6184\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6185\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "6186\n",
      "tensor(0.1130, grad_fn=<MseLossBackward0>)\n",
      "6187\n",
      "tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "6188\n",
      "tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "6189\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6190\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6191\n",
      "tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "6192\n",
      "tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "6193\n",
      "tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "6194\n",
      "tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "6195\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "6196\n",
      "tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "6197\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6198\n",
      "tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
      "6199\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "6200\n",
      "tensor(0.1991, grad_fn=<MseLossBackward0>)\n",
      "6201\n",
      "tensor(0.2194, grad_fn=<MseLossBackward0>)\n",
      "6202\n",
      "tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "6203\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "6204\n",
      "tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "6205\n",
      "tensor(0.1595, grad_fn=<MseLossBackward0>)\n",
      "6206\n",
      "tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "6207\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "6208\n",
      "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "6209\n",
      "tensor(0.2914, grad_fn=<MseLossBackward0>)\n",
      "6210\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "6211\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "6212\n",
      "tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "6213\n",
      "tensor(0.1782, grad_fn=<MseLossBackward0>)\n",
      "6214\n",
      "tensor(0.1126, grad_fn=<MseLossBackward0>)\n",
      "6215\n",
      "tensor(0.1484, grad_fn=<MseLossBackward0>)\n",
      "6216\n",
      "tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "6217\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "6218\n",
      "tensor(0.1976, grad_fn=<MseLossBackward0>)\n",
      "6219\n",
      "tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "6220\n",
      "tensor(0.1552, grad_fn=<MseLossBackward0>)\n",
      "6221\n",
      "tensor(0.1464, grad_fn=<MseLossBackward0>)\n",
      "6222\n",
      "tensor(0.1729, grad_fn=<MseLossBackward0>)\n",
      "6223\n",
      "tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "6224\n",
      "tensor(0.1323, grad_fn=<MseLossBackward0>)\n",
      "6225\n",
      "tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "6226\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "6227\n",
      "tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "6228\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "6229\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "6230\n",
      "tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "6231\n",
      "tensor(0.2767, grad_fn=<MseLossBackward0>)\n",
      "6232\n",
      "tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "6233\n",
      "tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "6234\n",
      "tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
      "6235\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6236\n",
      "tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "6237\n",
      "tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "6238\n",
      "tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "6239\n",
      "tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "6240\n",
      "tensor(0.1568, grad_fn=<MseLossBackward0>)\n",
      "6241\n",
      "tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "6242\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6243\n",
      "tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "6244\n",
      "tensor(0.1558, grad_fn=<MseLossBackward0>)\n",
      "6245\n",
      "tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "6246\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6247\n",
      "tensor(0.1574, grad_fn=<MseLossBackward0>)\n",
      "6248\n",
      "tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "6249\n",
      "tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "6250\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "6251\n",
      "tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "6252\n",
      "tensor(0.1564, grad_fn=<MseLossBackward0>)\n",
      "6253\n",
      "tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "6254\n",
      "tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "6255\n",
      "tensor(0.1737, grad_fn=<MseLossBackward0>)\n",
      "6256\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6257\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "6258\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "6259\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "6260\n",
      "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
      "6261\n",
      "tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "6262\n",
      "tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "6263\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "6264\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6265\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "6266\n",
      "tensor(0.1351, grad_fn=<MseLossBackward0>)\n",
      "6267\n",
      "tensor(0.1218, grad_fn=<MseLossBackward0>)\n",
      "6268\n",
      "tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "6269\n",
      "tensor(0.2116, grad_fn=<MseLossBackward0>)\n",
      "6270\n",
      "tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "6271\n",
      "tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "6272\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "6273\n",
      "tensor(0.1617, grad_fn=<MseLossBackward0>)\n",
      "6274\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "6275\n",
      "tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "6276\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "6277\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "6278\n",
      "tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "6279\n",
      "tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "6280\n",
      "tensor(0.1747, grad_fn=<MseLossBackward0>)\n",
      "6281\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "6282\n",
      "tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "6283\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6284\n",
      "tensor(0.1941, grad_fn=<MseLossBackward0>)\n",
      "6285\n",
      "tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "6286\n",
      "tensor(0.2877, grad_fn=<MseLossBackward0>)\n",
      "6287\n",
      "tensor(0.2504, grad_fn=<MseLossBackward0>)\n",
      "6288\n",
      "tensor(0.2357, grad_fn=<MseLossBackward0>)\n",
      "6289\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "6290\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "6291\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "6292\n",
      "tensor(0.1592, grad_fn=<MseLossBackward0>)\n",
      "6293\n",
      "tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "6294\n",
      "tensor(0.1556, grad_fn=<MseLossBackward0>)\n",
      "6295\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "6296\n",
      "tensor(0.1738, grad_fn=<MseLossBackward0>)\n",
      "6297\n",
      "tensor(0.2123, grad_fn=<MseLossBackward0>)\n",
      "6298\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "6299\n",
      "tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "6300\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "6301\n",
      "tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "6302\n",
      "tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "6303\n",
      "tensor(0.1882, grad_fn=<MseLossBackward0>)\n",
      "6304\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6305\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "6306\n",
      "tensor(0.1767, grad_fn=<MseLossBackward0>)\n",
      "6307\n",
      "tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "6308\n",
      "tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "6309\n",
      "tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "6310\n",
      "tensor(0.1546, grad_fn=<MseLossBackward0>)\n",
      "6311\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "6312\n",
      "tensor(0.2138, grad_fn=<MseLossBackward0>)\n",
      "6313\n",
      "tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "6314\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "6315\n",
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "6316\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6317\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "6318\n",
      "tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
      "6319\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "6320\n",
      "tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "6321\n",
      "tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
      "6322\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "6323\n",
      "tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "6324\n",
      "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "6325\n",
      "tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "6326\n",
      "tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "6327\n",
      "tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "6328\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6329\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "6330\n",
      "tensor(0.1974, grad_fn=<MseLossBackward0>)\n",
      "6331\n",
      "tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "6332\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "6333\n",
      "tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "6334\n",
      "tensor(0.1909, grad_fn=<MseLossBackward0>)\n",
      "6335\n",
      "tensor(0.2524, grad_fn=<MseLossBackward0>)\n",
      "6336\n",
      "tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "6337\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "6338\n",
      "tensor(0.1784, grad_fn=<MseLossBackward0>)\n",
      "6339\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "6340\n",
      "tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
      "6341\n",
      "tensor(0.1756, grad_fn=<MseLossBackward0>)\n",
      "6342\n",
      "tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "6343\n",
      "tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "6344\n",
      "tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "6345\n",
      "tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
      "6346\n",
      "tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "6347\n",
      "tensor(0.1706, grad_fn=<MseLossBackward0>)\n",
      "6348\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "6349\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6350\n",
      "tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "6351\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "6352\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6353\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "6354\n",
      "tensor(0.1682, grad_fn=<MseLossBackward0>)\n",
      "6355\n",
      "tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "6356\n",
      "tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "6357\n",
      "tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "6358\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "6359\n",
      "tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "6360\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "6361\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "6362\n",
      "tensor(0.2719, grad_fn=<MseLossBackward0>)\n",
      "6363\n",
      "tensor(0.1947, grad_fn=<MseLossBackward0>)\n",
      "6364\n",
      "tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "6365\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "6366\n",
      "tensor(0.2259, grad_fn=<MseLossBackward0>)\n",
      "6367\n",
      "tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "6368\n",
      "tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "6369\n",
      "tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "6370\n",
      "tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "6371\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6372\n",
      "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "6373\n",
      "tensor(0.2171, grad_fn=<MseLossBackward0>)\n",
      "6374\n",
      "tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "6375\n",
      "tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "6376\n",
      "tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "6377\n",
      "tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "6378\n",
      "tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "6379\n",
      "tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "6380\n",
      "tensor(0.3350, grad_fn=<MseLossBackward0>)\n",
      "6381\n",
      "tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "6382\n",
      "tensor(0.2171, grad_fn=<MseLossBackward0>)\n",
      "6383\n",
      "tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "6384\n",
      "tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "6385\n",
      "tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "6386\n",
      "tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "6387\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "6388\n",
      "tensor(0.1452, grad_fn=<MseLossBackward0>)\n",
      "6389\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "6390\n",
      "tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
      "6391\n",
      "tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
      "6392\n",
      "tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "6393\n",
      "tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "6394\n",
      "tensor(0.1504, grad_fn=<MseLossBackward0>)\n",
      "6395\n",
      "tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "6396\n",
      "tensor(0.1575, grad_fn=<MseLossBackward0>)\n",
      "6397\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "6398\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "6399\n",
      "tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "6400\n",
      "tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "6401\n",
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "6402\n",
      "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "6403\n",
      "tensor(0.2604, grad_fn=<MseLossBackward0>)\n",
      "6404\n",
      "tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "6405\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "6406\n",
      "tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "6407\n",
      "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
      "6408\n",
      "tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "6409\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "6410\n",
      "tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "6411\n",
      "tensor(0.1142, grad_fn=<MseLossBackward0>)\n",
      "6412\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "6413\n",
      "tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "6414\n",
      "tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "6415\n",
      "tensor(0.1915, grad_fn=<MseLossBackward0>)\n",
      "6416\n",
      "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
      "6417\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "6418\n",
      "tensor(0.1588, grad_fn=<MseLossBackward0>)\n",
      "6419\n",
      "tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "6420\n",
      "tensor(0.1716, grad_fn=<MseLossBackward0>)\n",
      "6421\n",
      "tensor(0.1800, grad_fn=<MseLossBackward0>)\n",
      "6422\n",
      "tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "6423\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6424\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "6425\n",
      "tensor(0.2558, grad_fn=<MseLossBackward0>)\n",
      "6426\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "6427\n",
      "tensor(0.1485, grad_fn=<MseLossBackward0>)\n",
      "6428\n",
      "tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "6429\n",
      "tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "6430\n",
      "tensor(0.2709, grad_fn=<MseLossBackward0>)\n",
      "6431\n",
      "tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "6432\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "6433\n",
      "tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "6434\n",
      "tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "6435\n",
      "tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "6436\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "6437\n",
      "tensor(0.0960, grad_fn=<MseLossBackward0>)\n",
      "6438\n",
      "tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "6439\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "6440\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "6441\n",
      "tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "6442\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "6443\n",
      "tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "6444\n",
      "tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "6445\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6446\n",
      "tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "6447\n",
      "tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "6448\n",
      "tensor(0.1828, grad_fn=<MseLossBackward0>)\n",
      "6449\n",
      "tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "6450\n",
      "tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "6451\n",
      "tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "6452\n",
      "tensor(0.1206, grad_fn=<MseLossBackward0>)\n",
      "6453\n",
      "tensor(0.1649, grad_fn=<MseLossBackward0>)\n",
      "6454\n",
      "tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
      "6455\n",
      "tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "6456\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6457\n",
      "tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "6458\n",
      "tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "6459\n",
      "tensor(0.1301, grad_fn=<MseLossBackward0>)\n",
      "6460\n",
      "tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "6461\n",
      "tensor(0.2519, grad_fn=<MseLossBackward0>)\n",
      "6462\n",
      "tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "6463\n",
      "tensor(0.2631, grad_fn=<MseLossBackward0>)\n",
      "6464\n",
      "tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "6465\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "6466\n",
      "tensor(0.2556, grad_fn=<MseLossBackward0>)\n",
      "6467\n",
      "tensor(0.1938, grad_fn=<MseLossBackward0>)\n",
      "6468\n",
      "tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "6469\n",
      "tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "6470\n",
      "tensor(0.1870, grad_fn=<MseLossBackward0>)\n",
      "6471\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "6472\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "6473\n",
      "tensor(0.2699, grad_fn=<MseLossBackward0>)\n",
      "6474\n",
      "tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "6475\n",
      "tensor(0.1933, grad_fn=<MseLossBackward0>)\n",
      "6476\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "6477\n",
      "tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "6478\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "6479\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "6480\n",
      "tensor(0.2213, grad_fn=<MseLossBackward0>)\n",
      "6481\n",
      "tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
      "6482\n",
      "tensor(0.1677, grad_fn=<MseLossBackward0>)\n",
      "6483\n",
      "tensor(0.1918, grad_fn=<MseLossBackward0>)\n",
      "6484\n",
      "tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "6485\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "6486\n",
      "tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "6487\n",
      "tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
      "6488\n",
      "tensor(0.3582, grad_fn=<MseLossBackward0>)\n",
      "6489\n",
      "tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "6490\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "6491\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6492\n",
      "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "6493\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "6494\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "6495\n",
      "tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "6496\n",
      "tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "6497\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "6498\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "6499\n",
      "tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "6500\n",
      "tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "6501\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "6502\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "6503\n",
      "tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "6504\n",
      "tensor(0.2186, grad_fn=<MseLossBackward0>)\n",
      "6505\n",
      "tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "6506\n",
      "tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "6507\n",
      "tensor(0.2117, grad_fn=<MseLossBackward0>)\n",
      "6508\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "6509\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6510\n",
      "tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "6511\n",
      "tensor(0.1565, grad_fn=<MseLossBackward0>)\n",
      "6512\n",
      "tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "6513\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6514\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "6515\n",
      "tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "6516\n",
      "tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "6517\n",
      "tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "6518\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6519\n",
      "tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "6520\n",
      "tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "6521\n",
      "tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "6522\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "6523\n",
      "tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "6524\n",
      "tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "6525\n",
      "tensor(0.3293, grad_fn=<MseLossBackward0>)\n",
      "6526\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6527\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "6528\n",
      "tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "6529\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "6530\n",
      "tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "6531\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "6532\n",
      "tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "6533\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "6534\n",
      "tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "6535\n",
      "tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "6536\n",
      "tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "6537\n",
      "tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "6538\n",
      "tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "6539\n",
      "tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "6540\n",
      "tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "6541\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6542\n",
      "tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
      "6543\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6544\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "6545\n",
      "tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "6546\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "6547\n",
      "tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "6548\n",
      "tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "6549\n",
      "tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "6550\n",
      "tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
      "6551\n",
      "tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "6552\n",
      "tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "6553\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "6554\n",
      "tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "6555\n",
      "tensor(0.1640, grad_fn=<MseLossBackward0>)\n",
      "6556\n",
      "tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "6557\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "6558\n",
      "tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "6559\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6560\n",
      "tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
      "6561\n",
      "tensor(0.1969, grad_fn=<MseLossBackward0>)\n",
      "6562\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6563\n",
      "tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "6564\n",
      "tensor(0.1886, grad_fn=<MseLossBackward0>)\n",
      "6565\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6566\n",
      "tensor(0.2832, grad_fn=<MseLossBackward0>)\n",
      "6567\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6568\n",
      "tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "6569\n",
      "tensor(0.2173, grad_fn=<MseLossBackward0>)\n",
      "6570\n",
      "tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "6571\n",
      "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "6572\n",
      "tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "6573\n",
      "tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "6574\n",
      "tensor(0.1752, grad_fn=<MseLossBackward0>)\n",
      "6575\n",
      "tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "6576\n",
      "tensor(0.1967, grad_fn=<MseLossBackward0>)\n",
      "6577\n",
      "tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "6578\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "6579\n",
      "tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "6580\n",
      "tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "6581\n",
      "tensor(0.1573, grad_fn=<MseLossBackward0>)\n",
      "6582\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6583\n",
      "tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "6584\n",
      "tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "6585\n",
      "tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "6586\n",
      "tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "6587\n",
      "tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "6588\n",
      "tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "6589\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6590\n",
      "tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "6591\n",
      "tensor(0.1965, grad_fn=<MseLossBackward0>)\n",
      "6592\n",
      "tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "6593\n",
      "tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "6594\n",
      "tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "6595\n",
      "tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "6596\n",
      "tensor(0.1857, grad_fn=<MseLossBackward0>)\n",
      "6597\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "6598\n",
      "tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "6599\n",
      "tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "6600\n",
      "tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "6601\n",
      "tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "6602\n",
      "tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "6603\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "6604\n",
      "tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "6605\n",
      "tensor(0.1833, grad_fn=<MseLossBackward0>)\n",
      "6606\n",
      "tensor(0.1905, grad_fn=<MseLossBackward0>)\n",
      "6607\n",
      "tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "6608\n",
      "tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "6609\n",
      "tensor(0.1850, grad_fn=<MseLossBackward0>)\n",
      "6610\n",
      "tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "6611\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "6612\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6613\n",
      "tensor(0.1861, grad_fn=<MseLossBackward0>)\n",
      "6614\n",
      "tensor(0.1714, grad_fn=<MseLossBackward0>)\n",
      "6615\n",
      "tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "6616\n",
      "tensor(0.1932, grad_fn=<MseLossBackward0>)\n",
      "6617\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "6618\n",
      "tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
      "6619\n",
      "tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "6620\n",
      "tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "6621\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "6622\n",
      "tensor(0.1795, grad_fn=<MseLossBackward0>)\n",
      "6623\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "6624\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "6625\n",
      "tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "6626\n",
      "tensor(0.2781, grad_fn=<MseLossBackward0>)\n",
      "6627\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "6628\n",
      "tensor(0.3199, grad_fn=<MseLossBackward0>)\n",
      "6629\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "6630\n",
      "tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "6631\n",
      "tensor(0.1451, grad_fn=<MseLossBackward0>)\n",
      "6632\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6633\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "6634\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "6635\n",
      "tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "6636\n",
      "tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "6637\n",
      "tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "6638\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "6639\n",
      "tensor(0.1501, grad_fn=<MseLossBackward0>)\n",
      "6640\n",
      "tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "6641\n",
      "tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "6642\n",
      "tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "6643\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "6644\n",
      "tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "6645\n",
      "tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "6646\n",
      "tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "6647\n",
      "tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "6648\n",
      "tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "6649\n",
      "tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "6650\n",
      "tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "6651\n",
      "tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "6652\n",
      "tensor(0.4039, grad_fn=<MseLossBackward0>)\n",
      "6653\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "6654\n",
      "tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "6655\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "6656\n",
      "tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "6657\n",
      "tensor(0.1796, grad_fn=<MseLossBackward0>)\n",
      "6658\n",
      "tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "6659\n",
      "tensor(0.1839, grad_fn=<MseLossBackward0>)\n",
      "6660\n",
      "tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "6661\n",
      "tensor(0.1809, grad_fn=<MseLossBackward0>)\n",
      "6662\n",
      "tensor(0.2596, grad_fn=<MseLossBackward0>)\n",
      "6663\n",
      "tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "6664\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "6665\n",
      "tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "6666\n",
      "tensor(0.1876, grad_fn=<MseLossBackward0>)\n",
      "6667\n",
      "tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "6668\n",
      "tensor(0.1681, grad_fn=<MseLossBackward0>)\n",
      "6669\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "6670\n",
      "tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "6671\n",
      "tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "6672\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "6673\n",
      "tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "6674\n",
      "tensor(0.3045, grad_fn=<MseLossBackward0>)\n",
      "6675\n",
      "tensor(0.4165, grad_fn=<MseLossBackward0>)\n",
      "6676\n",
      "tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "6677\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "6678\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6679\n",
      "tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "6680\n",
      "tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "6681\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "6682\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6683\n",
      "tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "6684\n",
      "tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "6685\n",
      "tensor(0.1774, grad_fn=<MseLossBackward0>)\n",
      "6686\n",
      "tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "6687\n",
      "tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "6688\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "6689\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "6690\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6691\n",
      "tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "6692\n",
      "tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "6693\n",
      "tensor(0.2160, grad_fn=<MseLossBackward0>)\n",
      "6694\n",
      "tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "6695\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "6696\n",
      "tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "6697\n",
      "tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "6698\n",
      "tensor(0.1332, grad_fn=<MseLossBackward0>)\n",
      "6699\n",
      "tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "6700\n",
      "tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "6701\n",
      "tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "6702\n",
      "tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "6703\n",
      "tensor(0.1227, grad_fn=<MseLossBackward0>)\n",
      "6704\n",
      "tensor(0.1547, grad_fn=<MseLossBackward0>)\n",
      "6705\n",
      "tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "6706\n",
      "tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "6707\n",
      "tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "6708\n",
      "tensor(0.1965, grad_fn=<MseLossBackward0>)\n",
      "6709\n",
      "tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "6710\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "6711\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "6712\n",
      "tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "6713\n",
      "tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "6714\n",
      "tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "6715\n",
      "tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "6716\n",
      "tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "6717\n",
      "tensor(0.1984, grad_fn=<MseLossBackward0>)\n",
      "6718\n",
      "tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "6719\n",
      "tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "6720\n",
      "tensor(0.1388, grad_fn=<MseLossBackward0>)\n",
      "6721\n",
      "tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "6722\n",
      "tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "6723\n",
      "tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "6724\n",
      "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "6725\n"
     ]
    }
   ],
   "source": [
    "rec_errors = torch.zeros(len(sequences))\n",
    "\n",
    "for i in range(len(sequences)):\n",
    "    seq = torch.from_numpy(np.array(sequences[i])).type(torch.FloatTensor)\n",
    "    tim = torch.from_numpy(np.array(timestamps[i])).type(torch.FloatTensor)\n",
    "    _,_, rec_error = model.predict(seq, tim.unsqueeze(1))\n",
    "    rec_errors[i] = rec_error.item()\n",
    "    print(rec_error)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "419a1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07628213614225388\n"
     ]
    }
   ],
   "source": [
    "print(rec_errors[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97f037f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rec_errors', 'wb') as f:\n",
    "    pickle.dump(rec_errors,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f27ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4e82fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=rec_errors.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b572eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a5d79a1",
   "metadata": {},
   "source": [
    "### kernel breaks down after 489..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d46f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d524f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "400\n",
      "tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "401\n",
      "tensor(0.1845, grad_fn=<MseLossBackward0>)\n",
      "402\n",
      "tensor(0.1928, grad_fn=<MseLossBackward0>)\n",
      "403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([38, 1, 128])) that is different to the input size (torch.Size([38, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 1, 128])) that is different to the input size (torch.Size([256, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "404\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "405\n",
      "tensor(0.1332, grad_fn=<MseLossBackward0>)\n",
      "406\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "407\n",
      "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "408\n",
      "tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "409\n",
      "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([234, 1, 128])) that is different to the input size (torch.Size([234, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "411\n",
      "tensor(0.1647, grad_fn=<MseLossBackward0>)\n",
      "412\n",
      "tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([468, 1, 128])) that is different to the input size (torch.Size([468, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([266, 1, 128])) that is different to the input size (torch.Size([266, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1187, grad_fn=<MseLossBackward0>)\n",
      "414\n",
      "tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "415\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "416\n",
      "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "417\n",
      "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "418\n",
      "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([889, 1, 128])) that is different to the input size (torch.Size([889, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "420\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "421\n",
      "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "422\n",
      "tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "423\n",
      "tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([93, 1, 128])) that is different to the input size (torch.Size([93, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([217, 1, 128])) that is different to the input size (torch.Size([217, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "425\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "426\n",
      "tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "427\n",
      "tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([321, 1, 128])) that is different to the input size (torch.Size([321, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([489, 1, 128])) that is different to the input size (torch.Size([489, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1158, grad_fn=<MseLossBackward0>)\n",
      "429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([345, 1, 128])) that is different to the input size (torch.Size([345, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([271, 1, 128])) that is different to the input size (torch.Size([271, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1788, grad_fn=<MseLossBackward0>)\n",
      "430\n",
      "tensor(0.1217, grad_fn=<MseLossBackward0>)\n",
      "431\n",
      "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
      "432\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "433\n",
      "tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "434\n",
      "tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "435\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "436\n",
      "tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "437\n",
      "tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "438\n",
      "tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([53, 1, 128])) that is different to the input size (torch.Size([53, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "440\n",
      "tensor(0.1778, grad_fn=<MseLossBackward0>)\n",
      "441\n",
      "tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([187, 1, 128])) that is different to the input size (torch.Size([187, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([99, 1, 128])) that is different to the input size (torch.Size([99, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "443\n",
      "tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "444\n",
      "tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "445\n",
      "tensor(0.3300, grad_fn=<MseLossBackward0>)\n",
      "446\n",
      "tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "447\n",
      "tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "448\n",
      "tensor(0.1711, grad_fn=<MseLossBackward0>)\n",
      "449\n",
      "tensor(0.1219, grad_fn=<MseLossBackward0>)\n",
      "450\n",
      "tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "451\n",
      "tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "452\n",
      "tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "453\n",
      "tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "454\n",
      "tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "455\n",
      "tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "456\n",
      "tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([724, 1, 128])) that is different to the input size (torch.Size([724, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1352, grad_fn=<MseLossBackward0>)\n",
      "458\n",
      "tensor(0.1320, grad_fn=<MseLossBackward0>)\n",
      "459\n",
      "tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "460\n",
      "tensor(0.1334, grad_fn=<MseLossBackward0>)\n",
      "461\n",
      "tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([596, 1, 128])) that is different to the input size (torch.Size([596, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "463\n",
      "tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "464\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "465\n",
      "tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([367, 1, 128])) that is different to the input size (torch.Size([367, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([82, 1, 128])) that is different to the input size (torch.Size([82, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([22, 1, 128])) that is different to the input size (torch.Size([22, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "467\n",
      "tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "468\n",
      "tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "469\n",
      "tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "470\n",
      "tensor(0.1825, grad_fn=<MseLossBackward0>)\n",
      "471\n",
      "tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "472\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([525, 1, 128])) that is different to the input size (torch.Size([525, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([162, 1, 128])) that is different to the input size (torch.Size([162, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "474\n",
      "tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "475\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "476\n",
      "tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "477\n",
      "tensor(0.1169, grad_fn=<MseLossBackward0>)\n",
      "478\n",
      "tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "479\n",
      "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
      "480\n",
      "tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([247, 1, 128])) that is different to the input size (torch.Size([247, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "482\n",
      "tensor(0.2426, grad_fn=<MseLossBackward0>)\n",
      "483\n",
      "tensor(0.1142, grad_fn=<MseLossBackward0>)\n",
      "484\n",
      "tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "485\n",
      "tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "486\n",
      "tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "487\n",
      "tensor(0.1200, grad_fn=<MseLossBackward0>)\n",
      "488\n",
      "tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4707, 1, 128])) that is different to the input size (torch.Size([4707, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "for i in range(400, 800):\n",
    "    seq = torch.from_numpy(np.array(sequences[i])).type(torch.FloatTensor)\n",
    "    tim = torch.from_numpy(np.array(timestamps[i])).type(torch.FloatTensor)\n",
    "    _,_, rec_error = model.predict(seq, tim.unsqueeze(1))\n",
    "    rec_errors.append(rec_error)\n",
    "    print(rec_error)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution plot for rec_errors\n",
    "\n",
    "# get vip_level array\n",
    "\n",
    "# get country_code array\n",
    "\n",
    "# get the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acacc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST\n",
    "\n",
    "# LSTM AUTOENCODER\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.90it/s, loss=0.0091651650]\n",
    "\n",
    "# TRAINING ACCURACY\n",
    "# 0.009165165014564991\n",
    "# 0.09573486833210244\n",
    "\n",
    "# TESTING MEAN LOSS\n",
    "# 25.63962173461914\n",
    "# 5.063558208870432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIATIONAL AUTOENCODER\n",
    "\n",
    "# TRAINING\n",
    "# 100%|██████████| 500/500 [00:43<00:00, 11.39it/s, loss=0.0042354001]\n",
    "# 100%|██████████| 500/500 [00:43<00:00, 11.36it/s, loss=0.0154977629]\n",
    "# 100%|██████████| 500/500 [00:43<00:00, 11.41it/s, loss=0.0088684270]\n",
    "\n",
    "# TESTING\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.87it/s, loss=0.0062272854]\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.81it/s, loss=0.0018926092]\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.84it/s, loss=0.0130772868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590df409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVERSED VS NON-REVERSED => REVERSED WORKS BETTER!\n",
    "# NON-REVERSED\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.86it/s, loss=0.0000736655]\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.84it/s, loss=0.0000185950]\n",
    "# 100%|██████████| 500/500 [00:42<00:00, 11.75it/s, loss=0.0000177078]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88571e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea72ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.decoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.train_predecoder(torched_windowed_sequences, \n",
    "                              torched_windowed_timestamps, 2,\n",
    "                              n_epochs = 500, batch_size = 5, training_prediction = 'mixed_teacher_forcing', teacher_forcing_ratio = 0.6, learning_rate = 0.01, dynamic_tf = False)\n",
    "print(math.sqrt(loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55fb58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with freezing\n",
    "# 100%|██████████| 500/500 [00:09<00:00, 50.44it/s, loss=0.0011930717]\n",
    "# 100%|██████████| 500/500 [00:10<00:00, 49.09it/s, loss=0.0013867632]\n",
    "\n",
    "# without freezing\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5546af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.encoder.state_dict())\n",
    "print(model.predictor.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8968a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "# 100%|██████████| 500/500 [00:45<00:00, 10.88it/s, loss=0.0000253534]\n",
    "# 100%|██████████| 500/500 [00:43<00:00, 11.58it/s, loss=0.0000157571]\n",
    "\n",
    "# LSTM w/ Peephole\n",
    "# 100%|██████████| 500/500 [00:52<00:00,  9.59it/s, loss=0.0000155904]\n",
    "# 100%|██████████| 500/500 [00:52<00:00,  9.56it/s, loss=0.0001305166]\n",
    "\n",
    "# LSTM w/ Peephole + Coupled Gates\n",
    "# 100%|██████████| 500/500 [00:55<00:00,  9.02it/s, loss=0.0005010203]\n",
    "# 100%|██████████| 500/500 [00:56<00:00,  8.83it/s, loss=0.0051181654]\n",
    "\n",
    "# TIME-LSTM 1\n",
    "# 100%|██████████| 500/500 [01:07<00:00,  7.43it/s, loss=0.0060292104]\n",
    "# 100%|██████████| 500/500 [01:07<00:00,  7.41it/s, loss=0.0104567041]\n",
    "\n",
    "# TIME-LSTM 2\n",
    "# 100%|██████████| 500/500 [01:20<00:00,  6.23it/s, loss=0.0013810578]\n",
    "# 100%|██████████| 500/500 [01:22<00:00,  6.07it/s, loss=0.0025202912]\n",
    "\n",
    "# TIME-LSTM 3\n",
    "# 100%|██████████| 500/500 [01:11<00:00,  6.95it/s, loss=0.0001785948]\n",
    "# 100%|██████████| 500/500 [01:13<00:00,  6.83it/s, loss=0.0001769290]\n",
    "# 5000 epochs\n",
    "\n",
    "# CUSTOM TIME\n",
    "# 100%|██████████| 500/500 [00:52<00:00,  9.57it/s, loss=0.0000210490]\n",
    "\n",
    "# PHASED-LSTM\n",
    "\n",
    "\n",
    "\n",
    "# 100%|██████████| 500/500 [00:38<00:00, 12.95it/s, loss=0.0000069499]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375e6f1",
   "metadata": {},
   "source": [
    "### Encoder-Decoder for Time-Series\n",
    "\n",
    "Using the same encoder model, we encode a window of operations to predict the next window of operations\n",
    "This is to show that the embeddings are meaningful such that through:\n",
    "1. The AE Decoder, they contain the historical user behaviour information\n",
    "2. The Time-Series Decoder, they contain the future user behaviour information:\n",
    "        1. Retrieve categorical sequences\n",
    "        2. Each output, categorical layer to assign to operation\n",
    "        3. Compute accuracy from correct operation category output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff10dd",
   "metadata": {},
   "source": [
    "100%|██████████| 500/500 [00:38<00:00, 12.95it/s, loss=0.0000069499]\n",
    "\n",
    "Run a grid search/random search on LSTM layers, latent space dimension, and epochs\n",
    "\n",
    "Where does the embedding come from?\n",
    "\n",
    "ASSUME TIME GATE WORKS BETTER THAN NO TIME GATE? because loss seems to be \\leq \n",
    "\n",
    "(we may use torch.nn.lstm for comparison)\n",
    "\n",
    "-loss=0.0000102043 on hidden size 15, epochs 500\n",
    "\n",
    "-loss=0.0000010081 on hidden size 30, epochs 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf10cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#torch.set_printoptions(threshold=sys.maxsize) # this will kill the kernel!\n",
    "\n",
    "print(torched_windowed_timestamps[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torched_windowed_timestamps[:,9].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torched_windowed_sequences[:,6][-1])\n",
    "print(torched_windowed_timestamps[:,6][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957233d1",
   "metadata": {},
   "source": [
    "### Cluster Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([ 7.2859e-02, -5.1723e-02,  1.6887e-01,  9.6478e-03,  2.7092e-01,\n",
    "         1.4126e-02,  1.2384e-01, -3.9685e-04,  2.2763e-01, -4.0240e-01,\n",
    "        -1.9798e-01, -3.4064e-01, -2.0647e-01,  1.3255e-01,  6.4034e-03,\n",
    "        -1.3859e-02,  1.0164e-01,  1.6872e-01, -1.1312e-01, -3.2962e-01,\n",
    "        -1.0826e-01, -1.7407e-02, -2.5063e-01, -1.6811e-01, -1.6072e-02,\n",
    "        -3.7014e-02,  8.8129e-02,  5.9020e-02,  1.5442e-01,  1.1737e-01,\n",
    "        -7.6847e-02,  4.6167e-02,  1.7816e-01,  3.5143e-01, -2.0578e-01,\n",
    "        -8.1568e-02,  1.6674e-01,  1.3171e-01,  4.0933e-02, -4.2767e-02,\n",
    "         4.8727e-01,  5.1966e-02, -2.6346e-01,  6.2688e-01,  2.4226e-01,\n",
    "         1.6288e-02,  1.5292e-01, -3.1451e-01, -4.3505e-02, -1.1195e-01,\n",
    "         3.7763e-02,  1.8957e-01,  6.5843e-02,  6.7268e-03, -1.6360e-01,\n",
    "         7.9658e-02,  8.2879e-03, -1.2846e-01,  1.8420e-01, -1.6801e-01,\n",
    "        -2.2163e-01, -8.7116e-02,  1.8645e-01, -7.0144e-02,  2.9216e-02,\n",
    "        -2.6450e-02, -3.7200e-02,  3.4123e-02, -1.3855e-01,  1.2327e-01,\n",
    "         9.6004e-03,  1.6783e-01, -1.9080e-01, -1.8574e-02,  1.3258e-01,\n",
    "         3.9922e-01,  2.0783e-01,  2.1572e-02, -2.8567e-02, -4.5407e-02,\n",
    "        -8.5485e-02, -8.9264e-03, -3.4358e-02,  1.5016e-02, -2.4072e-02,\n",
    "         2.4404e-01, -3.1834e-02, -2.7986e-02,  7.4648e-02, -1.0087e-02,\n",
    "        -3.1862e-02, -2.3848e-01, -8.0869e-02, -2.0942e-02, -6.9803e-02,\n",
    "         2.3009e-01,  1.3550e-01, -9.0289e-02,  7.8311e-03, -8.4256e-02,\n",
    "         1.4535e-01, -1.3228e-01,  1.1738e-03,  1.1044e-01, -9.6383e-02,\n",
    "        -3.6381e-03, -2.2033e-01,  1.2453e-01, -1.4537e-01, -7.5747e-03,\n",
    "         5.2217e-01, -3.2780e-01,  6.7146e-02, -1.4363e-01, -1.9472e-01,\n",
    "        -6.7836e-02,  2.1534e-01, -2.1962e-02,  5.1992e-01,  4.6406e-02,\n",
    "        -1.7308e-01,  8.7515e-02, -6.2887e-02,  2.3623e-02,  2.3809e-02,\n",
    "        -2.0818e-01, -2.4797e-02, -7.4244e-09])\n",
    "\n",
    "seq2 = torch.cat((torched_windowed_sequences[:,6], input_tensor.unsqueeze(0)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b633d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tensor = torch.tensor([325235235523.])\n",
    "time2 = torch.cat((torched_windowed_timestamps[:,6],time_tensor)).unsqueeze(1)\n",
    "print(torched_windowed_timestamps[:,6].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, embedding = model.predict(torched_windowed_sequences[:,6], torch.zeros(torched_windowed_sequences[:,6].shape[1]).unsqueeze(1))\n",
    "embedding = torch.cat(embedding).ravel().detach().numpy()\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5957fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2, embedding2 = model.predict(seq2, time2)\n",
    "embedding2 = torch.cat(embedding2).ravel().detach().numpy()\n",
    "print(embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(embedding2 - embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### is there any cost/energy associated with training for such a long time?\n",
    "\n",
    "# set window size\n",
    "# user sequences > window size -> more than one instance (sequence len - window size number of instances)\n",
    "\n",
    "# better to truncate based on time gap\n",
    "\n",
    "# reimplement with time gates\n",
    "\n",
    "# freedom, accessibility with machine learning models\n",
    "# random search instead of grid search (more efficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012c8dd",
   "metadata": {},
   "source": [
    "## Saving the model (and its checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9134a6",
   "metadata": {},
   "source": [
    "## Embed all Users!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85145b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequences)\n",
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611afaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences1= sequences[:2000]\n",
    "timestamps1=timestamps[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caec71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "uobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a39e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6726\n",
      "6726\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))\n",
    "print(len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b36fdc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([19, 1, 128])) that is different to the input size (torch.Size([19, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([104, 1, 128])) that is different to the input size (torch.Size([104, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([40, 1, 128])) that is different to the input size (torch.Size([40, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([116, 1, 128])) that is different to the input size (torch.Size([116, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 1, 128])) that is different to the input size (torch.Size([4, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([75, 1, 128])) that is different to the input size (torch.Size([75, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "188\n",
      "189\n",
      "190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([285, 1, 128])) that is different to the input size (torch.Size([285, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([30, 1, 128])) that is different to the input size (torch.Size([30, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "192\n",
      "193\n",
      "194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([377, 1, 128])) that is different to the input size (torch.Size([377, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([11, 1, 128])) that is different to the input size (torch.Size([11, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "196\n",
      "197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([306, 1, 128])) that is different to the input size (torch.Size([306, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([23, 1, 128])) that is different to the input size (torch.Size([23, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([56, 1, 128])) that is different to the input size (torch.Size([56, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([144, 1, 128])) that is different to the input size (torch.Size([144, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([112, 1, 128])) that is different to the input size (torch.Size([112, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([67, 1, 128])) that is different to the input size (torch.Size([67, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "205\n",
      "206\n",
      "207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([358, 1, 128])) that is different to the input size (torch.Size([358, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([387, 1, 128])) that is different to the input size (torch.Size([387, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([231, 1, 128])) that is different to the input size (torch.Size([231, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([750, 1, 128])) that is different to the input size (torch.Size([750, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([68, 1, 128])) that is different to the input size (torch.Size([68, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([110, 1, 128])) that is different to the input size (torch.Size([110, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([179, 1, 128])) that is different to the input size (torch.Size([179, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "229\n",
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([84, 1, 128])) that is different to the input size (torch.Size([84, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([286, 1, 128])) that is different to the input size (torch.Size([286, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([218, 1, 128])) that is different to the input size (torch.Size([218, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([106, 1, 128])) that is different to the input size (torch.Size([106, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([396, 1, 128])) that is different to the input size (torch.Size([396, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16, 1, 128])) that is different to the input size (torch.Size([16, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([203, 1, 128])) that is different to the input size (torch.Size([203, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([332, 1, 128])) that is different to the input size (torch.Size([332, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([420, 1, 128])) that is different to the input size (torch.Size([420, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([298, 1, 128])) that is different to the input size (torch.Size([298, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([246, 1, 128])) that is different to the input size (torch.Size([246, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([103, 1, 128])) that is different to the input size (torch.Size([103, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([57, 1, 128])) that is different to the input size (torch.Size([57, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([96, 1, 128])) that is different to the input size (torch.Size([96, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([416, 1, 128])) that is different to the input size (torch.Size([416, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([252, 1, 128])) that is different to the input size (torch.Size([252, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([69, 1, 128])) that is different to the input size (torch.Size([69, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([44, 1, 128])) that is different to the input size (torch.Size([44, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([197, 1, 128])) that is different to the input size (torch.Size([197, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "279\n",
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([87, 1, 128])) that is different to the input size (torch.Size([87, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n",
      "282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([374, 1, 128])) that is different to the input size (torch.Size([374, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n",
      "284\n",
      "285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([566, 1, 128])) that is different to the input size (torch.Size([566, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([60, 1, 128])) that is different to the input size (torch.Size([60, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([244, 1, 128])) that is different to the input size (torch.Size([244, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([330, 1, 128])) that is different to the input size (torch.Size([330, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([37, 1, 128])) that is different to the input size (torch.Size([37, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([170, 1, 128])) that is different to the input size (torch.Size([170, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([230, 1, 128])) that is different to the input size (torch.Size([230, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([47, 1, 128])) that is different to the input size (torch.Size([47, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35, 1, 128])) that is different to the input size (torch.Size([35, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([190, 1, 128])) that is different to the input size (torch.Size([190, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([72, 1, 128])) that is different to the input size (torch.Size([72, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([167, 1, 128])) that is different to the input size (torch.Size([167, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([323, 1, 128])) that is different to the input size (torch.Size([323, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([132, 1, 128])) that is different to the input size (torch.Size([132, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([215, 1, 128])) that is different to the input size (torch.Size([215, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([263, 1, 128])) that is different to the input size (torch.Size([263, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "324\n",
      "325\n",
      "326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([897, 1, 128])) that is different to the input size (torch.Size([897, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([105, 1, 128])) that is different to the input size (torch.Size([105, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([276, 1, 128])) that is different to the input size (torch.Size([276, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([33, 1, 128])) that is different to the input size (torch.Size([33, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([318, 1, 128])) that is different to the input size (torch.Size([318, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([59, 1, 128])) that is different to the input size (torch.Size([59, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([74, 1, 128])) that is different to the input size (torch.Size([74, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([126, 1, 128])) that is different to the input size (torch.Size([126, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([92, 1, 128])) that is different to the input size (torch.Size([92, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n",
      "357\n",
      "358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([70, 1, 128])) that is different to the input size (torch.Size([70, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2041, 1, 128])) that is different to the input size (torch.Size([2041, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([137, 1, 128])) that is different to the input size (torch.Size([137, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([444, 1, 128])) that is different to the input size (torch.Size([444, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([3, 1, 128])) that is different to the input size (torch.Size([3, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([114, 1, 128])) that is different to the input size (torch.Size([114, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([139, 1, 128])) that is different to the input size (torch.Size([139, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([91, 1, 128])) that is different to the input size (torch.Size([91, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([38, 1, 128])) that is different to the input size (torch.Size([38, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 1, 128])) that is different to the input size (torch.Size([256, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([234, 1, 128])) that is different to the input size (torch.Size([234, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([468, 1, 128])) that is different to the input size (torch.Size([468, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([266, 1, 128])) that is different to the input size (torch.Size([266, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([889, 1, 128])) that is different to the input size (torch.Size([889, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([93, 1, 128])) that is different to the input size (torch.Size([93, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([217, 1, 128])) that is different to the input size (torch.Size([217, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([321, 1, 128])) that is different to the input size (torch.Size([321, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "426\n",
      "427\n",
      "428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([489, 1, 128])) that is different to the input size (torch.Size([489, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([345, 1, 128])) that is different to the input size (torch.Size([345, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([271, 1, 128])) that is different to the input size (torch.Size([271, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([53, 1, 128])) that is different to the input size (torch.Size([53, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([187, 1, 128])) that is different to the input size (torch.Size([187, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([99, 1, 128])) that is different to the input size (torch.Size([99, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([724, 1, 128])) that is different to the input size (torch.Size([724, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([596, 1, 128])) that is different to the input size (torch.Size([596, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n",
      "464\n",
      "465\n",
      "466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([367, 1, 128])) that is different to the input size (torch.Size([367, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([82, 1, 128])) that is different to the input size (torch.Size([82, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([22, 1, 128])) that is different to the input size (torch.Size([22, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([525, 1, 128])) that is different to the input size (torch.Size([525, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([162, 1, 128])) that is different to the input size (torch.Size([162, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([247, 1, 128])) that is different to the input size (torch.Size([247, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4707, 1, 128])) that is different to the input size (torch.Size([4707, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n",
      "491\n",
      "492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([210, 1, 128])) that is different to the input size (torch.Size([210, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([602, 1, 128])) that is different to the input size (torch.Size([602, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([698, 1, 128])) that is different to the input size (torch.Size([698, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([65, 1, 128])) that is different to the input size (torch.Size([65, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([90, 1, 128])) that is different to the input size (torch.Size([90, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513\n",
      "514\n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([239, 1, 128])) that is different to the input size (torch.Size([239, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([533, 1, 128])) that is different to the input size (torch.Size([533, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([249, 1, 128])) that is different to the input size (torch.Size([249, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([98, 1, 128])) that is different to the input size (torch.Size([98, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([101, 1, 128])) that is different to the input size (torch.Size([101, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1242, 1, 128])) that is different to the input size (torch.Size([1242, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([273, 1, 128])) that is different to the input size (torch.Size([273, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([36, 1, 128])) that is different to the input size (torch.Size([36, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([424, 1, 128])) that is different to the input size (torch.Size([424, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([523, 1, 128])) that is different to the input size (torch.Size([523, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([89, 1, 128])) that is different to the input size (torch.Size([89, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([177, 1, 128])) that is different to the input size (torch.Size([177, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([191, 1, 128])) that is different to the input size (torch.Size([191, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579\n",
      "580\n",
      "581\n",
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([394, 1, 128])) that is different to the input size (torch.Size([394, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n",
      "584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([728, 1, 128])) that is different to the input size (torch.Size([728, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([165, 1, 128])) that is different to the input size (torch.Size([165, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([152, 1, 128])) that is different to the input size (torch.Size([152, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([39, 1, 128])) that is different to the input size (torch.Size([39, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([61, 1, 128])) that is different to the input size (torch.Size([61, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([182, 1, 128])) that is different to the input size (torch.Size([182, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([287, 1, 128])) that is different to the input size (torch.Size([287, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([391, 1, 128])) that is different to the input size (torch.Size([391, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n",
      "650\n",
      "651\n",
      "652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([185, 1, 128])) that is different to the input size (torch.Size([185, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([319, 1, 128])) that is different to the input size (torch.Size([319, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([113, 1, 128])) that is different to the input size (torch.Size([113, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([55, 1, 128])) that is different to the input size (torch.Size([55, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n",
      "659\n",
      "660\n",
      "661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([248, 1, 128])) that is different to the input size (torch.Size([248, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([115, 1, 128])) that is different to the input size (torch.Size([115, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n",
      "663\n",
      "664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([264, 1, 128])) that is different to the input size (torch.Size([264, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([316, 1, 128])) that is different to the input size (torch.Size([316, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([125, 1, 128])) that is different to the input size (torch.Size([125, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([506, 1, 128])) that is different to the input size (torch.Size([506, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([142, 1, 128])) that is different to the input size (torch.Size([142, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([138, 1, 128])) that is different to the input size (torch.Size([138, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1303, 1, 128])) that is different to the input size (torch.Size([1303, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([88, 1, 128])) that is different to the input size (torch.Size([88, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([455, 1, 128])) that is different to the input size (torch.Size([455, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([346, 1, 128])) that is different to the input size (torch.Size([346, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([143, 1, 128])) that is different to the input size (torch.Size([143, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([726, 1, 128])) that is different to the input size (torch.Size([726, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([188, 1, 128])) that is different to the input size (torch.Size([188, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([169, 1, 128])) that is different to the input size (torch.Size([169, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([151, 1, 128])) that is different to the input size (torch.Size([151, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([243, 1, 128])) that is different to the input size (torch.Size([243, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([130, 1, 128])) that is different to the input size (torch.Size([130, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([902, 1, 128])) that is different to the input size (torch.Size([902, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([212, 1, 128])) that is different to the input size (torch.Size([212, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([194, 1, 128])) that is different to the input size (torch.Size([194, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([845, 1, 128])) that is different to the input size (torch.Size([845, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n",
      "827\n",
      "828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([331, 1, 128])) that is different to the input size (torch.Size([331, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([703, 1, 128])) that is different to the input size (torch.Size([703, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([574, 1, 128])) that is different to the input size (torch.Size([574, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([201, 1, 128])) that is different to the input size (torch.Size([201, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([154, 1, 128])) that is different to the input size (torch.Size([154, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869\n",
      "870\n",
      "871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([435, 1, 128])) that is different to the input size (torch.Size([435, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([135, 1, 128])) that is different to the input size (torch.Size([135, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([453, 1, 128])) that is different to the input size (torch.Size([453, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([156, 1, 128])) that is different to the input size (torch.Size([156, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([131, 1, 128])) that is different to the input size (torch.Size([131, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([117, 1, 128])) that is different to the input size (torch.Size([117, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([149, 1, 128])) that is different to the input size (torch.Size([149, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([237, 1, 128])) that is different to the input size (torch.Size([237, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([211, 1, 128])) that is different to the input size (torch.Size([211, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([128, 1, 128])) that is different to the input size (torch.Size([128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([404, 1, 128])) that is different to the input size (torch.Size([404, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "1043\n",
      "1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([475, 1, 128])) that is different to the input size (torch.Size([475, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1718, 1, 128])) that is different to the input size (torch.Size([1718, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([259, 1, 128])) that is different to the input size (torch.Size([259, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([509, 1, 128])) that is different to the input size (torch.Size([509, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([62, 1, 128])) that is different to the input size (torch.Size([62, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([153, 1, 128])) that is different to the input size (torch.Size([153, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([251, 1, 128])) that is different to the input size (torch.Size([251, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([86, 1, 128])) that is different to the input size (torch.Size([86, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([351, 1, 128])) that is different to the input size (torch.Size([351, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([301, 1, 128])) that is different to the input size (torch.Size([301, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150, 1, 128])) that is different to the input size (torch.Size([150, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([223, 1, 128])) that is different to the input size (torch.Size([223, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194\n",
      "1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([457, 1, 128])) that is different to the input size (torch.Size([457, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([870, 1, 128])) that is different to the input size (torch.Size([870, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([97, 1, 128])) that is different to the input size (torch.Size([97, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([73, 1, 128])) that is different to the input size (torch.Size([73, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([159, 1, 128])) that is different to the input size (torch.Size([159, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([71, 1, 128])) that is different to the input size (torch.Size([71, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([290, 1, 128])) that is different to the input size (torch.Size([290, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([372, 1, 128])) that is different to the input size (torch.Size([372, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([76, 1, 128])) that is different to the input size (torch.Size([76, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([224, 1, 128])) that is different to the input size (torch.Size([224, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([650, 1, 128])) that is different to the input size (torch.Size([650, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([227, 1, 128])) that is different to the input size (torch.Size([227, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n",
      "1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([567, 1, 128])) that is different to the input size (torch.Size([567, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([343, 1, 128])) that is different to the input size (torch.Size([343, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([292, 1, 128])) that is different to the input size (torch.Size([292, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([811, 1, 128])) that is different to the input size (torch.Size([811, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([133, 1, 128])) that is different to the input size (torch.Size([133, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([107, 1, 128])) that is different to the input size (torch.Size([107, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([233, 1, 128])) that is different to the input size (torch.Size([233, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([102, 1, 128])) that is different to the input size (torch.Size([102, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([303, 1, 128])) that is different to the input size (torch.Size([303, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([443, 1, 128])) that is different to the input size (torch.Size([443, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([255, 1, 128])) that is different to the input size (torch.Size([255, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([196, 1, 128])) that is different to the input size (torch.Size([196, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([175, 1, 128])) that is different to the input size (torch.Size([175, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([399, 1, 128])) that is different to the input size (torch.Size([399, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([181, 1, 128])) that is different to the input size (torch.Size([181, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([136, 1, 128])) that is different to the input size (torch.Size([136, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([385, 1, 128])) that is different to the input size (torch.Size([385, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([193, 1, 128])) that is different to the input size (torch.Size([193, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([362, 1, 128])) that is different to the input size (torch.Size([362, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([258, 1, 128])) that is different to the input size (torch.Size([258, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([222, 1, 128])) that is different to the input size (torch.Size([222, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([393, 1, 128])) that is different to the input size (torch.Size([393, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([232, 1, 128])) that is different to the input size (torch.Size([232, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([157, 1, 128])) that is different to the input size (torch.Size([157, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([206, 1, 128])) that is different to the input size (torch.Size([206, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([315, 1, 128])) that is different to the input size (torch.Size([315, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([439, 1, 128])) that is different to the input size (torch.Size([439, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([507, 1, 128])) that is different to the input size (torch.Size([507, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([140, 1, 128])) that is different to the input size (torch.Size([140, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([118, 1, 128])) that is different to the input size (torch.Size([118, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([467, 1, 128])) that is different to the input size (torch.Size([467, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([94, 1, 128])) that is different to the input size (torch.Size([94, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([189, 1, 128])) that is different to the input size (torch.Size([189, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([262, 1, 128])) that is different to the input size (torch.Size([262, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([124, 1, 128])) that is different to the input size (torch.Size([124, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([176, 1, 128])) that is different to the input size (torch.Size([176, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1098, 1, 128])) that is different to the input size (torch.Size([1098, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([148, 1, 128])) that is different to the input size (torch.Size([148, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n"
     ]
    }
   ],
   "source": [
    "uobs = []\n",
    "\n",
    "for i in range(len(sequences)):\n",
    "    seq = torch.from_numpy(np.array(sequences[i])).type(torch.FloatTensor)\n",
    "    tim = torch.from_numpy(np.array(timestamps[i])).type(torch.FloatTensor)\n",
    "    _, embed, _ = model.predict(seq, tim.unsqueeze(1))\n",
    "    uobs.append(torch.cat(embed).ravel().detach().numpy())\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8648a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uobs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([-4.4352e-02,  1.2201e-02,  1.6216e-01,  1.6379e-01,  3.9218e-01,\n",
    "        -2.5394e-01, -5.2667e-02, -6.7875e-02,  6.5994e-01, -1.0205e-01,\n",
    "        -2.6776e-01, -2.0883e-01, -4.1226e-01,  7.7409e-02, -1.0235e-01,\n",
    "         3.9226e-01, -4.4637e-01, -3.3146e-01, -1.2367e-02, -5.5867e-02,\n",
    "        -7.0543e-01,  2.5752e-02, -5.8277e-02, -5.1242e-01, -9.3612e-02,\n",
    "         3.1211e-01,  2.6222e-01, -9.2457e-02,  1.3677e-01,  3.0865e-01,\n",
    "         2.4187e-01,  3.6984e-01,  6.5900e-01,  5.1530e-01,  1.4048e-02,\n",
    "        -2.5620e-01,  1.0549e-01,  3.4391e-01, -4.7275e-01,  3.2565e-02,\n",
    "         4.3158e-01, -1.5974e-01, -3.0765e-01,  5.4733e-01,  5.8574e-01,\n",
    "        -3.1861e-01,  2.0723e-01, -2.6745e-01, -6.3177e-02,  1.5469e-02,\n",
    "         5.2354e-02,  1.3191e-01,  2.1890e-01,  2.7721e-04,  3.7968e-02,\n",
    "        -9.9480e-02, -5.0709e-01,  1.6384e-01,  7.4540e-02,  4.1532e-02,\n",
    "        -5.4125e-02, -9.9936e-01,  3.2398e-01, -4.7699e-01,  1.5951e-01,\n",
    "         2.2943e-01, -2.6444e-01,  1.4613e-01, -5.8839e-01, -4.0362e-01,\n",
    "         1.2432e-01,  3.8341e-01, -2.6790e-01, -9.5816e-02, -2.8904e-01,\n",
    "         3.6368e-01,  8.3652e-02,  1.7725e-01,  2.7741e-01, -2.8172e-01,\n",
    "        -7.3207e-02,  4.3167e-01,  5.2676e-01, -2.8241e-01,  2.3268e-01,\n",
    "         2.0204e-01,  1.8995e-01,  2.2696e-01,  2.2350e-01, -1.2188e-01,\n",
    "        -3.5101e-02, -5.4444e-01, -4.6613e-01,  2.1541e-01,  2.2307e-01,\n",
    "        -1.0715e-01,  2.8139e-01,  1.6742e-01,  9.2263e-02,  2.7756e-01,\n",
    "         8.0698e-02, -1.8247e-01,  2.1044e-01,  2.0641e-01,  8.4537e-02,\n",
    "         2.7049e-01, -1.9913e-01, -2.0460e-01, -1.5651e-02,  5.7233e-01,\n",
    "         4.0540e-01, -1.4468e-01, -3.6146e-01, -2.8766e-01, -1.9464e-03,\n",
    "        -4.5186e-01, -8.1728e-02,  7.6493e-02, -1.9496e-02, -2.9143e-01,\n",
    "        -1.7943e-01,  4.2151e-01, -2.0292e-01,  5.1099e-01,  2.5352e-02,\n",
    "        -1.0709e-01,  1.5144e-01,  9.6194e-02])\n",
    "\n",
    "time_tensor = torch.tensor([34000.])\n",
    "\n",
    "embedding = uobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ce25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.test(input_tensor, time_tensor, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aecac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, embedding = model.test(torched_windowed_sequences[:,6], torched_windowed_timestamps[:,6].unsqueeze(1))\n",
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "393a9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uobs', 'wb') as f:\n",
    "    pickle.dump(uobs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = io.open('uobs.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, user in enumerate(uobs):\n",
    "    if index == 0:\n",
    "        continue  # skip 0, it's padding.\n",
    "    vec = weights[index]\n",
    "    out.write(word + \"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e244277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, embed1 = model.predict(torch.from_numpy(np.array(sequences[0])).type(torch.FloatTensor), torch.from_numpy(np.array(timestamps[0])).type(torch.FloatTensor).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cat(embed1).ravel().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68200a12",
   "metadata": {},
   "source": [
    "### To Do (Low Priority)\n",
    "\n",
    "Next steps:\n",
    "(1. Run a random hyperparameter search and re-review the code)\n",
    "(1. a) Finish the KMeans Operation-Level Embedding Test code)\n",
    "(2. Modify architecture based on Seq2Seq literature\n",
    "    - There are various architectures for many-to-many, namely Recursive (feeding), Repeat vectors, etc.\n",
    "    - Consider using EOS or SOS (currently we have only SOS)\n",
    "    - Consider delimitating sessions (but how to do it uniformly? does it go hand in hand with time gates?))\n",
    "2. Sanity check closest pairs\n",
    "3. Add time gates next, only after optimizing w/o\n",
    "4. Proceed with Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c07308",
   "metadata": {},
   "source": [
    "# Flagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9470ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for param in model.parameters():\n",
    "    print(i)\n",
    "    print(param.data)\n",
    "    print(param.data.shape)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4dbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eabf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20090584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6856dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0855e8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be6ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047d0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5653aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6123a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12377e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39070a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b2334f1",
   "metadata": {},
   "source": [
    "# K-Means Clustering + Operation-Level Flagging\n",
    "\n",
    "### To Do Later: DBScan Clustering, Variational Inference\n",
    "\n",
    "In order for there to be operation-level flagging, the user must be considered non-anomalous\n",
    "\n",
    "In other words, the next/latest operation must be anomalous enough for it to cause the hidden state to diverge\n",
    "\n",
    "Steps:\n",
    "1. Time-LSTM Autoencoder yields UOBS embeddings (encoder hidden states)\n",
    "2. UOBS embeddings are clustered to form user segmentations (or variational inference later...)\n",
    "3. Get hidden vector\n",
    "4. For each operation, calculate the bounds of time elapsed in which the operation keeps the user \"safe\"\n",
    "\n",
    "Such bounds are the \"flagging rules\". Alternatively, we may perform this on the cluster center to approximate a \"user profile\" based on fully-safe operations and safe bounds per non-fully-safe operations for some sort of user profiling that we can understand/imagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c436aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal kmeans cluster (ensemble, repeated trainings)\n",
    "# we want to maximize the Dunn index = min(intra cluster distance)/max (inter cluster distance)\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/ for KMeans ++\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=\"auto\").fit(X)\n",
    "kmeans.cluster_centers_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23649ffc",
   "metadata": {},
   "source": [
    "## Rough Analysis of User Level Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485808d1",
   "metadata": {},
   "source": [
    "### Roughly check similarities between 10-20 pairs of users and get back on this, then proceed to time gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do this with a windowed dataset? \n",
    "# as there is a different number of windows/instances generated per user\n",
    "\n",
    "OUT_path_pairs = 's3://tk-dev-datalake2/risk/jerry.zhu/UBS_Embedding/Op_Log_masked_20221121_20221129.parquet'\n",
    "data = pd.read_parquet(OUT_path_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ecbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "# filter out 1-operation users (non-sequential data)\n",
    "\n",
    "user_counts = data['user_id'].value_counts().reset_index()\n",
    "bottom_users = user_counts[user_counts['user_id']<=1]\n",
    "bottom_users = bottom_users['index'].tolist()\n",
    "data = data[~data['user_id'].isin(bottom_users)] \n",
    "print(\"Dataframe shape after filtering out singular operations is \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f395c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = data['user_id'].unique()\n",
    "\n",
    "print(len(users))\n",
    "print(users)\n",
    "\n",
    "def findIndex(name, users):\n",
    "    for i, user in enumerate(users):\n",
    "        if user==name:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequences))\n",
    "twentiesIndex = [i for i in range(len(sequences)) if len(sequences[i])==20]\n",
    "twentiesUsers = [users[i] for i in twentiesIndex]\n",
    "print(len(twentiesIndex))\n",
    "#print(twentiesUsers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0bc22",
   "metadata": {},
   "source": [
    "So we have 6726 users (and therefore sequences) with more than one operation in the last week of November;\n",
    "109 users with exactly 20 operations, so we're only going to compare across these users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "embTest = []\n",
    "predTest = []\n",
    "#twenties = w2vembedding(twenties, weights)\n",
    "for i in twentiesIndex:\n",
    "    prediction, embedding = model.predict(torched_windowed_sequences[:,i], torched_windowed_timestamps[:,i].unsqueeze(1))\n",
    "    embTest.append(torch.cat(embedding).ravel())\n",
    "    predTest.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embTest = [emb.detach().numpy() for emb in embTest]\n",
    "X = embTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f80de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_)\n",
    "print(set(kmeans.labels_))\n",
    "\n",
    "#kmeans.predict(X)\n",
    "#kmeans.cluster_centers_\n",
    "\n",
    "'''\n",
    "[ 6  7  6 10  7  7  6  6 14  4  6  9  2  6  0 10  9  6  6  3 11  9  7  1\n",
    "  1  1 11  5  7  0  4 12  2  0  6 11  6 11  0  3  6  3  2 12 10  0  6 11\n",
    "  1  3 12  1  1  0 12  6  2  9  4  3  9 10  0  8  0  3  0 10 11  5  8  1\n",
    "  1  1  1  7  1  1  1  1  1  6  6 10  4  6  2  9  9 11 10  4 14 10 12  2\n",
    "  4  6  7  9 10  0 10  6 13 13  6 10  7]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_v = io.open('embTest.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('userTest.tsv', 'w', encoding='utf-8')\n",
    "out_o = io.open('indexTest.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "\n",
    "for index, user in enumerate(twentiesUsers):\n",
    "    if index == 0:\n",
    "        continue  # skip 0, it's padding.\n",
    "    vec = embTest[index]\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(user + \"\\n\")\n",
    "    out_o.write(str(index) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "out_o.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(twentiesUsers))\n",
    "print(len(embTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109836b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embTest[37])\n",
    "print(twentiesUsers[37])\n",
    "print(embTest[35])\n",
    "print(twentiesUsers[35])\n",
    "print(embTest[81])\n",
    "print(twentiesUsers[81])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec08f5",
   "metadata": {},
   "source": [
    "#### Empirical check: \n",
    "\n",
    "79e2cebcc6e9cc225183b4b337ff2c95694de30f5fe61809ab06d0a6a20f5a42 AND \n",
    "\n",
    "67a4091d373bcf3fb471eaa42296c5d317b732f8525f583ae736fea4d4656be9\n",
    "\n",
    "are similar, while\n",
    "\n",
    "3eb626670ff5a334a4d88d7ec94a7b1af5ee611a7f04010ebfb278403707f279\n",
    "\n",
    "is different from both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(originalSeqs[findIndex(twentiesUsers[36], users)])\n",
    "print(originalSeqs[findIndex(twentiesUsers[46], users)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(originalSeqs[findIndex(twentiesUsers[48], users)])\n",
    "print(originalSeqs[findIndex(twentiesUsers[52], users)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d3877",
   "metadata": {},
   "source": [
    "Comments: in this scenario, some sequences are similar, yielding similar user-level vectors, but the significance of difference is not apparent. \n",
    "\n",
    "So, we try to find pairs with similar vectors, but apparently different sequences:\n",
    "- 36 and 46: \n",
    "    - c08db24027925633ced80abe9a69c7b728f800f3baeb9e8ca68f9e57a7b36628\n",
    "    - cb8ca9c313ecc4eee300d6da678cd84baa1ce10630689aa1ca1ed32acec4ccdc\n",
    "    - [17, 154, 154, 154, 53, 9, 47, 230, 47, 62, 154, 62, 92, 160, 187, 80, 202, 33, 138, 17]\n",
    "    - [243, 145, 116, 131, 144, 144, 37, 121, 13, 13, 164, 230, 206, 62, 160, 230, 80, 187, 202, 36]\n",
    "- 35 and 68:\n",
    "    - cedef2cf30f55063102ec7e27c6893533deb615211bc32c0fc2dd2a3317941c8\n",
    "    - 6af0230119b758863087fbf3a50ef1b796d52b0ab436c044a3dc739bc174f805\n",
    "    - [144, 144, 154, 230, 183, 17, 36, 144, 144, 62, 160, 80, 187, 202, 154, 230, 183, 154, 230, 183]\n",
    "    - [13, 13, 14, 180, 14, 180, 18, 109, 109, 18, 17, 14, 53, 230, 110, 230, 68, 154, 230, 183]\n",
    "- 38 and 33:\n",
    "     - 4cbd3ddf4ec5cfd1a85c36aa639ecd4980b48554544ea23d39a87131d8e08c00\n",
    "     - d2395776de5f71dc61f8d4c41c5bccd7f7ad02fc26d239d17aa1ccdbcf10f1eb\n",
    "     - [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 97, 17, 75, 13, 13, 13, 13, 13, 13]\n",
    "     - [144, 144, 154, 230, 183, 144, 144, 154, 230, 183, 154, 230, 183, 144, 144, 154, 230, 183, 144, 144]\n",
    "- 56 and 32:\n",
    "    - c00b9995dea99fa81237e13d6f3cb21c794de6976890c0ab4152695e0eaaa9af\n",
    "    - ca9f36790380cd38078c1199bfc2490b607838869ec74a0615e64fad0ca5dae7\n",
    "    - [17, 154, 53, 9, 47, 230, 230, 53, 230, 53, 9, 47, 230, 53, 53, 230, 53, 9, 47, 47]\n",
    "    - [17, 11, 154, 36, 53, 9, 47, 230, 47, 53, 9, 47, 230, 47, 53, 53, 53, 47, 230, 47]\n",
    "- 108 and 4:\n",
    "    - 5742754f10dc16310b3b14ecc038092749285e49c80286f9e495a453df65a072\n",
    "    - 55588e044f1fbafabe0f845fadcc1e5755720c6b02af9786988204f05b90749e\n",
    "    - [243, 145, 131, 158, 131, 158, 116, 131, 131, 109, 109, 82, 30, 144, 144, 27, 144, 144, 148, 7]\n",
    "    - [223, 223, 144, 144, 223, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 75, 144, 144]\n",
    "- 58 and 96:\n",
    "    - 7db44715a40576ad4d3d3d7e363827ef0071ab29e957d75d6d60e01e6f60221b\n",
    "    - 48ba4b829beababb63b988f3d4d6fd4a05d8239debaba79bd4ffe00aec34b2a7\n",
    "    - [144, 144, 39, 131, 39, 248, 184, 201, 39, 39, 39, 167, 167, 242, 242, 242, 53, 53, 190, 111]\n",
    "    - [144, 144, 144, 75, 202, 205, 154, 149, 53, 149, 53, 149, 53, 9, 47, 230, 47, 149, 53, 36]\n",
    "- 31 and 50:\n",
    "    - 3eb626670ff5a334a4d88d7ec94a7b1af5ee611a7f04010ebfb278403707f279\n",
    "    - 5a74be87c7c4e9dd50bf3d89467d8c3ace953bff712b92c966f0d9ea14960132\n",
    "    - [14, 17, 154, 230, 230, 183, 154, 230, 230, 183, 96, 154, 230, 230, 183, 53, 9, 47, 230, 47]\n",
    "    - [17, 154, 53, 9, 47, 230, 47, 154, 53, 9, 47, 230, 47, 17, 154, 53, 47, 9, 230, 47]\n",
    "- 60 and 88:\n",
    "    - 22f352771d9fe706e3b22d6c189fe44519618910c7fb75d712443cffdfa838d9\n",
    "    - f4e57bb45ae5bbdc08c0766a28e9255b95db8e9483ada25d1b0637e493ecfb2c\n",
    "    - [94, 94, 94, 94, 235, 130, 235, 235, 235, 11, 53, 149, 47, 47, 53, 149, 36, 17, 173, 173]\n",
    "    - [144, 27, 156, 100, 156, 100, 75, 156, 100, 133, 157, 157, 157, 157, 157, 156, 100, 156, 100, 14]\n",
    "- 27 and 69:\n",
    "    - 57178cbf6694f828ca46611392a1685c9b6ea8edbee4c4ff82a856c2df37ff3f\n",
    "    - 2559d6c8cf9a1b627f400fb17d09270149372c02dbcac83e9c7080c33d2e6235\n",
    "    - [53, 47, 9, 230, 230, 47, 230, 110, 154, 230, 183, 17, 230, 68, 154, 230, 183, 154, 230, 183]\n",
    "    - [154, 154, 230, 230, 230, 183, 154, 154, 154, 230, 230, 183, 154, 154, 230, 230, 230, 230, 230, 183]\n",
    "- 48 and 52:\n",
    "    - 8b38c4db3f3523c15217f6e627e30c0e4b707e61b855cc53f81c080ed25c1e65\n",
    "    - fc6e57b07995733da9f81dadb22d5dffa53df091ade6dab66d188a175608b6f0\n",
    "    - [154, 154, 154, 154, 154, 154, 183, 154, 154, 183, 154, 154, 154, 154, 154, 183, 154, 183, 154, 183]\n",
    "    - [154, 154, 154, 183, 154, 154, 154, 154, 154, 154, 183, 154, 154, 183, 154, 183, 154, 154, 154, 183]\n",
    "    \n",
    "Check vector similarity between operations of different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cceda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twentiesUsers[48])\n",
    "print(twentiesUsers[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156431ec",
   "metadata": {},
   "source": [
    "Observations at a first glance:\n",
    "- More often than not, pairs of user-level vectors match at the end \n",
    "    - This can be explained by the encoding of the cell-state (short-term memory), as the model encoding gives equal weighting (concatenates along the 0 axis) to the cell-state. \n",
    "    - An easy fix would be to discard the cell-state, keeping only the hidden-state prior to decoding (and using a default blank cell-state). Look into this?\n",
    "- Several pairs of user-level vector have similar frequency of a certain operation (154, 230, 144, etc), \"drowning out\" the other potentially important operations in the sequence\n",
    "    - 154, 230, and 144 correspond respectively to: \n",
    "        - '97a874321e4d1572fbfed141041b6c451751df55d0a1e78826a6c8dd446123ec'\n",
    "        - 'e55e4e5125823bcf5c3dd21a5b9bddeb35dc30cbae3aed81ccad1609d587310d'\n",
    "        - '8e2eef2e7c9028e26094ee1420f0507a976ca9e6b0fd04ef7b8b75d161f4046d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383a5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767610e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262aab99",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # encoder, decoder\n",
    "        self.encoder = resnet18_encoder(False, False)\n",
    "        self.decoder = resnet18_decoder(\n",
    "            latent_dim=latent_dim, \n",
    "            input_height=input_height, \n",
    "            first_conv=False, \n",
    "            maxpool1=False\n",
    "        )\n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def gaussian_likelihood(self, mean, logscale, sample):\n",
    "        scale = torch.exp(logscale)\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "        log_pxz = dist.log_prob(sample)\n",
    "        return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded \n",
    "        x_hat = vae.decoder(z)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo': elbo,\n",
    "            'kl': kl.mean(),\n",
    "            'recon_loss': recon_loss.mean(), \n",
    "            'reconstruction': recon_loss.mean(),\n",
    "            'kl': kl.mean(),\n",
    "        })\n",
    "\n",
    "        return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79057d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46a010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d53378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc135d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdfc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6d7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1655480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98262d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39f9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7aa8b26",
   "metadata": {},
   "source": [
    "## CNN Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a191975",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -v theano==0.9.0\n",
    "! pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "#! pip install -v pandas==0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ef5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cea40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source cuda11.1\n",
    "# To see Cuda version in use\n",
    "!nvcc -V\n",
    "!pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d250bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96286064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c249705",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = transforms.ToTensor()\n",
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                       train = True,\n",
    "                       download = True,\n",
    "                       transform = tensor_transform)\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,\n",
    "                                    batch_size = 32,\n",
    "                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28,128), \n",
    "            torch.nn.ReLU(True), #what does true do?\n",
    "            torch.nn.Linear(128,64),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64,36),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(36,18),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(18,9)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9,18),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(18,36),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(36,64),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(64,128),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(128,28*28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3, \n",
    "                             weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79937096",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "outputs = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for (image, _) in loader:\n",
    "        image = image.reshape(-1,28*28)\n",
    "        reconstructed = model(image)\n",
    "        loss = criterion(reconstructed, image)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "    outputs.append((epochs, image, reconstructed))\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b965818",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reconstructed.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = image[31].reshape(-1,28,28)\n",
    "plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = reconstructed[31].reshape(-1,28,28)\n",
    "item = item.detach().numpy()\n",
    "plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86176a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07012aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac5d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414f105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed77780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16987e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695eae1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fa424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4165379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d00829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce2144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76576457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f51a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17e2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69184a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61108809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5dfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221211d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8efdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4764b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb34dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a6f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635eb395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a8718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa241de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eadae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15cf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f460f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049fece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29477a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efa244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55a411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c025b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca35bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885c819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ad0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcc621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52510c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec939758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931aecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb515f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f87dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b39505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485f09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083197d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacbad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f763e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bcfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758f968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335e882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c35c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c2b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc0c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de27250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99ed00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fbfca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883eb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3387f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b556134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d55cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd75b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af4ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4285b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7296ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28199a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef60782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d21192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904b3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0aecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5346b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098a285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ab9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208e37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a200fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6637fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678988f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d29e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46fa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e1713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a390d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fc027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51dba59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff711a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1da8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4cf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c295b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b64f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a74e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f7d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f242e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca54e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d91dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69ab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416f561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5ef61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8ef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745318d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb8d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e806f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46204bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460859d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ca609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6839a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed81fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b31753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050f138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a1dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c045ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b15dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e022b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf74f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de032a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aeb747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b2354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa32d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b15311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524466ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9ab6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404f678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ccfe41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ef39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95f7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4767c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fddab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f67cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb45c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af96c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14017d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8b1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b9ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85775d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563121f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3374ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6626cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d5300f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49016db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99321760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273274d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c1fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006b8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d526e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f805f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdc245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b24865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4dec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4672236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ff175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030927c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a5fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464be007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296fef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e2660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79f372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a980cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3804682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f27300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09928c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec23086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf167c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24da6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0216c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58287b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365be74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790dc355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcee597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783201e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bc286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c00b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ac248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749d54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb076138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebb14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa02db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15527034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81380330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5226a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d0393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fc917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97654eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67ef76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d8cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b66d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c59c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a62bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e544c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabd26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3b0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8eaa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b846f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37470225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2481212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f11372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c1a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb4bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff1167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8518a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ebbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4be54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4efc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae9281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff275f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02c739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276a3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ef6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ea6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d539fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26e6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5832a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcea40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fce05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c44cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0651d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131a37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44187127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a569c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcc055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d5db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a603e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2c811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064723b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c17b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b852444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ba536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08aa845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e1298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d2c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89386e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321aae61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d10ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79246463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c870e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ea630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc2319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3ae2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734f0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0192f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d571c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60df08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32803cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084a432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef2356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a53e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094689b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a286e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811af67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c538a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272c53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c331a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623f13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fd538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb1268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bda66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339db788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fd30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba2f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97733f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5a026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83585a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b58550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e27555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2214c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed8354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f693be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad41e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5dd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6951c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b29932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38f216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e49c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d07e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a73cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ded810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb2539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dccfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31233517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e60d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714aa003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e6a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d120c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1629bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3be1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051cad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1cede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
